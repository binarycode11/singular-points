{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from meu_dataset import MeuDataset,avaliar_descritor,calcular_matching\n",
    "from teste_util import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_dataset = \"./data/datasets/features_path_flowers_dataset.pt\"\n",
    "# Carregar o dataset do arquivo \"meu_dataset.pt\"\n",
    "meu_dataset = MeuDataset.load_from_file(path_dataset)\n",
    "#verificar se o objeto meu dataset está retornando o tensor correto\n",
    "assert isinstance(meu_dataset,MeuDataset), 'o tipo de retorno não é MeuDataset'\n",
    "assert isinstance(meu_dataset[0][0],torch.Tensor), 'o tipo de retorno não é torch.Tensor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "batch_size_siam = 30\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(meu_dataset, [0.4,0.4,0.2])\n",
    "\n",
    "# Crie uma instância do DataLoader usando seu conjunto de dados personalizado\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size_siam, shuffle=False)\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=batch_size_siam, shuffle=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size_siam, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pairwise_distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "# def loss_fn(output_pos, output_neg, margin=15,total=100): \n",
    "#     acertos_pos = torch.sum(output_pos[:, 0] == output_pos[:, 1])\n",
    "#     false_pos = torch.sum(output_pos[:, 0] != output_pos[:, 1])\n",
    "#     false_neg = output_neg.shape[0]\n",
    "#     total_erros = false_pos + false_neg\n",
    "    \n",
    "#     loss = (total_erros-acertos_pos+margin).to(torch.float32).to(output_pos.device).detach().requires_grad_(True)\n",
    "#     loss = torch.relu(loss)  # Aplicar ReLU para descartar os valores negativos\n",
    "#     return loss/total\n",
    "\n",
    "def loss_fn(output_pos, output_neg, margin=15,total=100): \n",
    "    acertos_pos = torch.sum(output_pos[:, 0] == output_pos[:, 1])\n",
    "    false_pos = torch.sum(output_pos[:, 0] != output_pos[:, 1])\n",
    "    false_neg = output_neg.shape[0]\n",
    "    total_erros = false_pos + false_neg\n",
    "    \n",
    "    loss = (total_erros-acertos_pos+margin).to(torch.float32).to(output_pos.device).detach().requires_grad_(True)\n",
    "    loss = torch.relu(loss)  # Aplicar ReLU para descartar os valores negativos\n",
    "    # print(\"FN: \",false_neg,\"FP:\",false_pos, \"VP: \",acertos_pos.item(),\" TF: \",total_erros.item(),\" L: \",loss.item(),\"M :\",margin)\n",
    "    return loss/total\n",
    "\n",
    "#Create methods to train the model\n",
    "def train_one_epoch(model, data_loader, optimizer, loss_fn, device='cpu', is_training=True):\n",
    "    model.train(is_training)\n",
    "    total_loss = 0.\n",
    "    # Definir os intervalos de colunas\n",
    "    \n",
    "    progress_bar = tqdm(data_loader)\n",
    "    for idx,data in enumerate(progress_bar):\n",
    "        #extrair as features e orientações\n",
    "        batch_in,batch_out = data[0].to(device),data[1].to(device)        \n",
    "        descs_original = model(batch_in)# encontrando descritores\n",
    "        descs_transform = model(batch_out)# encontrando descritores\n",
    "        match_pos,match_neg  = calcular_matching(descs_original, descs_transform,th=100.50)# calculando os matches\n",
    "        loss = loss_fn(match_pos,match_neg ,margin=(batch_in.size(0)*3/2),total = batch_in.size(0)*4)\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'Loss: {loss.item()} - Total Loss: {total_loss}')\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wagner/.local/lib/python3.11/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  full_mask[mask] = norms.to(torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "from siamesa_e2cnn import Feature\n",
    "n_channel =8\n",
    "model =Feature(n_channel=n_channel).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.375 - Total Loss: 26.691668689250946: 100%|██████████| 71/71 [00:05<00:00, 13.14it/s]             \n",
      "Loss: 0.375 - Total Loss: 26.741668671369553: 100%|██████████| 71/71 [00:05<00:00, 14.16it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] - Running Loss: 26.6917, Test Loss: 26.7417, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.375 - Total Loss: 26.691668689250946: 100%|██████████| 71/71 [00:05<00:00, 13.16it/s]             \n",
      "Loss: 0.375 - Total Loss: 26.741668671369553: 100%|██████████| 71/71 [00:05<00:00, 14.09it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Running Loss: 26.6917, Test Loss: 26.7417, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.375 - Total Loss: 26.691668689250946: 100%|██████████| 71/71 [00:05<00:00, 13.13it/s]             \n",
      "Loss: 0.375 - Total Loss: 26.741668671369553: 100%|██████████| 71/71 [00:05<00:00, 14.08it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Running Loss: 26.6917, Test Loss: 26.7417, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.375 - Total Loss: 26.691668689250946: 100%|██████████| 71/71 [00:05<00:00, 13.15it/s]             \n",
      "Loss: 0.375 - Total Loss: 26.741668671369553: 100%|██████████| 71/71 [00:05<00:00, 14.08it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n",
      "Epoch [3/50] - Running Loss: 26.6917, Test Loss: 26.7417, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.375 - Total Loss: 26.691668689250946: 100%|██████████| 71/71 [00:05<00:00, 13.11it/s]             \n",
      "Loss: 0.375 - Total Loss: 26.741668671369553: 100%|██████████| 71/71 [00:05<00:00, 13.95it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - Running Loss: 26.6917, Test Loss: 26.7417, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.375 - Total Loss: 26.691668689250946: 100%|██████████| 71/71 [00:05<00:00, 13.13it/s]             \n",
      "Loss: 0.375 - Total Loss: 26.741668671369553: 100%|██████████| 71/71 [00:05<00:00, 14.00it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in loss for 5 epochs. Training stopped.\n",
      "Epoch: 5, Best Loss: 26.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "def train(model,dataloader_train,dataloader_val):\n",
    "    optimizer_siamese = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = ExponentialLR(optimizer_siamese, gamma=0.75)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    epochs_without_improvement = 0\n",
    "    epochs = 50\n",
    "    patience = 5\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model,dataloader_train , optimizer_siamese, loss_fn, device=device, is_training=True)\n",
    "        with torch.no_grad():\n",
    "            test_loss = train_one_epoch(model,dataloader_val , optimizer_siamese, loss_fn, device=device, is_training=False)\n",
    "\n",
    "        # Verificar se a perda melhorou\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model = model.state_dict()        \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if (epoch % 3 == 0) and (epoch != 0):\n",
    "            scheduler.step()\n",
    "            save_model(model, PATH_MODEL)\n",
    "        \n",
    "        # Verificar a condição de parada\n",
    "        if epochs_without_improvement == patience:\n",
    "            print(f\"No improvement in loss for {epochs_without_improvement} epochs. Training stopped.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - Running Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Initial LR: {optimizer_siamese.param_groups[0]['initial_lr']:.6f}, Current LR: {optimizer_siamese.param_groups[0]['lr']:.6f}, Epochs without Improvement: {epochs_without_improvement}\")\n",
    "\n",
    "    # Carregar a melhor configuração do modelo\n",
    "    model.load_state_dict(best_model)\n",
    "    print(f'Epoch: {epoch}, Best Loss: {best_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "PATH_MODEL = './data/models/feature_flowers_sp.pt'\n",
    "model = train(model,dataloader_train,dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(model, PATH_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./data/models/feature_flowers_sp.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos no DataLoader: 4224\n",
      "Acertei: 1969/2112 Errei: 90/2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "PATH_MODEL = './data/models/feature_flowers_sp.pt'\n",
    "model =Feature(n_channel=8)\n",
    "model.to(device)\n",
    "load_model(model, PATH_MODEL,device)\n",
    "\n",
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test, model,th=0.4)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 70.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos no DataLoader: 4224\n",
      "Acertei: 1283/2112 Errei: 2/2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test, model,th=0.32)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refazer o treinamento para fazer o descritor na imagem original ao inves da feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"./data/datasets/img_path_flowers_dataset.pt\"\n",
    "meu_dataset2 = MeuDataset.load_from_file(path_dataset)\n",
    "train_dataset2, val_dataset2, test_dataset2 = random_split(meu_dataset2, [0.4,0.4,0.2])\n",
    "\n",
    "# Crie uma instância do DataLoader usando seu conjunto de dados personalizado\n",
    "dataloader_train2 = DataLoader(train_dataset2, batch_size=batch_size_siam, shuffle=True)\n",
    "dataloader_val2 = DataLoader(val_dataset2, batch_size=batch_size_siam, shuffle=True)\n",
    "dataloader_test2 = DataLoader(test_dataset2, batch_size=batch_size_siam, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4166666865348816 - Total Loss: 39.48333543539047: 100%|██████████| 71/71 [00:01<00:00, 59.09it/s] \n",
      "Loss: 0.4583333432674408 - Total Loss: 39.291668742895126: 100%|██████████| 71/71 [00:01<00:00, 65.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] - Running Loss: 39.4833, Test Loss: 39.2917, Initial LR: 100.001000, Current LR: 100.001000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4583333432674408 - Total Loss: 39.35833552479744: 100%|██████████| 71/71 [00:01<00:00, 64.86it/s]  \n",
      "Loss: 0.4583333432674408 - Total Loss: 39.79166880249977: 100%|██████████| 71/71 [00:01<00:00, 70.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Running Loss: 39.3583, Test Loss: 39.7917, Initial LR: 100.001000, Current LR: 100.001000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4166666865348816 - Total Loss: 39.46666878461838: 100%|██████████| 71/71 [00:01<00:00, 63.03it/s] \n",
      "Loss: 0.375 - Total Loss: 39.00833550095558: 100%|██████████| 71/71 [00:01<00:00, 70.84it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Running Loss: 39.4667, Test Loss: 39.0083, Initial LR: 100.001000, Current LR: 100.001000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4583333432674408 - Total Loss: 39.208335280418396: 100%|██████████| 71/71 [00:01<00:00, 66.29it/s]\n",
      "Loss: 0.5 - Total Loss: 39.516669034957886: 100%|██████████| 71/71 [00:01<00:00, 70.32it/s]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/img_flowers_sp.pt\n",
      "Epoch [3/50] - Running Loss: 39.2083, Test Loss: 39.5167, Initial LR: 100.001000, Current LR: 75.000750, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4583333432674408 - Total Loss: 39.59166893362999: 100%|██████████| 71/71 [00:01<00:00, 66.47it/s] \n",
      "Loss: 0.4166666865348816 - Total Loss: 39.68333524465561: 100%|██████████| 71/71 [00:01<00:00, 69.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - Running Loss: 39.5917, Test Loss: 39.6833, Initial LR: 100.001000, Current LR: 75.000750, Epochs without Improvement: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5833333730697632 - Total Loss: 39.6000020802021: 100%|██████████| 71/71 [00:01<00:00, 63.65it/s]  \n",
      "Loss: 0.5833333730697632 - Total Loss: 39.616668701171875: 100%|██████████| 71/71 [00:01<00:00, 68.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] - Running Loss: 39.6000, Test Loss: 39.6167, Initial LR: 100.001000, Current LR: 75.000750, Epochs without Improvement: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5 - Total Loss: 39.10000213980675: 100%|██████████| 71/71 [00:01<00:00, 66.93it/s]                 \n",
      "Loss: 0.4583333432674408 - Total Loss: 39.12500211596489: 100%|██████████| 71/71 [00:00<00:00, 72.09it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/img_flowers_sp.pt\n",
      "Epoch [6/50] - Running Loss: 39.1000, Test Loss: 39.1250, Initial LR: 100.001000, Current LR: 56.250563, Epochs without Improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4583333432674408 - Total Loss: 39.49166867136955: 100%|██████████| 71/71 [00:01<00:00, 64.91it/s] \n",
      "Loss: 0.5833333730697632 - Total Loss: 39.48333561420441: 100%|██████████| 71/71 [00:01<00:00, 68.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in loss for 5 epochs. Training stopped.\n",
      "Epoch: 7, Best Loss: 39.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_channel =1\n",
    "model =Feature(n_channel=n_channel).to(device)\n",
    "PATH_MODEL = './data/models/img_flowers_sp.pt'\n",
    "model = train(model,dataloader_train2,dataloader_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 73.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos no DataLoader: 4224\n",
      "Acertei: 1163/2112 Errei: 7/2112\n",
      "Model saved to ./data/models/img_flowers_sp.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test2, model,th=0.25)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')\n",
    "save_model(model, PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e2cnn import gspaces\n",
    "from e2cnn import nn as enn    #the equivariant layer we need to build the model\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Feature(nn.Module):\n",
    "    def __init__(self,n_channel=2) -> None:\n",
    "        super().__init__()\n",
    "        r2_act = gspaces.Rot2dOnR2(N=12)\n",
    "\n",
    "        feat_type_in  = enn.FieldType(r2_act,  n_channel*[r2_act.trivial_repr])\n",
    "        feat_type_out = enn.FieldType(r2_act, n_channel*[r2_act.regular_repr])\n",
    "        self.input_type = feat_type_in\n",
    "\n",
    "        self.block1 = enn.SequentialModule(\n",
    "                enn.R2Conv(feat_type_in, feat_type_out, kernel_size=3, padding=0, bias=False),\n",
    "                enn.InnerBatchNorm(feat_type_out),\n",
    "                enn.ReLU(feat_type_out, inplace=True),\n",
    "                enn.GroupPooling(feat_type_out),\n",
    "                )\n",
    "        self.pool = enn.PointwiseAdaptiveAvgPool(self.block1.out_type,4)\n",
    "\n",
    "    def forward(self,X1)->torch.Tensor:\n",
    "        x = enn.GeometricTensor(X1, self.input_type)\n",
    "        n_dim = X1.shape[-1]\n",
    "        mask = enn.MaskModule(self.input_type, n_dim, margin=2).to(X1.device)\n",
    "        x = mask(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.tensor.reshape(x.shape[0],-1)\n",
    "        return x\n",
    "\n",
    "n_channel =8\n",
    "model =Feature(n_channel=n_channel).to(device)\n",
    "image =torch.rand(4,n_channel,32,32).to(device)\n",
    "model(image).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

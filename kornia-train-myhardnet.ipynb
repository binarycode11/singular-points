{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from meu_dataset import MeuDataset,avaliar_descritor,calcular_matching\n",
    "from teste_util import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_dataset = \"./data/datasets/features_path_flowers_dataset.pt\"\n",
    "# Carregar o dataset do arquivo \"meu_dataset.pt\"\n",
    "meu_dataset = MeuDataset.load_from_file(path_dataset)\n",
    "#verificar se o objeto meu dataset está retornando o tensor correto\n",
    "assert isinstance(meu_dataset,MeuDataset), 'o tipo de retorno não é MeuDataset'\n",
    "assert isinstance(meu_dataset[0][0],torch.Tensor), 'o tipo de retorno não é torch.Tensor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "batch_size_siam = 50\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(meu_dataset, [0.5,0.3,0.2])\n",
    "\n",
    "# Crie uma instância do DataLoader usando seu conjunto de dados personalizado\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size_siam, shuffle=False)\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=batch_size_siam, shuffle=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size_siam, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pairwise_distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "def loss_fn(output_pos, output_neg, margin=15,total=100): \n",
    "    acertos_pos = torch.sum(output_pos[:, 0] == output_pos[:, 1])\n",
    "    false_pos = torch.sum(output_pos[:, 0] != output_pos[:, 1])\n",
    "    false_neg = output_neg.shape[0]\n",
    "    total_erros = false_pos + false_neg\n",
    "    \n",
    "    loss = (total-acertos_pos+total_erros).to(torch.float32).to(output_pos.device).detach().requires_grad_(True)\n",
    "    loss = torch.relu(loss)  # Aplicar ReLU para descartar os valores negativos\n",
    "    return loss/total\n",
    "\n",
    "# def loss_fn(output_pos, output_neg, margin=15,total=100): \n",
    "#     acertos_pos = torch.sum(output_pos[:, 0] == output_pos[:, 1])\n",
    "#     false_pos = torch.sum(output_pos[:, 0] != output_pos[:, 1])\n",
    "#     false_neg = output_neg.shape[0]\n",
    "#     total_erros = false_pos + false_neg\n",
    "    \n",
    "#     loss = (total-acertos_pos+total_erros).to(torch.float32).to(output_pos.device).detach().requires_grad_(True)\n",
    "#     loss = torch.relu(loss)  # Aplicar ReLU para descartar os valores negativos\n",
    "#     return loss/total\n",
    "\n",
    "#Create methods to train the model\n",
    "def train_one_epoch(model, data_loader, optimizer, loss_fn, device='cpu', is_training=True):\n",
    "    model.train(is_training)\n",
    "    total_loss = 0.\n",
    "    # Definir os intervalos de colunas\n",
    "    \n",
    "    progress_bar = tqdm(data_loader)\n",
    "    for idx,data in enumerate(progress_bar):\n",
    "        #extrair as features e orientações\n",
    "        batch_in,batch_out = data[0].to(device),data[1].to(device)        \n",
    "        descs_original = model(batch_in)# encontrando descritores\n",
    "        descs_transform = model(batch_out)# encontrando descritores\n",
    "        match_pos,match_neg  = calcular_matching(descs_original, descs_transform,th=1.00)# calculando os matches\n",
    "        loss = loss_fn(match_pos,match_neg ,margin=(batch_in.size(0)*3/4),total = batch_in.size(0)*4)\n",
    "        \n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'Loss: {loss.item()} - Total Loss: {total_loss}')\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wagner/.local/lib/python3.11/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  full_mask[mask] = norms.to(torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "from e2cnn import gspaces\n",
    "from e2cnn import nn as enn    #the equivariant layer we need to build the model\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Feature(nn.Module):\n",
    "    def __init__(self,n_channel=2) -> None:\n",
    "        super().__init__()\n",
    "        r2_act = gspaces.Rot2dOnR2(N=18)\n",
    "\n",
    "        feat_type_in  = enn.FieldType(r2_act,  n_channel*[r2_act.trivial_repr])\n",
    "        feat_type_out = enn.FieldType(r2_act, 2*n_channel*[r2_act.regular_repr])\n",
    "        self.input_type = feat_type_in\n",
    "\n",
    "        self.block1 = enn.SequentialModule(\n",
    "                enn.R2Conv(feat_type_in, feat_type_out, kernel_size=3, padding=0, bias=False),\n",
    "                enn.InnerBatchNorm(feat_type_out),\n",
    "                enn.ReLU(feat_type_out, inplace=True)\n",
    "                )\n",
    "\n",
    "        self.pool1 = enn.PointwiseAvgPoolAntialiased(feat_type_out, sigma=0.66, stride=1, padding=0)\n",
    "\n",
    "        feat_type_in  = self.block1.out_type\n",
    "        feat_type_out = enn.FieldType(r2_act,  4*n_channel*[r2_act.regular_repr])\n",
    "        self.block2 = enn.SequentialModule(\n",
    "                enn.R2Conv(feat_type_in, feat_type_out, kernel_size=3, padding=0, bias=False),\n",
    "                enn.InnerBatchNorm(feat_type_out),\n",
    "                enn.ReLU(feat_type_out, inplace=True),\n",
    "                )\n",
    "        # self.pool2 = enn.PointwiseAvgPool(feat_type_out, 21)\n",
    "\n",
    "        feat_type_in  = feat_type_out\n",
    "        feat_type_out = enn.FieldType(r2_act,  8*n_channel*[r2_act.regular_repr])\n",
    "        self.block3 = enn.SequentialModule(\n",
    "                enn.R2Conv(feat_type_in, feat_type_out, kernel_size=3, padding=0, bias=False),\n",
    "                enn.InnerBatchNorm(feat_type_out),\n",
    "                enn.ReLU(feat_type_out, inplace=True),\n",
    "                enn.GroupPooling(feat_type_out),\n",
    "                )\n",
    "        self.pool = enn.PointwiseAdaptiveAvgPool(self.block3.out_type,1)\n",
    "\n",
    "    def forward(self,X1)->torch.Tensor:\n",
    "        x = enn.GeometricTensor(X1, self.input_type)\n",
    "        n_dim = X1.shape[-1]\n",
    "        mask = enn.MaskModule(self.input_type, n_dim, margin=2).to(X1.device)\n",
    "        x = mask(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.tensor.reshape(x.shape[0],-1)\n",
    "        return x\n",
    "\n",
    "n_channel =8\n",
    "model =Feature(n_channel=n_channel).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 20.37it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.55it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.53it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.36it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n",
      "Epoch [3/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.41it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.39it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 20.84it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n",
      "Epoch [6/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000563, Epochs without Improvement: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.36it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000563, Epochs without Improvement: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.39it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000563, Epochs without Improvement: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.38it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n",
      "Epoch [9/50] - Running Loss: 154.4300, Test Loss: 92.7878, Initial LR: 0.001000, Current LR: 0.000422, Epochs without Improvement: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0 - Total Loss: 154.4299976825714: 100%|██████████| 152/152 [00:07<00:00, 21.22it/s]                \n",
      "Loss: 1.0277777910232544 - Total Loss: 92.78777611255646: 100%|██████████| 91/91 [00:03<00:00, 23.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in loss for 10 epochs. Training stopped.\n",
      "Epoch: 10, Best Loss: 92.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "def train(model,dataloader_train,dataloader_val):\n",
    "    optimizer_siamese = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = ExponentialLR(optimizer_siamese, gamma=0.75)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    epochs_without_improvement = 0\n",
    "    epochs = 50\n",
    "    patience = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model,dataloader_train , optimizer_siamese, loss_fn, device=device, is_training=True)\n",
    "        with torch.no_grad():\n",
    "            test_loss = train_one_epoch(model,dataloader_val , optimizer_siamese, loss_fn, device=device, is_training=False)\n",
    "\n",
    "        # Verificar se a perda melhorou\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model = model.state_dict()        \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if (epoch % 3 == 0) and (epoch != 0):\n",
    "            scheduler.step()\n",
    "            save_model(model, PATH_MODEL)\n",
    "        \n",
    "        # Verificar a condição de parada\n",
    "        if epochs_without_improvement == patience:\n",
    "            print(f\"No improvement in loss for {epochs_without_improvement} epochs. Training stopped.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - Running Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Initial LR: {optimizer_siamese.param_groups[0]['initial_lr']:.6f}, Current LR: {optimizer_siamese.param_groups[0]['lr']:.6f}, Epochs without Improvement: {epochs_without_improvement}\")\n",
    "\n",
    "    # Carregar a melhor configuração do modelo\n",
    "    model.load_state_dict(best_model)\n",
    "    print(f'Epoch: {epoch}, Best Loss: {best_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "PATH_MODEL = './data/models/feature_flowers_sp.pt'\n",
    "model = train(model,dataloader_train,dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n",
      "Model loaded from ./data/models/feature_flowers_sp.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(model, PATH_MODEL)\n",
    "model =Feature(n_channel=n_channel)\n",
    "model.to(device)\n",
    "load_model(model, PATH_MODEL,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:02<00:00, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos no DataLoader: 12096\n",
      "Acertei: 5386/6048 Errei: 301/6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test, model,th=0.35)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refazer o treinamento para fazer o descritor na imagem original ao inves da feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"./data/datasets/img_path_flowers_dataset.pt\"\n",
    "meu_dataset = MeuDataset.load_from_file(path_dataset)\n",
    "train_dataset, val_dataset, test_dataset = random_split(meu_dataset, [0.4,0.4,0.2])\n",
    "\n",
    "# Crie uma instância do DataLoader usando seu conjunto de dados personalizado\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size_siam, shuffle=True)\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=batch_size_siam, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size_siam, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0729167461395264 - Total Loss: 131.3229147195816: 100%|██████████| 121/121 [00:02<00:00, 42.20it/s] \n",
      "Loss: 1.0833333730697632 - Total Loss: 130.63332951068878: 100%|██████████| 121/121 [00:02<00:00, 48.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] - Running Loss: 131.3229, Test Loss: 130.6333, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0833333730697632 - Total Loss: 131.96333050727844: 100%|██████████| 121/121 [00:02<00:00, 40.81it/s]\n",
      "Loss: 1.0729167461395264 - Total Loss: 129.93291223049164: 100%|██████████| 121/121 [00:02<00:00, 45.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Running Loss: 131.9633, Test Loss: 129.9329, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0729167461395264 - Total Loss: 131.77291321754456: 100%|██████████| 121/121 [00:02<00:00, 41.71it/s]\n",
      "Loss: 1.0729167461395264 - Total Loss: 130.7129133939743: 100%|██████████| 121/121 [00:02<00:00, 49.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] - Running Loss: 131.7729, Test Loss: 130.7129, Initial LR: 0.001000, Current LR: 0.001000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1041667461395264 - Total Loss: 131.74416434764862: 100%|██████████| 121/121 [00:02<00:00, 42.99it/s]\n",
      "Loss: 1.0729167461395264 - Total Loss: 130.58291351795197: 100%|██████████| 121/121 [00:02<00:00, 48.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/img_flowers_sp.pt\n",
      "Epoch [3/50] - Running Loss: 131.7442, Test Loss: 130.5829, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0729167461395264 - Total Loss: 131.80291438102722: 100%|██████████| 121/121 [00:02<00:00, 40.68it/s]\n",
      "Loss: 1.1041667461395264 - Total Loss: 130.1741622686386: 100%|██████████| 121/121 [00:02<00:00, 48.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] - Running Loss: 131.8029, Test Loss: 130.1742, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1041667461395264 - Total Loss: 132.20416462421417: 100%|██████████| 121/121 [00:02<00:00, 40.57it/s]\n",
      "Loss: 1.0520833730697632 - Total Loss: 130.13207948207855: 100%|██████████| 121/121 [00:02<00:00, 48.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] - Running Loss: 132.2042, Test Loss: 130.1321, Initial LR: 0.001000, Current LR: 0.000750, Epochs without Improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0520833730697632 - Total Loss: 131.67208099365234: 100%|██████████| 121/121 [00:02<00:00, 40.47it/s]\n",
      "Loss: 1.125 - Total Loss: 130.41499650478363: 100%|██████████| 121/121 [00:02<00:00, 46.15it/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/img_flowers_sp.pt\n",
      "Epoch [6/50] - Running Loss: 131.6721, Test Loss: 130.4150, Initial LR: 0.001000, Current LR: 0.000563, Epochs without Improvement: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0520833730697632 - Total Loss: 131.60208094120026: 100%|██████████| 121/121 [00:02<00:00, 40.80it/s]\n",
      "Loss: 1.0520833730697632 - Total Loss: 130.18207967281342: 100%|██████████| 121/121 [00:02<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] - Running Loss: 131.6021, Test Loss: 130.1821, Initial LR: 0.001000, Current LR: 0.000563, Epochs without Improvement: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0833333730697632 - Total Loss: 131.95333087444305: 100%|██████████| 121/121 [00:02<00:00, 40.86it/s]\n",
      "Loss: 1.0520833730697632 - Total Loss: 130.67207944393158: 100%|██████████| 121/121 [00:02<00:00, 47.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] - Running Loss: 131.9533, Test Loss: 130.6721, Initial LR: 0.001000, Current LR: 0.000563, Epochs without Improvement: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.125 - Total Loss: 131.68499732017517: 100%|██████████| 121/121 [00:02<00:00, 41.23it/s]             \n",
      "Loss: 1.0729167461395264 - Total Loss: 129.96291315555573: 100%|██████████| 121/121 [00:02<00:00, 47.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/img_flowers_sp.pt\n",
      "Epoch [9/50] - Running Loss: 131.6850, Test Loss: 129.9629, Initial LR: 0.001000, Current LR: 0.000422, Epochs without Improvement: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0625 - Total Loss: 131.7124971151352: 100%|██████████| 121/121 [00:03<00:00, 40.18it/s]             \n",
      "Loss: 1.0625 - Total Loss: 130.44249629974365: 100%|██████████| 121/121 [00:02<00:00, 47.59it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] - Running Loss: 131.7125, Test Loss: 130.4425, Initial LR: 0.001000, Current LR: 0.000422, Epochs without Improvement: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0416667461395264 - Total Loss: 131.79166388511658: 100%|██████████| 121/121 [00:02<00:00, 40.39it/s]\n",
      "Loss: 1.0729167461395264 - Total Loss: 130.7629133462906: 100%|██████████| 121/121 [00:02<00:00, 46.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in loss for 10 epochs. Training stopped.\n",
      "Epoch: 11, Best Loss: 129.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_channel =1\n",
    "model =Feature(n_channel=n_channel).to(device)\n",
    "PATH_MODEL = './data/models/img_flowers_sp.pt'\n",
    "model = train(model,dataloader_train,dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:01<00:00, 51.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos no DataLoader: 12096\n",
      "Acertei: 4589/6048 Errei: 883/6048\n",
      "Model saved to ./data/models/img_flowers_sp.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test, model,th=0.25)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')\n",
    "save_model(model, PATH_MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htEwVdkET4ey"
      },
      "source": [
        "### Teste de hipotese\n",
        "\n",
        "Esse notebook tem por objetivo detectar varios pontos e gerar um descritor otimo que seja resitente a variacoes de transformacoes afins e pequenas transformacoes projetivas, para isso temos:\n",
        "\n",
        "-- BaseFeatures para extrair informacoes equivariantes (num_channels,dim_first,dim_second,dim_third).\n",
        "\n",
        "-- SingularPoints lida com escala , e extrai as features consolidadas, em dim_third caracteristicas distintas, orientacao computadas além da lista de pontos.\n",
        "\n",
        "-- Computa a funcao de perda entre os mapas de orientacao e feature e os pontos que colidiram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pmau4e00T4e0"
      },
      "outputs": [],
      "source": [
        "# !git clone -b main https://github.com/wagner1986/singular-points.git singular_points\n",
        "# !pip install kornia e2cnn kornia_moons\n",
        "\n",
        "# !pwd\n",
        "# %cd /content/singular_points\n",
        "# !pwd\n",
        "\n",
        "# from google.colab import drive\n",
        "\n",
        "# # Monta o Google Drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HCT8rCN8T4e1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from e2cnn import gspaces\n",
        "from e2cnn import nn as enn    #the equivariant layer we need to build the model\n",
        "from torch import nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, loss, path):\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss,\n",
        "        # Adicione outras informações que você deseja salvar, como hiperparâmetros, configurações, etc.\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "    \n",
        "def load_checkpoint(model, optimizer, path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    # Outras informações que você salvou no dicionário de checkpoint podem ser acessadas aqui\n",
        "    return model, optimizer, epoch, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AzVkVP59ekwW"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from kornia.core import Module, Tensor, concatenate\n",
        "from kornia.filters import SpatialGradient\n",
        "from kornia.geometry.transform import pyrdown\n",
        "from kornia.utils.helpers import map_location_to_cpu\n",
        "\n",
        "from kornia.feature.scale_space_detector import get_default_detector_config, MultiResolutionDetector,Detector_config\n",
        "\n",
        "\n",
        "class KeyNet_conf(TypedDict):\n",
        "    num_filters: int\n",
        "    num_levels: int\n",
        "    kernel_size: int\n",
        "    Detector_conf: Detector_config\n",
        "\n",
        "\n",
        "keynet_default_config: KeyNet_conf = {\n",
        "    # Key.Net Model\n",
        "    'num_filters': 8,\n",
        "    'num_levels': 3,\n",
        "    'kernel_size': 5,\n",
        "    # Extraction Parameters\n",
        "    'Detector_conf': {'nms_size': 5, 'pyramid_levels': 2, 'up_levels': 1, 'scale_factor_levels': 1.3, 's_mult': 20.0},\n",
        "}\n",
        "\n",
        "\n",
        "class _FeatureExtractor(Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.hc_block = _HandcraftedBlock()\n",
        "        self.lb_block = _LearnableBlock()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x_hc = self.hc_block(x)\n",
        "        x_lb = self.lb_block(x_hc)\n",
        "        return x_lb\n",
        "\n",
        "\n",
        "class _HandcraftedBlock(Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.spatial_gradient = SpatialGradient('sobel', 1)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        sobel = self.spatial_gradient(x)\n",
        "        dx, dy = sobel[:, :, 0, :, :], sobel[:, :, 1, :, :]\n",
        "\n",
        "        sobel_dx = self.spatial_gradient(dx)\n",
        "        dxx, dxy = sobel_dx[:, :, 0, :, :], sobel_dx[:, :, 1, :, :]\n",
        "\n",
        "        sobel_dy = self.spatial_gradient(dy)\n",
        "        dyy = sobel_dy[:, :, 1, :, :]\n",
        "\n",
        "        hc_feats = concatenate([dx, dy, dx**2.0, dy**2.0, dx * dy, dxy, dxy**2.0, dxx, dyy, dxx * dyy], 1)\n",
        "\n",
        "        return hc_feats\n",
        "\n",
        "\n",
        "def _KeyNetConvBlock(\n",
        "    feat_type_in,\n",
        "    feat_type_out,\n",
        "    r2_act,\n",
        "    kernel_size: int = 5,\n",
        "    stride: int = 1,\n",
        "    padding: int = 2,\n",
        "    dilation: int = 1,\n",
        ") -> nn.Sequential:\n",
        "    return enn.SequentialModule(\n",
        "            enn.R2Conv(feat_type_in, feat_type_out, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "            enn.InnerBatchNorm(feat_type_out),\n",
        "            enn.ReLU(feat_type_out, inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "class _LearnableBlock(nn.Sequential):\n",
        "    def __init__(self, in_channels: int = 10, out_channels: int = 8, group_size=8) -> None:\n",
        "        super().__init__()\n",
        "        r2_act = gspaces.Rot2dOnR2(N=group_size)\n",
        "\n",
        "        feat_type_in = enn.FieldType(r2_act, in_channels * [r2_act.trivial_repr])\n",
        "        self.in_type = feat_type_in\n",
        "        feat_type_out = enn.FieldType(r2_act, out_channels * [r2_act.regular_repr])\n",
        "        self.block0 = _KeyNetConvBlock(feat_type_in, feat_type_out, r2_act)\n",
        "\n",
        "        feat_type_out = enn.FieldType(r2_act, out_channels * [r2_act.regular_repr])\n",
        "        self.block1 = _KeyNetConvBlock(self.block0.out_type, feat_type_out, r2_act)\n",
        "\n",
        "        feat_type_out = enn.FieldType(r2_act, out_channels * [r2_act.regular_repr])\n",
        "        self.block2 = _KeyNetConvBlock(self.block1.out_type, feat_type_out, r2_act)\n",
        "        self.gpool = enn.GroupPooling(self.block2.out_type)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = enn.GeometricTensor(x, self.in_type)\n",
        "        x = self.block0(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.gpool(x)\n",
        "        return x.tensor\n",
        "\n",
        "class KeyNet(Module):\n",
        "    def __init__(self, pretrained: bool = False, keynet_conf: KeyNet_conf = keynet_default_config) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        num_filters = keynet_conf['num_filters']\n",
        "        self.num_levels = keynet_conf['num_levels']\n",
        "        kernel_size = keynet_conf['kernel_size']\n",
        "        padding = kernel_size // 2\n",
        "\n",
        "        self.feature_extractor = _FeatureExtractor()\n",
        "        \n",
        "        self.last_conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=num_filters * self.num_levels, out_channels=1, kernel_size=kernel_size, padding=padding\n",
        "            ),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        if pretrained:\n",
        "            KeyNet_URL =\"./data/models/key_map_ep123.pth\"\n",
        "            load_checkpoint(self,None, KeyNet_URL)\n",
        "            print(\"KeyNet loaded\")\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        shape_im = x.shape\n",
        "        feats: List[Tensor] = [self.feature_extractor(x)]\n",
        "        for i in range(1, self.num_levels):\n",
        "            x = pyrdown(x, factor=1.2)\n",
        "            feats_i = self.feature_extractor(x)\n",
        "            feats_i = F.interpolate(feats_i, size=(shape_im[2], shape_im[3]), mode='bilinear')\n",
        "            feats.append(feats_i)\n",
        "        scores = self.last_conv(concatenate(feats, 1))\n",
        "        return scores\n",
        "\n",
        "\n",
        "class KeyNetDetector(MultiResolutionDetector):\n",
        "    def __init__(\n",
        "        self,\n",
        "        pretrained: bool = False,\n",
        "        num_features: int = 2048,\n",
        "        keynet_conf: KeyNet_conf = keynet_default_config,\n",
        "        ori_module: Optional[Module] = None,\n",
        "        aff_module: Optional[Module] = None,\n",
        "    ) -> None:\n",
        "        model = KeyNet(pretrained, keynet_conf)\n",
        "        super().__init__(model, num_features, keynet_conf['Detector_conf'], ori_module, aff_module)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FAtdAEDnekwX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def criar_mascara(size_batch,dimensao_janela, tamanho_borda):\n",
        "    num_channels = 1\n",
        "    mascara = torch.zeros((size_batch,num_channels, dimensao_janela, dimensao_janela), dtype=torch.uint8)\n",
        "    mascara[..., tamanho_borda:-tamanho_borda, tamanho_borda:-tamanho_borda] = 1\n",
        "    return mascara.to(torch.float32)\n",
        "\n",
        "def my_similarity(a, b):\n",
        "    # a_norm = torch.nn.functional.normalize(a.view(a.size(0), -1), dim=-1)\n",
        "    # b_norm = torch.nn.functional.normalize(b.view(b.size(0), -1), dim=-1)\n",
        "    # return torch.cdist(a_norm, b_norm, p=2)\n",
        "    return torch.cdist(a.view(a.size(0), -1), b.view(b.size(0), -1), p=2)\n",
        "\n",
        "# Crie métodos para calcular a perda\n",
        "def loss_fn(map_anch, map_pos, margin=0.9):\n",
        "    similarities = my_similarity(map_anch, map_pos)\n",
        "    # Calcular a média da diagonal principal (âncoras vs. seus respectivos positivos)\n",
        "    mean_diagonal = torch.mean(torch.diagonal(similarities))\n",
        "    # Calcular a média dos outros elementos (âncoras vs. seus negativos correspondentes)\n",
        "    mean_other = torch.mean(similarities[~torch.eye(similarities.shape[0], dtype=torch.bool)])\n",
        "    losses = torch.relu(mean_diagonal - mean_other + margin)  # pos - neg + margin\n",
        "    return losses,mean_diagonal,mean_other\n",
        "\n",
        "\n",
        "def extract_feat_in_batch(model, batch_img):\n",
        "    repo_features = torch.tensor([], dtype=torch.float).to(batch_img.device)\n",
        "    for image in batch_img:\n",
        "        feature = model(image[None])  # Adicione 'None' ou 'unsqueeze(0)' se necessário\n",
        "        repo_features = torch.cat([repo_features, feature], dim=0)  # Coloque 'feature' dentro de uma lista []\n",
        "    return repo_features\n",
        "\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "def train_one_epoch(model, train_loader, loss_map, optimizer=None, device='cpu', transformations=None,is_training=True):\n",
        "    model.train(is_training) # Set model to training mode\n",
        "    total_loss = 0.\n",
        "    desc=\"Train \" if is_training else \"Test \"\n",
        "    t = tqdm(train_loader, desc=desc)\n",
        "    batch_i = 0\n",
        "    loss_maps = 0.\n",
        "    for batch_image, labels in t:\n",
        "        batch_image = batch_image.to(device)\n",
        "        mask = criar_mascara(batch_image.shape[0],batch_image.shape[-1],30).to(device)\n",
        "        features_key_summary = extract_feat_in_batch(model,batch_image*mask)\n",
        "\n",
        "        batch_t,mask_t,features_key_summary_t = transformations(batch_image,mask,features_key_summary)# transformar orientacoes e pontos\n",
        "        features_key_summary_t2 = extract_feat_in_batch(model,batch_image*mask)# prever os pontos da imagem transformada\n",
        "\n",
        "\n",
        "        loss,mean_diagonal,mean_other = loss_map(features_key_summary_t,features_key_summary_t2,margin = 70)\n",
        "\n",
        "        if is_training:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        t.set_description(\"{} Loss: {:.5f} Mean AP {:.5f} Mean AN {:.5f}\".format(desc,loss,mean_diagonal,mean_other))\n",
        "        del features_key_summary\n",
        "        del batch_t, mask_t, features_key_summary_t\n",
        "        del features_key_summary_t2\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        batch_i += 1\n",
        "    return total_loss/batch_i\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y6iKv51zekwY"
      },
      "outputs": [],
      "source": [
        "from teste_util import *\n",
        "import teste_util as TS\n",
        "\n",
        "# Fixar a semente do Torch para operações específicas\n",
        "fixed_seed()\n",
        "\n",
        "# leitura dos dados\n",
        "trainloader,testloader =read_dataload_flower(120,'./data/datasets')\n",
        "#gerar variacao de transformacoes pespectivas e fotometrica\n",
        "iterator=iter(trainloader)\n",
        "img,labels = next(iterator)\n",
        "params_lists =AugmentationParamsGenerator(6,img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/wagner/.local/lib/python3.11/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
            "  full_mask[mask] = norms.to(torch.uint8)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch_i  123 loss  0.0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_keynet = KeyNet().to(device)\n",
        "optimizer = optim.Adam(model_keynet.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "model_keynet, optimizer, epoch_i, loss =load_checkpoint(model_keynet, optimizer,'./data/models/key_map_ep123.pth')\n",
        "print(\"epoch_i \",epoch_i,\"loss \",loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sWEdgQlekwY",
        "outputId": "bf0f6498-1f6f-404f-a9e1-034c9c47187e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 0.00000 Mean AP 368.70273 Mean AN 460.83902: 100%|██████████| 34/34 [01:36<00:00,  2.83s/it] \n",
            "Test  Loss: 0.00000 Mean AP 484.01651 Mean AN 607.50848: 100%|██████████| 34/34 [00:19<00:00,  1.78it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "salvou no colab\n",
            "Epoch [123/300] - Running Loss: 50.0888, Test Loss: 2.2065, Initial LR: 0.001000, Current LR: 0.000001, Epochs without Improvement: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 73.42487 Mean AP 489.42508 Mean AN 486.00021: 100%|██████████| 34/34 [01:35<00:00,  2.81s/it]\n",
            "Test  Loss: 0.00000 Mean AP 509.62787 Mean AN 603.01770: 100%|██████████| 34/34 [00:18<00:00,  1.79it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "salvou no colab\n",
            "Epoch [124/300] - Running Loss: 45.6186, Test Loss: 2.1177, Initial LR: 0.001000, Current LR: 0.000001, Epochs without Improvement: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 0.00000 Mean AP 185.45985 Mean AN 432.49554: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it] \n",
            "Test  Loss: 0.00000 Mean AP 0.37791 Mean AN 613.02814: 100%|██████████| 34/34 [00:19<00:00,  1.79it/s]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [125/300] - Running Loss: 50.5152, Test Loss: 2.1644, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 49.48193 Mean AP 490.28870 Mean AN 510.80676: 100%|██████████| 34/34 [01:36<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 549.70148 Mean AN 634.41974: 100%|██████████| 34/34 [00:19<00:00,  1.78it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "salvou no colab\n",
            "Epoch [126/300] - Running Loss: 42.8834, Test Loss: 1.3588, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 0.00000 Mean AP 419.08316 Mean AN 494.58664: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it] \n",
            "Test  Loss: 0.00000 Mean AP 428.51410 Mean AN 623.20874: 100%|██████████| 34/34 [00:19<00:00,  1.79it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [127/300] - Running Loss: 55.8459, Test Loss: 2.5851, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 55.76599 Mean AP 501.68317 Mean AN 515.91718: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 474.24973 Mean AN 625.81866: 100%|██████████| 34/34 [00:19<00:00,  1.78it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [128/300] - Running Loss: 56.0079, Test Loss: 3.5710, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 29.41074 Mean AP 433.81363 Mean AN 474.40289: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 497.05484 Mean AN 593.62793: 100%|██████████| 34/34 [00:19<00:00,  1.77it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [129/300] - Running Loss: 52.0010, Test Loss: 2.1608, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 79.89328 Mean AP 475.90814 Mean AN 466.01486: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 507.61780 Mean AN 605.29510: 100%|██████████| 34/34 [00:19<00:00,  1.78it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [130/300] - Running Loss: 49.4787, Test Loss: 2.9484, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 32.35037 Mean AP 446.61401 Mean AN 484.26364: 100%|██████████| 34/34 [01:36<00:00,  2.83s/it]\n",
            "Test  Loss: 0.00000 Mean AP 500.44788 Mean AN 632.70392: 100%|██████████| 34/34 [00:18<00:00,  1.80it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [131/300] - Running Loss: 42.9264, Test Loss: 2.2159, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 73.77142 Mean AP 476.73984 Mean AN 472.96841: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 437.56885 Mean AN 638.14423: 100%|██████████| 34/34 [00:18<00:00,  1.80it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [132/300] - Running Loss: 55.5723, Test Loss: 3.0972, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 52.61282 Mean AP 487.72278 Mean AN 505.10995: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 508.61288 Mean AN 646.93060: 100%|██████████| 34/34 [00:19<00:00,  1.79it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "salvou no colab\n",
            "Epoch [133/300] - Running Loss: 53.2444, Test Loss: 1.3480, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 77.74344 Mean AP 469.51904 Mean AN 461.77560: 100%|██████████| 34/34 [01:36<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 500.16736 Mean AN 610.74304: 100%|██████████| 34/34 [00:19<00:00,  1.78it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [134/300] - Running Loss: 43.2628, Test Loss: 3.0771, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 78.68884 Mean AP 516.16840 Mean AN 507.47955: 100%|██████████| 34/34 [01:35<00:00,  2.81s/it]\n",
            "Test  Loss: 0.00000 Mean AP 214.26366 Mean AN 581.24725: 100%|██████████| 34/34 [00:19<00:00,  1.79it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [135/300] - Running Loss: 37.1238, Test Loss: 3.0458, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 63.62079 Mean AP 537.13281 Mean AN 543.51202: 100%|██████████| 34/34 [01:35<00:00,  2.82s/it]\n",
            "Test  Loss: 0.00000 Mean AP 502.69308 Mean AN 621.47803: 100%|██████████| 34/34 [00:19<00:00,  1.75it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [136/300] - Running Loss: 44.9336, Test Loss: 2.0289, Initial LR: 0.001000, Current LR: 0.000000, Epochs without Improvement: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train  Loss: 82.97330 Mean AP 516.38422 Mean AN 503.41092:  24%|██▎       | 8/34 [00:25<01:23,  3.20s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(best_model)\n\u001b[1;32m     61\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Best Loss: \u001b[39m\u001b[39m{\u001b[39;00mbest_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m train_with_early_stopping(model_keynet\u001b[39m.\u001b[39;49mto(device), trainloader, testloader, loss_fn, optimizer, scheduler, device, transforms, epochs\u001b[39m=\u001b[39;49mepochs, patience\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
            "Cell \u001b[0;32mIn[8], line 37\u001b[0m, in \u001b[0;36mtrain_with_early_stopping\u001b[0;34m(model, trainloader, testloader, criterion_d, optimizer, scheduler, device, transformations, epochs, patience)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m (epoch \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mand\u001b[39;00m (epoch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     34\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m running_loss \u001b[39m=\u001b[39m train_one_epoch(model, trainloader, loss_map\u001b[39m=\u001b[39;49mcriterion_d,  optimizer\u001b[39m=\u001b[39;49moptimizer, device\u001b[39m=\u001b[39;49mdevice, transformations\u001b[39m=\u001b[39;49mtransformations, is_training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     39\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     40\u001b[0m     loss_test \u001b[39m=\u001b[39m train_one_epoch(model, testloader, loss_map\u001b[39m=\u001b[39mcriterion_d,  optimizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, device\u001b[39m=\u001b[39mdevice, transformations\u001b[39m=\u001b[39mtransformations, is_training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_map, optimizer, device, transformations, is_training)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m is_training:\n\u001b[1;32m     54\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 55\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     56\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     58\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "transforms = kornia.augmentation.AugmentationSequential(\n",
        "    kornia.augmentation.RandomAffine(degrees=360, translate=(0.2, 0.2), scale=(0.95, 1.05), shear=10,p=0.8),\n",
        "    kornia.augmentation.RandomPerspective(0.2, p=0.7),\n",
        "    kornia.augmentation.RandomBoxBlur((4,4),p=0.5),\n",
        "    # kornia.augmentation.RandomEqualize(p=0.3),\n",
        "    data_keys=[\"input\",\"input\",\"input\"],\n",
        "    same_on_batch=True,\n",
        "    # random_apply=10,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "epochs=300\n",
        "i_epoch = 0\n",
        "loss = 0\n",
        "\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.75)\n",
        "\n",
        "import torch\n",
        "\n",
        "def train_with_early_stopping(model, trainloader, testloader, criterion_d, optimizer, scheduler, device, transformations, epochs=100, patience=20):\n",
        "    best_loss = float('inf')\n",
        "    best_model = None\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(epoch_i,epochs):\n",
        "        # Atualizar a taxa de aprendizado\n",
        "        if (epoch % 5 == 0) and (epoch != 0):\n",
        "            scheduler.step()\n",
        "            \n",
        "\n",
        "        running_loss = train_one_epoch(model, trainloader, loss_map=criterion_d,  optimizer=optimizer, device=device, transformations=transformations, is_training=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loss_test = train_one_epoch(model, testloader, loss_map=criterion_d,  optimizer=None, device=device, transformations=transformations, is_training=False)\n",
        "\n",
        "        # Verificar se a perda melhorou\n",
        "        if loss_test < best_loss:\n",
        "            best_loss = loss_test\n",
        "            epochs_without_improvement = 0\n",
        "            best_model = model.state_dict()            \n",
        "            save_checkpoint(model=model, epoch=epoch, optimizer=optimizer, loss=loss_test, path='./data/models/key_map_ep{}.pth'.format(epoch))\n",
        "            print(\"salvou no colab\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Verificar a condição de parada\n",
        "        if epochs_without_improvement == patience:\n",
        "            print(f\"No improvement in loss for {epochs_without_improvement} epochs. Training stopped.\")\n",
        "            break\n",
        "\n",
        "        print(f\"Epoch [{epoch}/{epochs}] - Running Loss: {running_loss:.4f}, Test Loss: {loss_test:.4f}, Initial LR: {optimizer.param_groups[0]['initial_lr']:.6f}, Current LR: {optimizer.param_groups[0]['lr']:.6f}, Epochs without Improvement: {epochs_without_improvement}\")\n",
        "\n",
        "    # Carregar a melhor configuração do modelo\n",
        "    model.load_state_dict(best_model)\n",
        "    print(f'Epoch: {epoch}, Best Loss: {best_loss:.4f}')\n",
        "\n",
        "train_with_early_stopping(model_keynet.to(device), trainloader, testloader, loss_fn, optimizer, scheduler, device, transforms, epochs=epochs, patience=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### APOS treinamento a validacao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detector = KeyNetDetector(pretrained=True, num_features=60, keynet_conf=keynet_default_config)\n",
        "detector.to(device).eval()\n",
        "\n",
        "descriptor = kornia.feature.SIFTDescriptor(TS.PS, rootsift=True).to(device)\n",
        "\n",
        "image = torch.rand(1, 1, 128, 128).to(device)  # Imagem de exemplo 128x128 pixels em escala de cinza\n",
        "\n",
        "# Faz a inferência com o modelo\n",
        "with torch.no_grad():\n",
        "    lafs, resps = detector(image)\n",
        "    print(lafs.shape, resps.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEaon7EGMwsH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import kornia\n",
        "from kornia_moons.viz import draw_LAF_matches\n",
        "\n",
        "def detect_and_extract_features(image, detector, descriptor, PS):\n",
        "    with torch.no_grad():\n",
        "        lafs, resps = detector(image[None])\n",
        "        patches = kornia.feature.extract_patches_from_pyramid(image[None], lafs, PS)\n",
        "        B, N, CH, H, W = patches.size()\n",
        "        # print('patches  ',patches.shape,B, N, CH, H, W,resps)\n",
        "        descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
        "\n",
        "        return lafs, descs\n",
        "\n",
        "def detect_extract_feat_in_batch(batch_img, detector, descriptor, PS):\n",
        "    repo_lafs_desc = []\n",
        "    with torch.no_grad():\n",
        "        for image  in batch_img:\n",
        "            try:\n",
        "                lafs, descs = detect_and_extract_features(image, detector, descriptor, PS)\n",
        "                repo_lafs_desc.append((lafs,descs))\n",
        "            except RuntimeError as e:\n",
        "                print(\"erro ao extrair features\")\n",
        "\n",
        "    return repo_lafs_desc\n",
        "\n",
        "def matching_imagens(ref_img,batch_img, repo_lafs_desc,detector, descriptor):\n",
        "    best_match_info = None\n",
        "    best_match_count = 0\n",
        "    best_match_index = None\n",
        "    with torch.no_grad():\n",
        "        # Detectar e extrair características da imagem de referência\n",
        "        lafs_ref, descs_ref = detect_and_extract_features(ref_img, detector, descriptor, TS.PS)\n",
        "\n",
        "        for i, (lafs_i, descs_i) in enumerate(repo_lafs_desc):\n",
        "            # Detectar e extrair características da imagem atual do batch\n",
        "\n",
        "            # matches = bidirectional_match(descs_ref[0], descs_i[0], threshold=0.85)\n",
        "            scores, matches = kornia.feature.match_snn(descs_ref[0], descs_i[0], 0.85) # correspondencia dos descritories a uma distância de 0.9\n",
        "            if matches.shape[0] >= 4:\n",
        "                # Cálculo da homografia\n",
        "                inliers_mask = compute_homography(lafs_ref, lafs_i, matches)\n",
        "\n",
        "                # Check if this match is better than the previous best match\n",
        "                if matches.shape[0] > best_match_count:\n",
        "                    best_match_info = (lafs_ref[0][None].cpu(), lafs_i[0][None].cpu(), matches.cpu(),\n",
        "                                       kornia.tensor_to_image(ref_img.cpu()), kornia.tensor_to_image(batch_img[i].cpu()),\n",
        "                                       inliers_mask)\n",
        "                    best_match_count = matches.shape[0]\n",
        "                    best_match_index = i\n",
        "        if best_match_info is not None and best_match_index==0:# TODO: Remove this condition best_match_index==0\n",
        "            # Plot the best match\n",
        "\n",
        "            draw_LAF_matches(\n",
        "                *best_match_info,\n",
        "                draw_dict={\"inlier_color\": (0.2, 1, 0.2), \"tentative_color\": (1, 1, 0.2, 0.3), \"feature_color\": None, \"vertical\": False},\n",
        "            )\n",
        "        # else:\n",
        "        #     print(\"No matches found with enough inliers.\")\n",
        "    return best_match_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AUaOBVrNlq-"
      },
      "outputs": [],
      "source": [
        "params_lists.aug_list.data_keys =[\"input\"]\n",
        "aug_list = params_lists.aug_list\n",
        "\n",
        "acertos = 0\n",
        "total = 0\n",
        "from tqdm.notebook import tqdm\n",
        "pbar =  tqdm(testloader)\n",
        "for imgs_batch,labels_batch in pbar:# itera em todo dataset\n",
        "    imgs_batch = imgs_batch.to(device)\n",
        "\n",
        "    params_item = next(params_lists)\n",
        "    timg_gray_t = aug_list(imgs_batch,params=params_item)\n",
        "    plt.show()\n",
        "    repo_lafs_desc= detect_extract_feat_in_batch(timg_gray_t,detector,descriptor,PS)\n",
        "\n",
        "    for i,img_gray in enumerate(imgs_batch):# itera em cada batch\n",
        "\n",
        "        match_index = matching_imagens(img_gray,timg_gray_t,repo_lafs_desc,detector, descriptor)\n",
        "\n",
        "        total+=1\n",
        "        if match_index == i:\n",
        "            acertos += 1\n",
        "        pbar.set_description(f\"acertos/total: {acertos}/{total}  \")\n",
        "print(\"acertos: \",acertos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    loss_test = train_one_epoch(detector.model, testloader, loss_map=loss_fn,  optimizer=None, device=device, transformations=transforms, is_training=False)\n",
        "    print(f\"Test loss: {loss_test:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

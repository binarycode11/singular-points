{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    logger = logging.getLogger(\"Utils\")\n",
    "    logger.debug(f\"Setting seed to {seed}\")\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def check_and_clear_memory():\n",
    "    logger = logging.getLogger(\"Utils\")\n",
    "    logger.debug(f'Memória alocada antes da limpeza: {torch.cuda.memory_allocated()} bytes')\n",
    "    logger.debug(f'Memória reservada antes da limpeza: {torch.cuda.memory_reserved()} bytes')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    logger.debug(f'Memória alocada após limpeza: {torch.cuda.memory_allocated()} bytes')\n",
    "    logger.debug(f'Memória reservada após limpeza: {torch.cuda.memory_reserved()} bytes')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia\n",
    "from kornia.feature import LocalFeature, LAFDescriptor, MultiResolutionDetector,SOSNet\n",
    "from kornia.feature import CornerGFTT, PassLAF, LAFOrienter, LAFAffNetShapeEstimator\n",
    "from kornia.feature.scale_space_detector import get_default_detector_config\n",
    "from kornia.feature.keynet import KeyNetDetector\n",
    "from kornia.feature.keynet import keynet_default_config\n",
    "\n",
    "from external.REKD import REKD\n",
    "from teste_util import CustomNetDetector\n",
    "\n",
    "class GFTTFeatureSosNet(LocalFeature): #0.9    |   0.005\n",
    "    \"\"\"Convenience module, which implements GFTT detector + SOSNet descriptor.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 200,\n",
    "        upright: bool = False,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        config: dict = None,\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = get_default_detector_config()\n",
    "        detector = MultiResolutionDetector(\n",
    "            CornerGFTT(),\n",
    "            num_features,\n",
    "            config,\n",
    "            ori_module=PassLAF() if upright else LAFOrienter(19),\n",
    "            aff_module=LAFAffNetShapeEstimator(preserve_orientation=upright).eval(),  # Usa `upright` para definir `preserve_orientation`\n",
    "        ).to(device)\n",
    "\n",
    "        # Initialize your descriptor (e.g., SOSNet) as before\n",
    "        # Example with SOSNet - replace with actual initialization if different\n",
    "        sosnet32 = SOSNet(pretrained=True)  # Placeholder; adjust according to actual SOSNet import\n",
    "        sosnet32 = sosnet32.to(device).eval()\n",
    "\n",
    "        descriptor = LAFDescriptor(sosnet32, patch_size=32, grayscale_descriptor=True).to(device)\n",
    "\n",
    "        super().__init__(detector, descriptor)\n",
    "\n",
    "\n",
    "\n",
    "class KeyNetFeatureSosNet(LocalFeature):\n",
    "    \"\"\"Convenience module that combines KeyNet detector + SOSNet descriptor.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 200,\n",
    "        upright: bool = False,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        config: dict = None,\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = config or {\n",
    "                    'num_filters': 8,\n",
    "                    'num_levels': 3,\n",
    "                    'kernel_size': 5,\n",
    "                    'Detector_conf': {'nms_size': 5, 'pyramid_levels': 2, 'up_levels': 2, 'scale_factor_levels': 1.3, 's_mult': 12.0},\n",
    "            }\n",
    "        # Initialize KeyNet detector\n",
    "        detector = KeyNetDetector(\n",
    "            pretrained=True,\n",
    "            num_features=num_features,\n",
    "            ori_module=PassLAF() if upright else LAFOrienter(32),\n",
    "            aff_module=LAFAffNetShapeEstimator(preserve_orientation=upright).eval(),\n",
    "            keynet_conf=config,\n",
    "        ).to(device).eval()\n",
    "\n",
    "        # Initialize SOSNet descriptor\n",
    "        sosnet32 = SOSNet(pretrained=True).to(device).eval()        \n",
    "        descriptor = LAFDescriptor(sosnet32, patch_size=32, grayscale_descriptor=True).to(device).eval()\n",
    "\n",
    "        # Call the parent constructor\n",
    "        super().__init__(detector, descriptor)\n",
    "\n",
    "class KeyNetFeatureSIFT(LocalFeature):\n",
    "    \"\"\"Convenience module that combines KeyNet detector + SIFT descriptor.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 200,\n",
    "        upright: bool = False,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        config: dict = None,\n",
    "    ) -> None:\n",
    "        if config is None:\n",
    "            config = config or {\n",
    "                    'num_filters': 8,\n",
    "                    'num_levels': 3,\n",
    "                    'kernel_size': 5,\n",
    "                    'Detector_conf': {'nms_size': 5, 'pyramid_levels': 2, 'up_levels': 2, 'scale_factor_levels': 1.3, 's_mult': 12.0},\n",
    "            }\n",
    "             \n",
    "        # Initialize KeyNet detector\n",
    "        detector = KeyNetDetector(\n",
    "            pretrained=True,\n",
    "            num_features=num_features,\n",
    "            ori_module=PassLAF() if upright else LAFOrienter(32),\n",
    "            aff_module=LAFAffNetShapeEstimator(preserve_orientation=upright).eval(),\n",
    "            keynet_conf=config,\n",
    "        ).to(device).eval()\n",
    "\n",
    "        patch_size = 13   \n",
    "        # Initialize SIFT descriptor\n",
    "        sift_descriptor = kornia.feature.SIFTDescriptor(patch_size=patch_size, rootsift=True).to(device)\n",
    "\n",
    "        descriptor = LAFDescriptor(sift_descriptor, patch_size=patch_size, grayscale_descriptor=True).to(device)\n",
    "\n",
    "        # Call the parent constructor\n",
    "        super().__init__(detector, descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from kornia.feature import SOSNet, MultiResolutionDetector, LAFDescriptor, LAFOrienter, LocalFeature\n",
    "from external.REKD import REKD\n",
    "from config import get_config_rekd\n",
    "\n",
    "class REKDSosNet(LocalFeature):\n",
    "    \"\"\"Combina REKD detector e SOSNet descriptor\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 200,\n",
    "        upright: bool = False,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        config: dict = None,\n",
    "    ) -> None:\n",
    "        super().__init__(detector=None, descriptor=None)\n",
    "        self.device = device\n",
    "        self.config = config or {\n",
    "            'num_filters': 8,\n",
    "            'num_levels': 3,\n",
    "            'kernel_size': 5,\n",
    "            'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.3, 's_mult': 12.0},\n",
    "        }\n",
    "        args = get_config_rekd(jupyter=True)\n",
    "        args.load_dir = 'trained_models/release_group36_f2_s2_t2.log/best_model.pt'\n",
    "        self.detector = self._initialize_detector(num_features,args)\n",
    "        self.descriptor = self._initialize_descriptor()\n",
    "\n",
    "    def _initialize_detector(self,num_features,args):\n",
    "        \"\"\"Cria o detector REKD\"\"\"\n",
    "        class REKDetector(nn.Module):\n",
    "            def __init__(self, args, device: torch.device) -> None:\n",
    "                super().__init__()\n",
    "                self.model = REKD(args, device).to(device).eval()\n",
    "                self.model.load_state_dict(torch.load(args.load_dir, weights_only=False))\n",
    "\n",
    "            def forward(self, x: Tensor) -> Tensor:\n",
    "                return self.model(x)[0]  # Apenas as chaves detectadas\n",
    "\n",
    "        return MultiResolutionDetector(REKDetector(args, self.device), num_features=num_features,config=self.config[\"Detector_conf\"], \n",
    "                                       ori_module=LAFOrienter(19)).to(self.device)\n",
    "\n",
    "    def _initialize_descriptor(self) -> LAFDescriptor:\n",
    "        \"\"\"Cria o descritor SOSNet\"\"\"\n",
    "        return LAFDescriptor(SOSNet(pretrained=True).to(self.device).eval(), patch_size=32, grayscale_descriptor=True).to(self.device)\n",
    "\n",
    "    # def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "    #     \"\"\"Detecta e descreve pontos-chave\"\"\"\n",
    "    #     lafs, responses = self.detector(img)\n",
    "    #     return lafs, responses, self.descriptor(img, lafs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from kornia.feature import SOSNet, MultiResolutionDetector, LAFDescriptor, LAFOrienter, LocalFeature\n",
    "from config import get_config_singular\n",
    "from best.singular_point import SingularPoints\n",
    "\n",
    "class SingularPointSosNet(LocalFeature):\n",
    "    def __init__(        self,\n",
    "        num_features: int = 200,\n",
    "        upright: bool = False,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        config: dict = None\n",
    "        ) -> None:\n",
    "        super().__init__(detector=None, descriptor=None)\n",
    "        self.device = device\n",
    "        self.config = config or {\n",
    "            'num_filters': 8,\n",
    "            'num_levels': 3,\n",
    "            'kernel_size': 5,\n",
    "            'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.3, 's_mult': 12.0},\n",
    "        }\n",
    "\n",
    "        args = get_config_singular(jupyter=True)\n",
    "        args.num_channels = 1\n",
    "        args.load_dir = './data/models/sp_map_fo_30.pth'\n",
    "\n",
    "        self.detector = self._initialize_detector(num_features,args)\n",
    "        self.descriptor = self._initialize_descriptor()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _initialize_detector(self,num_features, args):\n",
    "        \"\"\"Cria o detector REKD\"\"\"\n",
    "        class SingularPointDetector(nn.Module):\n",
    "            \n",
    "            def __init__(self,args) -> None:\n",
    "                super().__init__()\n",
    "                self.model = SingularPoints(args)\n",
    "                self.model.load_state_dict(torch.load(args.load_dir, weights_only=False))\n",
    "\n",
    "            def forward(self, x):\n",
    "                features_key,features_key_summary,features_ori,features_ori_summary,max_coords_values, max_map= self.model(x)\n",
    "                return features_key_summary\n",
    "\n",
    "        return MultiResolutionDetector(SingularPointDetector(args), num_features = num_features,config = self.config[\"Detector_conf\"], \n",
    "                                       ori_module=LAFOrienter(19))\n",
    "\n",
    "    def _initialize_descriptor(self) -> LAFDescriptor:\n",
    "        \"\"\"Cria o descritor SOSNet\"\"\"\n",
    "        return LAFDescriptor(SOSNet(pretrained=True), patch_size=32, grayscale_descriptor=True).to(self.device)\n",
    "\n",
    "    # def forward(self, img: Tensor, mask: Optional[Tensor] = None) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "    #     \"\"\"Detecta e descreve pontos-chave\"\"\"\n",
    "    #     lafs, responses = self.detector(img)\n",
    "    #     return lafs, responses, self.descriptor(img, lafs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import kornia\n",
    "from kornia.feature import DescriptorMatcher\n",
    "\n",
    "class LocalComparisonPipeline:\n",
    "    \"\"\"\n",
    "    Compara imagens de inspeção e referência usando características locais e correspondência de descritores.\n",
    "    \"\"\"\n",
    "    def __init__(self, local_feature, descriptor_matcher):\n",
    "        self.local_feature = local_feature\n",
    "        self.descriptor_matcher = descriptor_matcher\n",
    "\n",
    "    def run(self, inspection_images: torch.Tensor, reference_images: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compara imagens de inspeção e referência e retorna uma matriz de pontuação baseada em correspondências de descritores.\n",
    "        \"\"\"\n",
    "        n, m = inspection_images.shape[0], reference_images.shape[0]\n",
    "        scores = np.zeros((n, m))\n",
    "        cache_reference = {}\n",
    "\n",
    "        for i_index, i_image in enumerate(inspection_images):\n",
    "            lafs0, _, descriptors0 = self.local_feature(i_image[:1][None])\n",
    "\n",
    "            for r_index, r_image in enumerate(reference_images):\n",
    "                if r_index not in cache_reference:\n",
    "                    _, _, descriptors1 = self.local_feature(r_image[:1][None])\n",
    "                    cache_reference[r_index] = descriptors1\n",
    "                descriptors1 = cache_reference[r_index]\n",
    "\n",
    "                _, matches = self.descriptor_matcher(descriptors0[0], descriptors1[0])\n",
    "\n",
    "                num_match = matches.shape[0]\n",
    "                scores[i_index, r_index] = num_match if num_match >= 3 else 0\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def evaluate_matches(self, matches_matrix, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Avalia correspondências entre imagens e calcula TP, FP e FN com base no limiar de similaridade.\n",
    "        \"\"\"\n",
    "        n, m = matches_matrix.shape\n",
    "        TP, FP, FN = 0, 0, 0\n",
    "\n",
    "        for i in range(m):\n",
    "            if np.max(matches_matrix[i]) >= threshold and np.argmax(matches_matrix[i]) == i:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "\n",
    "        for i in range(m, n):\n",
    "            if np.max(matches_matrix[i]) >= threshold and np.argmax(matches_matrix[i]) < m:\n",
    "                FP += 1\n",
    "\n",
    "        return TP, FP, FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationGenerator:\n",
    "    def __init__(self, n_variations):\n",
    "        # Definir as augmentações\n",
    "        aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "            kornia.augmentation.RandomAffine(degrees=360, translate=(0.25, 0.25), scale=(0.95, 1.05), shear=10, p=0.85),\n",
    "            kornia.augmentation.RandomPerspective(0.3, p=0.85),\n",
    "            kornia.augmentation.RandomBoxBlur((3, 3), p=0.85),\n",
    "            data_keys=[\"input\"],\n",
    "            same_on_batch=True,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.augmentation_sequence = aug_gen\n",
    "        self.n_variations = n_variations\n",
    "        self.param_list = []\n",
    "        self.current_index = 0\n",
    "\n",
    "    def generate_variations(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Gera múltiplas variações de augmentações e coleta seus parâmetros.\n",
    "        \"\"\"\n",
    "        for _ in range(self.n_variations):\n",
    "            self.augmentation_sequence(input_tensor)            \n",
    "            self.param_list.append(self.augmentation_sequence._params)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current_index = 0  # Resetar o índice a cada nova iteração\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"\n",
    "        Retorna a próxima variação de parâmetros de augmentação.\n",
    "        A iteração será circular.\n",
    "        \"\"\"\n",
    "        result = self.param_list[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.param_list)\n",
    "        return result\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Método para resetar o estado do gerador de augmentação.\"\"\"\n",
    "        self.current_index = 0  # Reseta o índice de iteração\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Main:Dispositivo: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 5\n",
      "INFO:Main:TP: 1354, FP: 3036, FN: 1682\n",
      "INFO:Main:Precisão: 0.31, Recall: 0.45, F1-score: 0.36\n",
      "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 5\n",
      "INFO:Main:TP: 1549, FP: 1269, FN: 1487\n",
      "INFO:Main:Precisão: 0.55, Recall: 0.51, F1-score: 0.53\n",
      "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import kornia as K\n",
    "import logging\n",
    "from itertools import product\n",
    "from teste_util import read_dataload_woods,read_dataload_fibers,read_dataload_flower\n",
    "from utils.TensorImgIO import imshow_points\n",
    "from kornia.feature import LocalFeature\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Logger específico\n",
    "logger = logging.getLogger(\"Main\")  # Logger para a execução principal\n",
    "logger.setLevel(logging.INFO)  # Define o nível de log como INFO\n",
    "\n",
    "# Definição do grid de parâmetros\n",
    "param_grid = {\n",
    "    'num_features': [60],  # Número de características\n",
    "    'feature_local': [KeyNetFeatureSIFT,KeyNetFeatureSosNet,REKDSosNet,SingularPointSosNet],  # Diversos detectores de características\n",
    "    'distance': [0.90],  # Distância para a correspondência (padrão 0.8)\n",
    "    'threshold': [5]  # Limite para correspondência\n",
    "}\n",
    "\n",
    "# Função para configurar o detector e executar o código para uma combinação de parâmetros\n",
    "def run_experiment(dataloader, pipeline,threshold,aug_gen):\n",
    "    TP_total, FP_total, FN_total = 0, 0, 0  # Inicializa os contadores totais de TP, FP e FN\n",
    "\n",
    "    for inspection_batch, _ in dataloader:\n",
    "        inspection_batch = inspection_batch.to(device)        \n",
    "        params_item = next(aug_gen)\n",
    "        reference_batch_t =aug_gen.augmentation_sequence(inspection_batch,params=params_item)\n",
    "        # Pega apenas a metade inicial de reference_batch_t\n",
    "        half_reference_batch = reference_batch_t[:reference_batch_t.shape[0] // 2]\n",
    "        logger.debug(f\"Lote inspecao: {inspection_batch.shape} Lote referencia {half_reference_batch.shape}\")\n",
    "\n",
    "        # Executa o pipeline de detecção de características\n",
    "        with torch.no_grad():\n",
    "            scores = pipeline.run(inspection_batch, half_reference_batch)\n",
    "            TP, FP, FN = pipeline.evaluate_matches(scores,threshold=threshold)\n",
    "\n",
    "            # Acumula os resultados de TP, FP e FN\n",
    "            TP_total += TP\n",
    "            FP_total += FP\n",
    "            FN_total += FN\n",
    "            \n",
    "            logger.debug(f\"TP: {TP}, FP: {FP}, FN: {FN}\")\n",
    "    \n",
    "    # Exibe os resultados totais de TP, FP e FN após o experimento\n",
    "    logger.debug(f\"Total de TP: {TP_total}, FP: {FP_total}, FN: {FN_total}\")\n",
    "    return TP_total, FP_total, FN_total\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    set_seed(42)\n",
    "    # Inicializa o dispositivo (GPU ou CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Dispositivo: {device}\")\n",
    "    # \n",
    "    # args = get_config_singular(jupyter=True)\n",
    "\n",
    "    # trainloader, testloader = read_dataload_woods(120,batch_size=132)\n",
    "    trainloader, testloader = read_dataload_flower(120,batch_size=132)\n",
    "    # trainloader, testloader = read_dataload_fibers(120,batch_size=132)\n",
    "    # gerar variacao de transformacoes pespectivas e fotometrica\n",
    "    iterator = iter(testloader)\n",
    "    img, labels = next(iterator)\n",
    "    aug_gen = AugmentationGenerator(10)\n",
    "    aug_gen.generate_variations(img)\n",
    "\n",
    "    # Itera entre todas as combinações de parâmetros\n",
    "    for num_features, feature_local_class, distance, threshold in product(*param_grid.values()):\n",
    "        logger.info(f\"Executando experimento com: {num_features} características, \"\n",
    "            f\"detector {feature_local_class.__name__}, \"\n",
    "            f\"distância {distance}, e limiar {threshold}\")\n",
    "        set_seed(1)\n",
    "    \n",
    "        # Executa o pipeline de detecção de características\n",
    "        with torch.no_grad():\n",
    "            # Inicializa o detector com a configuração\n",
    "            local_feature = feature_local_class(num_features=num_features, device=device).to(device).eval()\n",
    "            descriptor_matcher = DescriptorMatcher(match_mode=\"snn\", th=distance).to(device).eval()  # Usando o matcher SNN\n",
    "            pipeline = LocalComparisonPipeline(local_feature=local_feature, descriptor_matcher=descriptor_matcher)\n",
    "        \n",
    "            # Executa o experimento e retorna os totais de TP, FP e FN\n",
    "            TP_total, FP_total, FN_total = run_experiment(testloader, pipeline,threshold, aug_gen)\n",
    "            aug_gen.reset()# //TODO: reiniciar o gerador de transformacoes\n",
    "            # //FIXME: o TP_total e FN_total devem ser 0\n",
    "            check_and_clear_memory()\n",
    "            # Calcula a precisão, recall e F1-score\n",
    "            precision = TP_total / (TP_total + FP_total) if (TP_total + FP_total) > 0 else 0\n",
    "            recall = TP_total / (TP_total + FN_total) if (TP_total + FN_total) > 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            logger.info(f\"TP: {TP_total}, FP: {FP_total}, FN: {FN_total}\")\n",
    "            logger.info(f\"Precisão: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.3, 's_mult': 12.0},\n",
    "aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "    kornia.augmentation.RandomAffine(degrees=360, translate=(0.25, 0.25), scale=(0.95, 1.05), shear=10, p=0.8),\n",
    "    kornia.augmentation.RandomPerspective(0.3, p=0.7),\n",
    "    kornia.augmentation.RandomBoxBlur((3, 3), p=0.7),\n",
    "    data_keys=[\"input\"],\n",
    "    same_on_batch=True,\n",
    ")\n",
    "\n",
    "FLOWERS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 712, FP: 0, FN: 308\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.70, F1-score: 0.82\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 1002, FP: 0, FN: 18\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.98, F1-score: 0.99\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 1013, FP: 0, FN: 7\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.99, F1-score: 1.00\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 1020, FP: 0, FN: 0\n",
    "INFO:Main:Precisão: 1.00, Recall: 1.00, F1-score: 1.00\n",
    "\n",
    "\n",
    "------------------------------------------------\n",
    "'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.3, 's_mult': 12.0},\n",
    "aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "    kornia.augmentation.RandomAffine(degrees=360, translate=(0.25, 0.25), scale=(0.95, 1.05), shear=10, p=0.85),\n",
    "    kornia.augmentation.RandomPerspective(0.3, p=0.85),\n",
    "    kornia.augmentation.RandomBoxBlur((3, 3), p=0.85),\n",
    "    data_keys=[\"input\"],\n",
    "    same_on_batch=True,\n",
    ")\n",
    "FLOWERS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 690, FP: 0, FN: 330\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.68, F1-score: 0.81\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 983, FP: 0, FN: 37\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.96, F1-score: 0.98\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 1011, FP: 0, FN: 9\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.99, F1-score: 1.00\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 1020, FP: 0, FN: 0\n",
    "INFO:Main:Precisão: 1.00, Recall: 1.00, F1-score: 1.00\n",
    "\n",
    "------------------------------------------------\n",
    "'Detector_conf': {'nms_size': 5, 'pyramid_levels': 2, 'up_levels': 2, 'scale_factor_levels': 1.3, 's_mult': 12.0},#KeyNetFeatureSIFT,KeyNetFeatureSosNet\n",
    "'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.3, 's_mult': 12.0},#REKD e SingularPointsDetector\n",
    "aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "    kornia.augmentation.RandomAffine(degrees=360, translate=(0.25, 0.25), scale=(0.95, 1.05), shear=10, p=0.85),\n",
    "    kornia.augmentation.RandomPerspective(0.3, p=0.85),\n",
    "    kornia.augmentation.RandomBoxBlur((4, 4), p=0.85),\n",
    "    data_keys=[\"input\"],\n",
    "    same_on_batch=True,\n",
    ")\n",
    "\n",
    "WOODS\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 31, FP: 0, FN: 465\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.06, F1-score: 0.12\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 115, FP: 0, FN: 381\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.23, F1-score: 0.38\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 246, FP: 0, FN: 250\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.50, F1-score: 0.66\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 387, FP: 0, FN: 109\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.78, F1-score: 0.88\n",
    "\n",
    "FIBERS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 34, FP: 0, FN: 186\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.15, F1-score: 0.27\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 8, FP: 0, FN: 212\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.04, F1-score: 0.07\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 4, FP: 0, FN: 216\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.02, F1-score: 0.04\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 111, FP: 0, FN: 109\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.50, F1-score: 0.67\n",
    "\n",
    "FLOWERS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 390, FP: 0, FN: 630\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.38, F1-score: 0.55\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 513, FP: 0, FN: 507\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.50, F1-score: 0.67\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 990, FP: 0, FN: 30\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.97, F1-score: 0.99\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 0.5\n",
    "INFO:Main:TP: 1009, FP: 0, FN: 11\n",
    "INFO:Main:Precisão: 1.00, Recall: 0.99, F1-score: 0.99\n",
    "\n",
    "------------------------------------------------\n",
    "aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "    kornia.augmentation.RandomAffine(degrees=360, translate=(0.25, 0.25), scale=(0.95, 1.05), shear=10, p=0.85),\n",
    "    kornia.augmentation.RandomPerspective(0.3, p=0.85),\n",
    "    kornia.augmentation.RandomBoxBlur((3, 3), p=0.85),\n",
    "    data_keys=[\"input\"],\n",
    "    same_on_batch=True,\n",
    ")\n",
    "\n",
    "\n",
    "FLOWERS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 259, FP: 510, FN: 251\n",
    "INFO:Main:Precisão: 0.34, Recall: 0.51, F1-score: 0.41\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 293, FP: 122, FN: 217\n",
    "INFO:Main:Precisão: 0.71, Recall: 0.57, F1-score: 0.63\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 506, FP: 171, FN: 4\n",
    "INFO:Main:Precisão: 0.75, Recall: 0.99, F1-score: 0.85\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 510, FP: 165, FN: 0\n",
    "INFO:Main:Precisão: 0.76, Recall: 1.00, F1-score: 0.86\n",
    "\n",
    "\n",
    "WOODS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 14, FP: 330, FN: 311\n",
    "INFO:Main:Precisão: 0.04, Recall: 0.04, F1-score: 0.04\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 124, FP: 151, FN: 201\n",
    "INFO:Main:Precisão: 0.45, Recall: 0.38, F1-score: 0.41\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 176, FP: 191, FN: 149\n",
    "INFO:Main:Precisão: 0.48, Recall: 0.54, F1-score: 0.51\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 292, FP: 50, FN: 33\n",
    "INFO:Main:Precisão: 0.85, Recall: 0.90, F1-score: 0.88\n",
    "\n",
    "FIBERS\n",
    "\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSIFT, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 25, FP: 198, FN: 173\n",
    "INFO:Main:Precisão: 0.11, Recall: 0.13, F1-score: 0.12\n",
    "INFO:Main:Executando experimento com: 60 características, detector KeyNetFeatureSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 8, FP: 198, FN: 190\n",
    "INFO:Main:Precisão: 0.04, Recall: 0.04, F1-score: 0.04\n",
    "INFO:Main:Executando experimento com: 60 características, detector REKDSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 2, FP: 21, FN: 196\n",
    "INFO:Main:Precisão: 0.09, Recall: 0.01, F1-score: 0.02\n",
    "INFO:Main:Executando experimento com: 60 características, detector SingularPointSosNet, distância 0.9, e limiar 5\n",
    "INFO:Main:TP: 122, FP: 56, FN: 76\n",
    "INFO:Main:Precisão: 0.69, Recall: 0.62, F1-score: 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definindo o valor do limiar\n",
    "threshold = 1.0\n",
    "\n",
    "# Matriz de similaridade (5x5)\n",
    "matches_matrix = np.array([\n",
    "    [5.0, 0.2, 0.3, 0.0, 0.0],  # Linha 0 (correspondência correta com o próprio item)\n",
    "    [0.1, 3.0, 0.4, 0.0, 0.0],  # Linha 1 (correspondência correta com o próprio item)\n",
    "    [0.2, 0.3, 3.0, 0.0, 0.0],  # Linha 2 (correspondência correta com o próprio item)\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],  # Linha 3 (nenhuma correspondência correta)\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0],   # Linha 4 (nenhuma correspondência correta)\n",
    "    [0.0, 3.0, 0.0, 0.0, 0.0],  # Linha 5 (nenhuma correspondência correta)\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0]   # Linha 7 (nenhuma correspondência correta)\n",
    "])\n",
    "\n",
    "\n",
    "# Testando a função\n",
    "class Evaluator:\n",
    "    def evaluate_matches(self, matches_matrix, threshold=0.5):\n",
    "        n, m = matches_matrix.shape\n",
    "        TP, FP, FN = 0, 0, 0\n",
    "\n",
    "        for i in range(m):\n",
    "            if np.max(matches_matrix[i]) >= threshold and np.argmax(matches_matrix[i]) == i:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "\n",
    "        for i in range(m, n):\n",
    "            if np.max(matches_matrix[i]) >= threshold and np.argmax(matches_matrix[i]) < m:\n",
    "                FP += 1\n",
    "\n",
    "        return TP, FP, FN\n",
    "\n",
    "# Instanciando o avaliador e chamando a função\n",
    "evaluator = Evaluator()\n",
    "TP, FP, FN = evaluator.evaluate_matches(matches_matrix, threshold)\n",
    "\n",
    "# Resultado\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singular-points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

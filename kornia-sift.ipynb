{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingular_point\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mteste_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import best.singular_point as sp\n",
    "from teste_util import *\n",
    "import teste_util as TS\n",
    "\n",
    "# Fixar a semente do Torch para operações específicas\n",
    "fixed_seed()\n",
    "\n",
    "# leitura dos dados\n",
    "trainloader,testloader =read_dataload_flower(sp.args.img_size,'./data/datasets')\n",
    "iterator=iter(testloader)\n",
    "img,labels = next(iterator)\n",
    "print(img.shape,labels.shape)\n",
    "\n",
    "# Carregar o modelo singular points\n",
    "path_siamese = './data/models/sp_map_fo_30.pth'\n",
    "sp.args.num_channels = 1\n",
    "model = sp.SingularPoints(args=sp.args).to(sp.device)\n",
    "load_model(model,path_siamese,sp.device)\n",
    "\n",
    "#gerar variacao de transformacoes pespectivas e fotometrica\n",
    "params_lists =AugmentationParamsGenerator(6,img.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo de detecção e correspondencia com kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.feature import *\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda:0')\n",
    "PS = 19 # patch size\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift\n",
    "resp = BlobHessian()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(1, 1.3, PS, double_image=True)\n",
    "print('scale_pyr ',scale_pyr)\n",
    "nms = kornia.geometry.ConvQuadInterp3d(15)\n",
    "n_features = 60\n",
    "\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(PS),\n",
    "                              minima_are_also_good=True,\n",
    "                              mr_size=6.0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_extract_features(image, detector, descriptor, PS):\n",
    "    with torch.no_grad():\n",
    "        lafs, resps = detector(image[None])\n",
    "        # print('lafs ',lafs.shape,' resps ',resps.shape,' image ',image[None].shape)\n",
    "        patches = kornia.feature.extract_patches_from_pyramid(image[None], lafs, PS)\n",
    "        B, N, CH, H, W = patches.size()\n",
    "        descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "        return lafs, descs\n",
    "    \n",
    "def detect_extract_feat_in_batch(batch_img, detector, descriptor, PS):\n",
    "    repo_lafs_desc = []\n",
    "    with torch.no_grad():\n",
    "        for image  in batch_img:            \n",
    "            lafs, resps = detector(image[None])\n",
    "            patches = kornia.feature.extract_patches_from_pyramid(image[None], lafs, PS)\n",
    "\n",
    "            B, N, CH, H, W = patches.size()\n",
    "            print(\"detect_extract_feat_in_batch \",B, N, CH, H, W,patches.view(B * N, CH, H, W).shape)\n",
    "            \n",
    "            descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "            repo_lafs_desc.append((lafs,descs))\n",
    "            \n",
    "    return repo_lafs_desc\n",
    "\n",
    "def matching_imagens(ref_img,batch_img, repo_lafs_desc):\n",
    "    best_match_info = None\n",
    "    best_match_count = 0\n",
    "    best_match_index = None\n",
    "    with torch.no_grad():\n",
    "        # Detectar e extrair características da imagem de referência\n",
    "        lafs_ref, descs_ref = detect_and_extract_features(ref_img, detector, descriptor, PS)\n",
    "        \n",
    "        for i, (lafs_i, descs_i) in enumerate(repo_lafs_desc):\n",
    "            # Detectar e extrair características da imagem atual do batch\n",
    "            # lafs_i, descs_i = detect_and_extract_features(img, detector, descriptor, PS)\n",
    "            # Comparar as características da imagem de referência com a imagem atual do batch\n",
    "            scores, matches = kornia.feature.match_snn(descs_ref[0], descs_i[0], 0.85) # correspondencia dos descritories a uma distância de 0.9\n",
    "\n",
    "            if matches.shape[0] >= 4:\n",
    "                # Cálculo da homografia\n",
    "                inliers_mask = compute_homography(lafs_ref, lafs_i, matches)\n",
    "                # print(lafs_ref[0][None].shape, lafs_ref[0].shape, matches.shape, inliers_mask.shape)\n",
    "\n",
    "                # Check if this match is better than the previous best match\n",
    "                if matches.shape[0] > best_match_count:\n",
    "                    best_match_info = (lafs_ref[0][None].cpu(), lafs_i[0][None].cpu(), matches.cpu(),\n",
    "                                       kornia.tensor_to_image(ref_img.cpu()), kornia.tensor_to_image(batch_img[i].cpu()),\n",
    "                                       inliers_mask)\n",
    "                    best_match_count = matches.shape[0]\n",
    "                    best_match_index = i\n",
    "\n",
    "        if best_match_info is not None and best_match_index==0:# TODO: Remove this condition best_match_index==0\n",
    "            # Plot the best match\n",
    "            from kornia_moons.viz import draw_LAF_matches\n",
    "\n",
    "            draw_LAF_matches(\n",
    "                *best_match_info,\n",
    "                draw_dict={\"inlier_color\": (0.2, 1, 0.2), \"tentative_color\": (1, 1, 0.2, 0.3), \"feature_color\": None, \"vertical\": False},\n",
    "            )\n",
    "        # else:\n",
    "        #     print(\"No matches found with enough inliers.\")\n",
    "    return best_match_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lists.aug_list.data_keys =[\"input\"]\n",
    "aug_list = params_lists.aug_list\n",
    "\n",
    "acertos = 0\n",
    "total = 0\n",
    "from tqdm.notebook import tqdm\n",
    "pbar =  tqdm(testloader)\n",
    "for imgs_batch,labels_batch in pbar:# itera em todo dataset\n",
    "    imgs_batch = imgs_batch.to(sp.device)\n",
    "    \n",
    "    params_item = next(params_lists)\n",
    "    timg_gray_t = aug_list(imgs_batch,params=params_item)\n",
    "    repo_lafs_desc= detect_extract_feat_in_batch(timg_gray_t,detector,descriptor,TS.PS)\n",
    "        \n",
    "    for i,img_gray in enumerate(imgs_batch):# itera em cada batch\n",
    "\n",
    "        match_index = matching_imagens(img_gray,timg_gray_t,repo_lafs_desc)\n",
    "        # print(\"match_index: \",match_index,\" i: \",i)\n",
    "        total+=1\n",
    "        if match_index == i:\n",
    "            acertos += 1\n",
    "        pbar.set_description(f\"acertos/total: {acertos}/{total}  \")\n",
    "print(\"acertos: \",acertos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

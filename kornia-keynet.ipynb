{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "# Fixar a semente do Torch para operações específicas\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kornia\n",
    "from kornia.feature.scale_space_detector import get_default_detector_config, MultiResolutionDetector\n",
    "from kornia.feature.keynet import KeyNetDetector\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "PS = 19 # patch size\n",
    "keynet_default_config = {\n",
    "    'num_filters': 8,\n",
    "    'num_levels': 3,\n",
    "    'kernel_size': 5,\n",
    "    'Detector_conf': {'nms_size': 15, 'pyramid_levels': 1, 'up_levels': 1, 'scale_factor_levels': 1.3, 's_mult': 22.0},\n",
    "}\n",
    "\n",
    "\n",
    "# timg_gray = img.to(device)#timg_gray.to(device)\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift#sift\n",
    "\n",
    "detector = KeyNetDetector(num_features=60, keynet_conf=keynet_default_config,ori_module=kornia.feature.LAFOrienter(PS)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 1, 120, 120]) torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import kornia\n",
    "from teste_util import *\n",
    "import best.singular_point as sp\n",
    "\n",
    "# leitura dos dados\n",
    "trainloader,testloader =read_dataload_flower(sp.args.img_size,'./data/datasets')\n",
    "iterator=iter(testloader)\n",
    "img,labels = next(iterator)\n",
    "print(img.shape,labels.shape)\n",
    "\n",
    "params_lists =AugmentationParamsGenerator(6,img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_extract_features(image, detector, descriptor, PS):\n",
    "    with torch.no_grad():\n",
    "        lafs, resps = detector(image[None])\n",
    "        patches = kornia.feature.extract_patches_from_pyramid(image[None], lafs, PS)\n",
    "        B, N, CH, H, W = patches.size()\n",
    "        descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "        # print('descs  ',descs.shape)\n",
    "        return lafs, descs\n",
    "\n",
    "def detect_extract_feat_in_batch(batch_img, detector, descriptor, PS):\n",
    "    repo_lafs_desc = []\n",
    "    with torch.no_grad():\n",
    "        for image  in batch_img:            \n",
    "            lafs, resps = detector(image[None])\n",
    "            patches = kornia.feature.extract_patches_from_pyramid(image[None], lafs, PS)\n",
    "            # print('lafs  ',lafs.shape)\n",
    "            B, N, CH, H, W = patches.size()\n",
    "            descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "            repo_lafs_desc.append((lafs,descs))\n",
    "            \n",
    "    return repo_lafs_desc\n",
    "\n",
    "def matching_imagens(ref_img,batch_img, repo_lafs_desc):\n",
    "    best_match_info = None\n",
    "    best_match_count = 0\n",
    "    best_match_index = None\n",
    "    with torch.no_grad():\n",
    "        # Detectar e extrair características da imagem de referência\n",
    "        lafs_ref, descs_ref = detect_and_extract_features(ref_img, detector, descriptor, PS)\n",
    "        \n",
    "        for i, (lafs_i, descs_i) in enumerate(repo_lafs_desc):\n",
    "            # Detectar e extrair características da imagem atual do batch\n",
    "            # lafs_i, descs_i = detect_and_extract_features(img, detector, descriptor, PS)\n",
    "            # Comparar as características da imagem de referência com a imagem atual do batch\n",
    "            scores, matches = kornia.feature.match_snn(descs_ref[0], descs_i[0], 0.85) # correspondencia dos descritories a uma distância de 0.9\n",
    "\n",
    "            if matches.shape[0] >= 4:\n",
    "                # Cálculo da homografia\n",
    "                inliers_mask = compute_homography(lafs_ref, lafs_i, matches)\n",
    "                # print(lafs_ref[0][None].shape, lafs_ref[0].shape, matches.shape, inliers_mask.shape)\n",
    "\n",
    "                # Check if this match is better than the previous best match\n",
    "                if matches.shape[0] > best_match_count:\n",
    "                    best_match_info = (lafs_ref[0][None].cpu(), lafs_i[0][None].cpu(), matches.cpu(),\n",
    "                                       kornia.tensor_to_image(ref_img.cpu()), kornia.tensor_to_image(batch_img[i].cpu()),\n",
    "                                       inliers_mask)\n",
    "                    best_match_count = matches.shape[0]\n",
    "                    best_match_index = i\n",
    "\n",
    "        if best_match_info is not None and best_match_index==0:# TODO: Remove this condition best_match_index==0\n",
    "            # Plot the best match\n",
    "            from kornia_moons.viz import draw_LAF_matches\n",
    "\n",
    "            draw_LAF_matches(\n",
    "                *best_match_info,\n",
    "                draw_dict={\"inlier_color\": (0.2, 1, 0.2), \"tentative_color\": (1, 1, 0.2, 0.3), \"feature_color\": None, \"vertical\": False},\n",
    "            )\n",
    "        # else:\n",
    "        #     print(\"No matches found with enough inliers.\")\n",
    "    return best_match_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05671a3aa3c54e0ba9c82b6ef0bb0d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_lists.aug_list.data_keys =[\"input\"]\n",
    "aug_list = params_lists.aug_list\n",
    "\n",
    "acertos = 0\n",
    "total = 0\n",
    "from tqdm.notebook import tqdm\n",
    "pbar =  tqdm(testloader)\n",
    "for imgs_batch,labels_batch in pbar:# itera em todo dataset\n",
    "    imgs_batch = imgs_batch.to(sp.device)\n",
    "    \n",
    "    params_item = next(params_lists)\n",
    "    timg_gray_t = aug_list(imgs_batch,params=params_item)\n",
    "    repo_lafs_desc= detect_extract_feat_in_batch(timg_gray_t,detector,descriptor,PS)\n",
    "        \n",
    "    for i,img_gray in enumerate(imgs_batch):# itera em cada batch\n",
    "\n",
    "        match_index = matching_imagens(img_gray,timg_gray_t,repo_lafs_desc)\n",
    "        # print(\"match_index: \",match_index,\" i: \",i)\n",
    "        total+=1\n",
    "        if match_index == i:\n",
    "            acertos += 1\n",
    "        pbar.set_description(f\"acertos/total: {acertos}/{total}  \")\n",
    "print(\"acertos: \",acertos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Documentation: Assessing Positional Congruence in Keypoint Detection\n",
    "\n",
    "This Colab notebook evaluates the **repeatability** of keypoint detection algorithms by measuring **positional congruence** between detected keypoints in original images (`I`) and their transformed counterparts (`τ(I)`). The experiment compares our method's performance against state-of-the-art detectors, including **KeyNet** and **REKD**.\n",
    "\n",
    "### Methodology:\n",
    "The evaluation is restricted to overlapping subregions between the original and transformed datasets to ensure meaningful comparisons. The criterion for positional congruence is defined as:\n",
    "\n",
    "**|Kᵢ(τ(Iᵢ)) - τ(Kᵢ(Iᵢ))| ≤ α**\n",
    "\n",
    "Where:\n",
    "- `Kᵢ(Iᵢ)`: Keypoints detected in the original image.\n",
    "- `Kᵢ(τ(Iᵢ))`: Keypoints detected in the transformed image.\n",
    "- `τ`: Transformation applied to the image.\n",
    "- `α`: Acceptable positional deviation threshold.\n",
    "\n",
    "### Objective:\n",
    "This experiment aims to validate the hypothesis that improving keypoint repeatability enhances feature matching and image identification accuracy. It forms the foundation for comparing detector performance and evaluating their robustness to image transformations.\n",
    "\n",
    "By adopting a rigorous and reproducible framework, this notebook provides an impartial assessment of keypoint detectors under diverse real-world conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkornia\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/__init__.py:2475\u001b[0m\n\u001b[1;32m   2471\u001b[0m     torch_module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;18m__name__\u001b[39m, device_type])\n\u001b[1;32m   2472\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[torch_module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m-> 2475\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   2476\u001b[0m     export \u001b[38;5;28;01mas\u001b[39;00m export,\n\u001b[1;32m   2477\u001b[0m     func \u001b[38;5;28;01mas\u001b[39;00m func,\n\u001b[1;32m   2478\u001b[0m     library \u001b[38;5;28;01mas\u001b[39;00m library,\n\u001b[1;32m   2479\u001b[0m     return_types \u001b[38;5;28;01mas\u001b[39;00m return_types,\n\u001b[1;32m   2480\u001b[0m )\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond \u001b[38;5;28;01mas\u001b[39;00m cond, while_loop \u001b[38;5;28;01mas\u001b[39;00m while_loop\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/export/__init__.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatibility\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpass_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PassResult\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpass_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PassManager\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     FlattenFunc,\n\u001b[1;32m     32\u001b[0m     FromDumpableContextFn,\n\u001b[1;32m     33\u001b[0m     ToDumpableContextFn,\n\u001b[1;32m     34\u001b[0m     UnflattenFunc,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/fx/passes/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_drawer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_manipulation\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m net_min_base\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/fx/passes/graph_drawer.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _format_arg, _get_qualified_name\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperator_schemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_function\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshape_prop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorMetadata\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydot\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/fx/passes/shape_prop.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatibility\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect_fake_mode\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_sparse_any\n\u001b[1;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorMetadata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShapeProp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTensorMetadata\u001b[39;00m(NamedTuple):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# TensorMetadata is a structure containing pertinent information\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# about a tensor within a PyTorch program.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# General Tensor metadata\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/_subclasses/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     DynamicOutputShapeException,\n\u001b[1;32m      4\u001b[0m     FakeTensor,\n\u001b[1;32m      5\u001b[0m     FakeTensorMode,\n\u001b[1;32m      6\u001b[0m     UnsupportedFakeTensorException,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossRefFakeMode\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFakeTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFakeTensorMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossRefFakeMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py:2409\u001b[0m\n\u001b[1;32m   2390\u001b[0m _DISPATCH_META_HANDLERS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2391\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprim\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mdefault: _device_handler,\n\u001b[1;32m   2392\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m.\u001b[39mdefault: \u001b[38;5;28;01mlambda\u001b[39;00m args: \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2400\u001b[0m     ),\n\u001b[1;32m   2401\u001b[0m }\n\u001b[1;32m   2403\u001b[0m _DISPATCH_HANDLE_DIRECTLY \u001b[38;5;241m=\u001b[39m ordered_set(\n\u001b[1;32m   2404\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39mis_coalesced\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m   2405\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39mdense_dim\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m   2406\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msparse_dim\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m   2407\u001b[0m )\n\u001b[0;32m-> 2409\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_impls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m     _device_not_kwarg_ops,\n\u001b[1;32m   2411\u001b[0m     _is_tensor_constructor,\n\u001b[1;32m   2412\u001b[0m     _like_tensor_constructors,\n\u001b[1;32m   2413\u001b[0m     contains_tensor_types,\n\u001b[1;32m   2414\u001b[0m     get_fast_op_impls,\n\u001b[1;32m   2415\u001b[0m     has_meta,\n\u001b[1;32m   2416\u001b[0m     op_implementations_checks,\n\u001b[1;32m   2417\u001b[0m     stride_incorrect_op,\n\u001b[1;32m   2418\u001b[0m )\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;129m@atexit\u001b[39m\u001b[38;5;241m.\u001b[39mregister\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump_cache_stats\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2423\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFakeTensor cache stats:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/_subclasses/fake_impls.py:71\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_noncontiguous_supported\u001b[39m(device):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m _like_tensor_constructors \u001b[38;5;241m=\u001b[39m ordered_set(\n\u001b[1;32m     60\u001b[0m     aten\u001b[38;5;241m.\u001b[39mempty_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     61\u001b[0m     aten\u001b[38;5;241m.\u001b[39mempty_like\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     62\u001b[0m     aten\u001b[38;5;241m.\u001b[39mfull_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     63\u001b[0m     aten\u001b[38;5;241m.\u001b[39mfull_like\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     64\u001b[0m     aten\u001b[38;5;241m.\u001b[39mones_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     65\u001b[0m     aten\u001b[38;5;241m.\u001b[39mones_like\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     66\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrand_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     67\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrand_like\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     68\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrandn_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     69\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrandn_like\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     70\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrandint_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[0;32m---> 71\u001b[0m     \u001b[43maten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m,\n\u001b[1;32m     72\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrandint_like\u001b[38;5;241m.\u001b[39mlow_dtype,\n\u001b[1;32m     73\u001b[0m     aten\u001b[38;5;241m.\u001b[39mrandint_like\u001b[38;5;241m.\u001b[39mlow_dtype_out,\n\u001b[1;32m     74\u001b[0m     aten\u001b[38;5;241m.\u001b[39mzeros_like\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     75\u001b[0m     aten\u001b[38;5;241m.\u001b[39mzeros_like\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     76\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_empty\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     77\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_empty\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     78\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_empty_strided\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     79\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_empty_strided\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     80\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_full\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     81\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_full\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     82\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_zeros\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     83\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_zeros\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     84\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_ones\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     85\u001b[0m     aten\u001b[38;5;241m.\u001b[39mnew_ones\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     89\u001b[0m _device_not_kwarg_ops \u001b[38;5;241m=\u001b[39m ordered_set(\n\u001b[1;32m     90\u001b[0m     aten\u001b[38;5;241m.\u001b[39m_resize_output_\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[1;32m     91\u001b[0m     aten\u001b[38;5;241m.\u001b[39m_nested_tensor_from_tensor_list\u001b[38;5;241m.\u001b[39mdefault,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     aten\u001b[38;5;241m.\u001b[39m_resize_output\u001b[38;5;241m.\u001b[39mout,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# this op is never actually used\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/_ops.py:1076\u001b[0m, in \u001b[0;36mOpOverloadPacket.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1074\u001b[0m use_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m key\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;66;03m# TODO: disallow access to overloads registered by JIT\u001b[39;00m\n\u001b[0;32m-> 1076\u001b[0m op_dk_tags \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_operation_overload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qualified_op_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_key\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_dk_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1081\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe underlying op of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no overload name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1082\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import kornia\n",
    "from torch import nn\n",
    "from teste_util import *\n",
    "from kornia.feature.keynet import KeyNetDetector\n",
    "from custom_local_feature import REKDSosNet, SingularPointSosNet\n",
    "import itertools\n",
    "\n",
    "# Fixar a semente do Torch para operações específicas\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "keynet_default_config = {\n",
    "    'num_filters': 8,\n",
    "    'num_levels': 3,\n",
    "    'kernel_size': 5,\n",
    "    'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.0, 's_mult': 5.0},\n",
    "}\n",
    "\n",
    "\n",
    "# Inicializar os detectores e adicionar seus nomes de classe\n",
    "detectors = {\n",
    "    \"KeyNetDetector\": KeyNetDetector(pretrained=True, num_features=60, \n",
    "                                     keynet_conf=keynet_default_config, \n",
    "                                     ori_module=kornia.feature.LAFOrienter(32)).to(device),\n",
    "    \"REKDSosNet\": REKDSosNet(config=keynet_default_config,device=device)._initialize_detector(num_features=60,size_laf=32).to(device),\n",
    "    \"SingularPointSosNet\": SingularPointSosNet(config=keynet_default_config,device=device)._initialize_detector(num_features=60,size_laf=32).to(device),\n",
    "}\n",
    "\n",
    "# Leitura dos dados\n",
    "dataloaders = {\n",
    "    # \"flower\": read_dataload_flower(120)[1],\n",
    "    \"fibers\": read_dataload_fibers(120)[1],\n",
    "    \"woods\": read_dataload_woods(120)[1],\n",
    "}\n",
    "\n",
    "# Gerar combinações entre detectores e dataloaders\n",
    "def generate_combinations(detectors, dataloaders):\n",
    "    # Produto cartesiano entre detectores e dataloaders\n",
    "    return list(itertools.product(dataloaders.items(), detectors.items()))\n",
    "\n",
    "# Gerar combinações\n",
    "combinations = generate_combinations(detectors, dataloaders)\n",
    "\n",
    "# Listar as combinações\n",
    "# for i, ((dataset_name, dataloader), (class_name, detector)) in enumerate(combinations, 1):\n",
    "#     print(f\"Combinação {i}: Detector - {class_name} ({detector.__class__.__name__}), Dataset - {dataset_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import kornia.feature as KF\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia as K\n",
    "\n",
    "def visualize_LAF(img, LAF, img_idx = 0):\n",
    "    x, y = KF.laf.get_laf_pts_to_draw(LAF, img_idx)\n",
    "    print(x[0][:5],y[0][:5])\n",
    "    plt.figure()\n",
    "    plt.imshow(K.utils.tensor_to_image(img[img_idx]))\n",
    "    plt.plot(x, y, 'r')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_matching_images(img1, LAF1, img2, LAF2, matches):\n",
    "    print(LAF1.shape,LAF2.shape)\n",
    "    x1, y1 = KF.laf.get_laf_pts_to_draw(LAF1, 0)  # Pontos da primeira imagem\n",
    "    x2, y2 = KF.laf.get_laf_pts_to_draw(LAF2, 0)  # Pontos da segunda imagem\n",
    "\n",
    "    # Converte as listas x2 e y2 em arrays NumPy\n",
    "    x2 = np.array(x2)\n",
    "    y2 = np.array(y2)\n",
    "\n",
    "    # Crie uma imagem combinada concatenando as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((K.utils.tensor_to_image(img1), K.utils.tensor_to_image(img2)), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))  # Cria uma figura com uma subplot\n",
    "\n",
    "    # Plota a imagem combinada\n",
    "    ax.imshow(combined_image)\n",
    "    ax.axis('off')\n",
    "    # Plota os pontos correspondentes nas duas imagens\n",
    "    ax.plot(x1, y1, 'c')  # 'ro' representa pontos vermelhos na primeira imagem\n",
    "    ax.plot(x2 + img1.shape[1], y2, 'y')  # Desloca os pontos azuis na segunda imagem para a direita\n",
    "\n",
    "    points1 =kornia.feature.get_laf_center(LAF1)[0].cpu()\n",
    "    points2 =kornia.feature.get_laf_center(LAF2)[0].cpu()\n",
    "    print(points1.shape,points2.shape)\n",
    "    for match in matches:\n",
    "        x1_match, y1_match = points1[match[0],0], points1[match[0],1]\n",
    "        x2_match, y2_match = points2[match[1],0] + img1.shape[1], points2[match[1],1]\n",
    "       \n",
    "        ax.plot([x1_match, x2_match], [y1_match, y2_match], '-', color='red', lw=1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_matches_keypoints(image1, keypoints1, image2, keypoints2, matches, **kwargs):\n",
    "    print('image1 shape: ',image1.shape,image1.dtype,image2.shape,image2.dtype)\n",
    "    # Concatenar as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(combined_image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Desenhar pontos correspondentes e linhas conectando-os\n",
    "    offset = image1.shape[1]\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints1):\n",
    "        ax.plot(x, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints2):\n",
    "        ax.plot(x+offset, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x+offset, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for match in matches:\n",
    "        x1, y1 = keypoints1[match[0],0], keypoints1[match[0],1]\n",
    "        x2, y2 = keypoints2[match[1],0]+offset, keypoints2[match[1],1]\n",
    "        ax.plot([x1, x2], [y1, y2], '-', color='lime', lw=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_with_keypoints(image_tensor, keypoints_tensor):\n",
    "    # Converter a imagem tensorial em objeto PIL.Image\n",
    "    image = kornia.utils.tensor_to_image(image_tensor)\n",
    "    # Plotar a imagem e os keypoints\n",
    "    plt.imshow(image)\n",
    "    if keypoints_tensor is not None:\n",
    "        # Extrair as coordenadas x e y dos keypoints\n",
    "        keypoints_x = keypoints_tensor[:,0].flatten().tolist()\n",
    "        keypoints_y = keypoints_tensor[:,1].flatten().tolist()\n",
    "        plt.scatter(keypoints_x, keypoints_y, c='red')\n",
    "    plt.show()\n",
    "    \n",
    "def filtrar_keypoints(lista_de_pontos, tensor_mascara):\n",
    "    # Verificar se as coordenadas estão dentro das dimensões\n",
    "    dimensao_max_x, dimensao_max_y = tensor_mascara.shape[1] - 1, tensor_mascara.shape[0] - 1\n",
    "    pontos_filtrados = [\n",
    "        ponto.tolist()  for ponto in lista_de_pontos \n",
    "        if 0 <= ponto[0] <= dimensao_max_x \n",
    "        and 0 <= ponto[1] <= dimensao_max_y \n",
    "        and tensor_mascara[int(ponto[1]), int(ponto[0])] \n",
    "    ]\n",
    "    return torch.tensor(pontos_filtrados)\n",
    "\n",
    "def find_best_matching_indices_knn(points1, points2, threshold, k=3):\n",
    "    if len(points1) == 0 or len(points2) == 0:\n",
    "        return []\n",
    "    distances = cdist(points1, points2)\n",
    "    best_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    best_distances = np.take_along_axis(distances, best_indices, axis=1)\n",
    "    matched = []\n",
    "\n",
    "    for i in range(len(points1)):\n",
    "        min_distance = np.min(best_distances[i])        \n",
    "        if min_distance < threshold:\n",
    "            best_index = np.argmin(best_distances[i])\n",
    "            matched.append((i, best_indices[i, best_index]))\n",
    "\n",
    "    return matched\n",
    "\n",
    "\n",
    "def detect_extract_feat_in_batch(batch1,aug_list, detector):\n",
    "    origem_total = []\n",
    "    matches_total = []\n",
    "    with torch.no_grad():\n",
    "        for img1  in batch1:            \n",
    "            lafs1, resps1 = detector(img1[None])\n",
    "\n",
    "            B,C,H,W = img1[None].shape\n",
    "            mask = torch.ones(B,C,H,W).to(img1.device) \n",
    "            \n",
    "            #lafs1 to points1\n",
    "            points1 =kornia.feature.get_laf_center(lafs1)\n",
    "\n",
    "            if( points1.shape[1] == 0):\n",
    "                print('aug_list shape: ',points1.shape) \n",
    "                continue     \n",
    "\n",
    "            params = next(aug_list)    \n",
    "            img2,mask_t,ponts_t=aug_list.augmentation_sequence(img1,mask,points1,params=params)           \n",
    "             \n",
    "            img2 = img2.to(img1.device)\n",
    "            lafs2, resps2 = detector(img2)\n",
    "            points2 =kornia.feature.get_laf_center(lafs2)     \n",
    "            filtered_points1 = filtrar_keypoints(ponts_t[0],mask_t[0,0].bool())            \n",
    "            filtered_points2 = filtrar_keypoints(points2[0],mask_t[0,0].bool())\n",
    "            # print(\"shape p & f\",points1.shape,filtered_points1.shape,filtered_points2.shape)\n",
    "            matches = find_best_matching_indices_knn(filtered_points1.cpu(), filtered_points2.cpu(), threshold=1.0, k=1)  \n",
    "            matches2 = find_best_matching_indices_knn(ponts_t[0].cpu(), points2[0].cpu(), threshold=0.6, k=1)  \n",
    "            \n",
    "            # visualize_matching_images(img1[0], lafs1, img2[0,0], lafs2,matches2)\n",
    "            # print(img1.shape,img1.device,img2[0].shape,img2.device)\n",
    "            # plot_matches_keypoints(img2[0,0].cpu(), filtered_points1, img2[0,0].cpu(), filtered_points2, matches)\n",
    "            if( filtered_points1.shape[0] == 0 or filtered_points2.shape[0] == 0):\n",
    "                print('filtered_points1 shape: ',filtered_points1.shape,'filtered_points2 shape: ',filtered_points2.shape)\n",
    "                continue       \n",
    "                 \n",
    "            origem_total.append(len(filtered_points1))\n",
    "            matches_total.append(len(matches))            \n",
    "    return (np.mean(matches_total)/np.mean(origem_total))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationGenerator:\n",
    "    def __init__(self, n_variations):\n",
    "        # Definir as augmentações\n",
    "        aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "            kornia.augmentation.RandomAffine(degrees=360, translate=(0.2, 0.2), scale=(0.95, 1.05), shear=10,p=0.8),\n",
    "            kornia.augmentation.RandomPerspective(0.2, p=0.7),\n",
    "            kornia.augmentation.RandomBoxBlur((4,4),p=0.5),\n",
    "            data_keys=[kornia.constants.DataKey.INPUT,  # Especifica as chaves corretamente\n",
    "                       kornia.constants.DataKey.MASK,\n",
    "                       kornia.constants.DataKey.KEYPOINTS],\n",
    "            same_on_batch=True,\n",
    "        )\n",
    "\n",
    "        self.augmentation_sequence = aug_gen\n",
    "        self.n_variations = n_variations\n",
    "        self.param_list = []\n",
    "        self.current_index = 0\n",
    "\n",
    "    def generate_variations(self, image, mask, keypoints):\n",
    "        \"\"\"\n",
    "        Gera múltiplas variações de augmentações e coleta seus parâmetros.\n",
    "        \"\"\"\n",
    "        for _ in range(self.n_variations):\n",
    "            # Apenas executa a sequência de augmentação e salva os parâmetros gerados\n",
    "            self.augmentation_sequence(image, mask, keypoints)\n",
    "            self.param_list.append(self.augmentation_sequence._params)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current_index = 0  # Resetar o índice a cada nova iteração\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"\n",
    "        Retorna a próxima variação de parâmetros de augmentação.\n",
    "        A iteração será circular.\n",
    "        \"\"\"\n",
    "        result = self.param_list[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.param_list)\n",
    "        return result\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Método para resetar o estado do gerador de augmentação.\"\"\"\n",
    "        self.current_index = 0  # Reseta o índice de iteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bca9b41c7e4bc1a2243ff0f7a4179e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation KeyNetDetector-fibers:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecf95089e7e4eae92268eaf9580a3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation REKDSosNet-fibers:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "filtered_points1 shape:  torch.Size([2, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([7, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "filtered_points1 shape:  torch.Size([2, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n",
      "aug_list shape:  torch.Size([1, 0, 2])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29248974cdc446c9d0a351aef3dea6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation SingularPointSosNet-fibers:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21216443497642b3b79a0769b02f87c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation KeyNetDetector-woods:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_points1 shape:  torch.Size([24, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([49, 2]) filtered_points2 shape:  torch.Size([0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9bc71e6c474a169665c25192bef026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation REKDSosNet-woods:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_points1 shape:  torch.Size([15, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([19, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([14, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([3, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([10, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([19, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([12, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([8, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([31, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([23, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([22, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([25, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([27, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([7, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([29, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([19, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([20, 2]) filtered_points2 shape:  torch.Size([0])\n",
      "filtered_points1 shape:  torch.Size([16, 2]) filtered_points2 shape:  torch.Size([0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2ee333c3064c9f839ee43a739e7db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation SingularPointSosNet-woods:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "aug_gen = AugmentationGenerator(15)\n",
    "image = torch.rand(1, 1, 120, 120)  # Imagem com valores aleatórios\n",
    "mask = torch.ones(1, 1, 120, 120)  # Máscara binária\n",
    "keypoints = torch.tensor([[[30, 30], [90, 90]]], dtype=torch.float32)  # Pontos chave de exemplo\n",
    "\n",
    "# Gerar as variações\n",
    "aug_gen.generate_variations(image, mask, keypoints)\n",
    "\n",
    "for i, ((dataset_name, dataloader), (class_name, detector)) in enumerate(combinations, 1):\n",
    "    matches_total = []\n",
    "    pbar = tqdm(dataloader, desc=f\"Evaluation {class_name}-{dataset_name}\")  # Usando f-string para formatar o nome da classe do detector\n",
    "    for imgs_batch, labels_batch in pbar:  # Itera em todo o dataset\n",
    "        imgs_batch = imgs_batch.to(device)    \n",
    "        mean = detect_extract_feat_in_batch(imgs_batch, aug_gen, detector)\n",
    "        matches_total.append(mean)\n",
    "        pbar.set_postfix({\"Dataset Match Mean\": f\"{np.mean(matches_total):.4f}\"})\n",
    "        aug_gen.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation KeyNetDetector-flower: 100% 102/102 [04:55<00:00,  2.29s/it, Dataset Match Mean=10.8670]\n",
    "Evaluation REKDSosNet-flower: 100% 102/102 [05:23<00:00,  2.41s/it, Dataset Match Mean=30.2402]\n",
    "Evaluation SingularPointSosNet-flower: 100% 102/102 [07:32<00:00,  3.37s/it, Dataset Match Mean=40.1165]\n",
    "\n",
    "Evaluation KeyNetDetector-woods: 100% 22/22 [00:31<00:00,  1.14s/it, Dataset Match Mean=11.9748]\n",
    "Evaluation REKDSosNet-woods: 100% 22/22 [00:31<00:00,  1.15s/it, Dataset Match Mean=19.4605]\n",
    "Evaluation SingularPointSosNet-woods: 100% 22/22 [00:49<00:00,  1.84s/it, Dataset Match Mean=34.3371]\n",
    "\n",
    "Evaluation KeyNetDetector-fibers: 100% 9/9 [00:15<00:00,  1.75s/it, Dataset Match Mean=10.4233]\n",
    "Evaluation REKDSosNet-fibers: 100% 9/9 [00:15<00:00,  1.60s/it, Dataset Match Mean=3.6245]\n",
    "Evaluation SingularPointSosNet-fibers: 100% 9/9 [00:30<00:00,  3.37s/it, Dataset Match Mean=42.1785]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singular-points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Documentation: Assessing Positional Congruence in Keypoint Detection\n",
    "\n",
    "This Colab notebook evaluates the **repeatability** of keypoint detection algorithms by measuring **positional congruence** between detected keypoints in original images (`I`) and their transformed counterparts (`τ(I)`). The experiment compares our method's performance against state-of-the-art detectors, including **KeyNet** and **REKD**.\n",
    "\n",
    "### Methodology:\n",
    "The evaluation is restricted to overlapping subregions between the original and transformed datasets to ensure meaningful comparisons. The criterion for positional congruence is defined as:\n",
    "\n",
    "**|Kᵢ(τ(Iᵢ)) - τ(Kᵢ(Iᵢ))| ≤ α**\n",
    "\n",
    "Where:\n",
    "- `Kᵢ(Iᵢ)`: Keypoints detected in the original image.\n",
    "- `Kᵢ(τ(Iᵢ))`: Keypoints detected in the transformed image.\n",
    "- `τ`: Transformation applied to the image.\n",
    "- `α`: Acceptable positional deviation threshold.\n",
    "\n",
    "### Objective:\n",
    "This experiment aims to validate the hypothesis that improving keypoint repeatability enhances feature matching and image identification accuracy. It forms the foundation for comparing detector performance and evaluating their robustness to image transformations.\n",
    "\n",
    "By adopting a rigorous and reproducible framework, this notebook provides an impartial assessment of keypoint detectors under diverse real-world conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kornia\n",
    "from torch import nn\n",
    "# from kornia.feature.keynet import KeyNetDetector\n",
    "# from custom_local_feature import REKDSosNet, SingularPointSosNet\n",
    "from visidex.kornia_local_feature import KeyNetFeatureSIFT, REKDSosNet,SingularPointSosNet\n",
    "from visidex.model import read_dataload_fibers,read_dataload_flower,read_dataload_woods\n",
    "from visidex.utils import set_seed, AugmentationGenerator\n",
    "import itertools\n",
    "\n",
    "# Fixar a semente do Torch para operações específicas\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "keynet_default_config = {\n",
    "    'num_filters': 8,\n",
    "    'num_levels': 3,\n",
    "    'kernel_size': 5,\n",
    "    'Detector_conf': {'nms_size': 5, 'pyramid_levels': 0, 'up_levels': 0, 'scale_factor_levels': 1.0, 's_mult': 5.0},\n",
    "}\n",
    "\n",
    "\n",
    "# Inicializar os detectores e adicionar seus nomes de classe\n",
    "detectors = {\n",
    "    \"KeyNetDetector\": KeyNetFeatureSIFT(config=keynet_default_config,device=device).initialize_detector(num_features=60).to(device),\n",
    "    \"REKDSosNet\": REKDSosNet(config=keynet_default_config,device=device).initialize_detector(num_features=60).to(device),\n",
    "    \"SingularPointSosNet\": SingularPointSosNet(config=keynet_default_config,device=device).initialize_detector(num_features=60).to(device),\n",
    "}\n",
    "\n",
    "# Leitura dos dados\n",
    "dataloaders = {\n",
    "    # \"flower\": read_dataload_flower(120)[1],\n",
    "    \"fibers\": read_dataload_fibers(120)[1],\n",
    "    # \"woods\": read_dataload_woods(120)[1],\n",
    "}\n",
    "\n",
    "# Gerar combinações entre detectores e dataloaders\n",
    "def generate_combinations(detectors, dataloaders):\n",
    "    # Produto cartesiano entre detectores e dataloaders\n",
    "    return list(itertools.product(dataloaders.items(), detectors.items()))\n",
    "\n",
    "# Gerar combinações\n",
    "combinations = generate_combinations(detectors, dataloaders)\n",
    "\n",
    "# Listar as combinações\n",
    "# for i, ((dataset_name, dataloader), (class_name, detector)) in enumerate(combinations, 1):\n",
    "#     print(f\"Combinação {i}: Detector - {class_name} ({detector.__class__.__name__}), Dataset - {dataset_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import kornia.feature as KF\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia as K\n",
    "\n",
    "def visualize_LAF(img, LAF, img_idx = 0):\n",
    "    x, y = KF.laf.get_laf_pts_to_draw(LAF, img_idx)\n",
    "    print(x[0][:5],y[0][:5])\n",
    "    plt.figure()\n",
    "    plt.imshow(K.utils.tensor_to_image(img[img_idx]))\n",
    "    plt.plot(x, y, 'r')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_matching_images(img1, LAF1, img2, LAF2, matches):\n",
    "    print(LAF1.shape,LAF2.shape)\n",
    "    x1, y1 = KF.laf.get_laf_pts_to_draw(LAF1, 0)  # Pontos da primeira imagem\n",
    "    x2, y2 = KF.laf.get_laf_pts_to_draw(LAF2, 0)  # Pontos da segunda imagem\n",
    "\n",
    "    # Converte as listas x2 e y2 em arrays NumPy\n",
    "    x2 = np.array(x2)\n",
    "    y2 = np.array(y2)\n",
    "\n",
    "    # Crie uma imagem combinada concatenando as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((K.utils.tensor_to_image(img1), K.utils.tensor_to_image(img2)), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))  # Cria uma figura com uma subplot\n",
    "\n",
    "    # Plota a imagem combinada\n",
    "    ax.imshow(combined_image)\n",
    "    ax.axis('off')\n",
    "    # Plota os pontos correspondentes nas duas imagens\n",
    "    ax.plot(x1, y1, 'c')  # 'ro' representa pontos vermelhos na primeira imagem\n",
    "    ax.plot(x2 + img1.shape[1], y2, 'y')  # Desloca os pontos azuis na segunda imagem para a direita\n",
    "\n",
    "    points1 =kornia.feature.get_laf_center(LAF1)[0].cpu()\n",
    "    points2 =kornia.feature.get_laf_center(LAF2)[0].cpu()\n",
    "    print(points1.shape,points2.shape)\n",
    "    for match in matches:\n",
    "        x1_match, y1_match = points1[match[0],0], points1[match[0],1]\n",
    "        x2_match, y2_match = points2[match[1],0] + img1.shape[1], points2[match[1],1]\n",
    "       \n",
    "        ax.plot([x1_match, x2_match], [y1_match, y2_match], '-', color='red', lw=1.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_matches_keypoints(image1, keypoints1, image2, keypoints2, matches, **kwargs):\n",
    "    print('image1 shape: ',image1.shape,image1.dtype,image2.shape,image2.dtype)\n",
    "    # Concatenar as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(combined_image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Desenhar pontos correspondentes e linhas conectando-os\n",
    "    offset = image1.shape[1]\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints1):\n",
    "        ax.plot(x, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints2):\n",
    "        ax.plot(x+offset, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x+offset, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for match in matches:\n",
    "        x1, y1 = keypoints1[match[0],0], keypoints1[match[0],1]\n",
    "        x2, y2 = keypoints2[match[1],0]+offset, keypoints2[match[1],1]\n",
    "        ax.plot([x1, x2], [y1, y2], '-', color='lime', lw=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_with_keypoints(image_tensor, keypoints_tensor):\n",
    "    # Converter a imagem tensorial em objeto PIL.Image\n",
    "    image = kornia.utils.tensor_to_image(image_tensor)\n",
    "    # Plotar a imagem e os keypoints\n",
    "    plt.imshow(image)\n",
    "    if keypoints_tensor is not None:\n",
    "        # Extrair as coordenadas x e y dos keypoints\n",
    "        keypoints_x = keypoints_tensor[:,0].flatten().tolist()\n",
    "        keypoints_y = keypoints_tensor[:,1].flatten().tolist()\n",
    "        plt.scatter(keypoints_x, keypoints_y, c='red')\n",
    "    plt.show()\n",
    "    \n",
    "def filtrar_keypoints(lista_de_pontos, tensor_mascara):\n",
    "    # Verificar se as coordenadas estão dentro das dimensões\n",
    "    dimensao_max_x, dimensao_max_y = tensor_mascara.shape[1] - 1, tensor_mascara.shape[0] - 1\n",
    "    pontos_filtrados = [\n",
    "        ponto.tolist()  for ponto in lista_de_pontos \n",
    "        if 0 <= ponto[0] <= dimensao_max_x \n",
    "        and 0 <= ponto[1] <= dimensao_max_y \n",
    "        and tensor_mascara[int(ponto[1]), int(ponto[0])] \n",
    "    ]\n",
    "    return torch.tensor(pontos_filtrados)\n",
    "\n",
    "def find_best_matching_indices_knn(points1, points2, threshold, k=3):\n",
    "    if len(points1) == 0 or len(points2) == 0:\n",
    "        return []\n",
    "    distances = cdist(points1, points2)\n",
    "    best_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    best_distances = np.take_along_axis(distances, best_indices, axis=1)\n",
    "    matched = []\n",
    "\n",
    "    for i in range(len(points1)):\n",
    "        min_distance = np.min(best_distances[i])        \n",
    "        if min_distance < threshold:\n",
    "            best_index = np.argmin(best_distances[i])\n",
    "            matched.append((i, best_indices[i, best_index]))\n",
    "\n",
    "    return matched\n",
    "\n",
    "\n",
    "def detect_extract_feat_in_batch(batch1,aug_list, detector):\n",
    "    origem_total = []\n",
    "    matches_total = []\n",
    "    with torch.no_grad():\n",
    "        for img1  in batch1:            \n",
    "            lafs1, resps1 = detector(img1[None])\n",
    "\n",
    "            B,C,H,W = img1[None].shape\n",
    "            mask = torch.ones(B,C,H,W).to(img1.device) \n",
    "            \n",
    "            #lafs1 to points1\n",
    "            points1 =kornia.feature.get_laf_center(lafs1)\n",
    "\n",
    "            if( points1.shape[1] == 0):\n",
    "                print('aug_list shape: ',points1.shape) \n",
    "                continue     \n",
    "\n",
    "            params = next(aug_list)    \n",
    "            img2,mask_t,ponts_t=aug_list.augmentation_sequence(img1,mask,points1,params=params)           \n",
    "             \n",
    "            img2 = img2.to(img1.device)\n",
    "            lafs2, resps2 = detector(img2)\n",
    "            points2 =kornia.feature.get_laf_center(lafs2)     \n",
    "            print('points1 shape: ',points1.shape,'mask_t shape: ',mask_t.shape)\n",
    "            filtered_points1 = filtrar_keypoints(ponts_t[0],mask_t[0,0].bool())            \n",
    "            filtered_points2 = filtrar_keypoints(points2[0],mask_t[0,0].bool())\n",
    "            print(\"shape p & f\",points1.shape,filtered_points1.shape,filtered_points2.shape)\n",
    "            matches = find_best_matching_indices_knn(filtered_points1.cpu(), filtered_points2.cpu(), threshold=1.0, k=1)  \n",
    "\n",
    "            if( filtered_points1.shape[0] == 0 or filtered_points2.shape[0] == 0):\n",
    "                print('filtered_points1 shape: ',filtered_points1.shape,'filtered_points2 shape: ',filtered_points2.shape)\n",
    "                continue  \n",
    "                 \n",
    "            origem_total.append(len(filtered_points1))\n",
    "            matches_total.append(len(matches))            \n",
    "    return (np.mean(matches_total)/np.mean(origem_total))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wagner/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/functional.py:4969: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/wagner/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f69f9e7b3c4407898bd02976ae53802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation KeyNetDetector-fibers:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points1 shape:  torch.Size([1, 34, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 34, 2]) torch.Size([30, 2]) torch.Size([12, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([17, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([23, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([22, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([21, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([23, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([15, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([31, 2]) torch.Size([23, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([22, 2]) torch.Size([28, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([19, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([26, 2]) torch.Size([20, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([22, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([24, 2]) torch.Size([24, 2])\n",
      "points1 shape:  torch.Size([1, 35, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 35, 2]) torch.Size([34, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([22, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([19, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([21, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([28, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([19, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([23, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([18, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 41, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 41, 2]) torch.Size([37, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 30, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 30, 2]) torch.Size([26, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([17, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 39, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 39, 2]) torch.Size([37, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([26, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([20, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 28, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 28, 2]) torch.Size([27, 2]) torch.Size([14, 2])\n",
      "points1 shape:  torch.Size([1, 36, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 36, 2]) torch.Size([36, 2]) torch.Size([41, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([20, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 21, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 21, 2]) torch.Size([19, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 28, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 28, 2]) torch.Size([28, 2]) torch.Size([23, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([21, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 29, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 29, 2]) torch.Size([24, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([21, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([20, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 19, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 19, 2]) torch.Size([18, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([16, 2]) torch.Size([20, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([20, 2]) torch.Size([24, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([23, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([24, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([22, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([25, 2]) torch.Size([12, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([23, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([19, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([22, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 18, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 18, 2]) torch.Size([16, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 33, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 33, 2]) torch.Size([28, 2]) torch.Size([29, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([24, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([21, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 31, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 31, 2]) torch.Size([27, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([18, 2]) torch.Size([20, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([21, 2]) torch.Size([28, 2])\n",
      "points1 shape:  torch.Size([1, 30, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 30, 2]) torch.Size([30, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([26, 2]) torch.Size([28, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([26, 2]) torch.Size([12, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([23, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([17, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([29, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([26, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([22, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([22, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([24, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 38, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 38, 2]) torch.Size([32, 2]) torch.Size([32, 2])\n",
      "points1 shape:  torch.Size([1, 28, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 28, 2]) torch.Size([25, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([24, 2]) torch.Size([24, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([25, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([23, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 28, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 28, 2]) torch.Size([27, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 30, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 30, 2]) torch.Size([30, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([27, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([27, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([19, 2]) torch.Size([14, 2])\n",
      "points1 shape:  torch.Size([1, 29, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 29, 2]) torch.Size([23, 2]) torch.Size([12, 2])\n",
      "points1 shape:  torch.Size([1, 29, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 29, 2]) torch.Size([29, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 33, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 33, 2]) torch.Size([28, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([28, 2]) torch.Size([30, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([20, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([16, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([20, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([30, 2]) torch.Size([27, 2])\n",
      "points1 shape:  torch.Size([1, 30, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 30, 2]) torch.Size([24, 2]) torch.Size([23, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([22, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 37, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 37, 2]) torch.Size([35, 2]) torch.Size([30, 2])\n",
      "points1 shape:  torch.Size([1, 31, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 31, 2]) torch.Size([31, 2]) torch.Size([32, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([24, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 30, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 30, 2]) torch.Size([25, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 30, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 30, 2]) torch.Size([26, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([26, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([21, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([24, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 28, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 28, 2]) torch.Size([27, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 20, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 20, 2]) torch.Size([17, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([20, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([23, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([23, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([23, 2]) torch.Size([20, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([22, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 31, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 31, 2]) torch.Size([30, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 40, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 40, 2]) torch.Size([40, 2]) torch.Size([46, 2])\n",
      "points1 shape:  torch.Size([1, 29, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 29, 2]) torch.Size([25, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([18, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 18, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 18, 2]) torch.Size([18, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([19, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([22, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 23, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 23, 2]) torch.Size([23, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([19, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([22, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([23, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 17, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 17, 2]) torch.Size([10, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([19, 2])\n",
      "points1 shape:  torch.Size([1, 28, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 28, 2]) torch.Size([28, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([13, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([25, 2]) torch.Size([25, 2])\n",
      "points1 shape:  torch.Size([1, 31, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 31, 2]) torch.Size([25, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 26, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 26, 2]) torch.Size([20, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 31, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 31, 2]) torch.Size([31, 2]) torch.Size([36, 2])\n",
      "points1 shape:  torch.Size([1, 29, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 29, 2]) torch.Size([25, 2]) torch.Size([21, 2])\n",
      "points1 shape:  torch.Size([1, 25, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 25, 2]) torch.Size([22, 2]) torch.Size([17, 2])\n",
      "points1 shape:  torch.Size([1, 21, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 21, 2]) torch.Size([16, 2]) torch.Size([18, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([20, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 32, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 32, 2]) torch.Size([28, 2]) torch.Size([23, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([21, 2]) torch.Size([22, 2])\n",
      "points1 shape:  torch.Size([1, 27, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 27, 2]) torch.Size([21, 2]) torch.Size([23, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([24, 2]) torch.Size([15, 2])\n",
      "points1 shape:  torch.Size([1, 21, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 21, 2]) torch.Size([21, 2]) torch.Size([16, 2])\n",
      "points1 shape:  torch.Size([1, 24, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 24, 2]) torch.Size([24, 2]) torch.Size([23, 2])\n",
      "points1 shape:  torch.Size([1, 22, 2]) mask_t shape:  torch.Size([1, 1, 120, 120])\n",
      "shape p & f torch.Size([1, 22, 2]) torch.Size([20, 2]) torch.Size([11, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs_batch, labels_batch \u001b[38;5;129;01min\u001b[39;00m pbar:  \u001b[38;5;66;03m# Itera em todo o dataset\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     imgs_batch \u001b[38;5;241m=\u001b[39m imgs_batch\u001b[38;5;241m.\u001b[39mto(device)    \n\u001b[0;32m---> 19\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_extract_feat_in_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     matches_total\u001b[38;5;241m.\u001b[39mappend(mean)\n\u001b[1;32m     21\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Match Mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(matches_total)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n",
      "Cell \u001b[0;32mIn[14], line 144\u001b[0m, in \u001b[0;36mdetect_extract_feat_in_batch\u001b[0;34m(batch1, aug_list, detector)\u001b[0m\n\u001b[1;32m    141\u001b[0m img2,mask_t,ponts_t\u001b[38;5;241m=\u001b[39maug_list\u001b[38;5;241m.\u001b[39maugmentation_sequence(img1,mask,points1,params\u001b[38;5;241m=\u001b[39mparams)           \n\u001b[1;32m    143\u001b[0m img2 \u001b[38;5;241m=\u001b[39m img2\u001b[38;5;241m.\u001b[39mto(img1\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 144\u001b[0m lafs2, resps2 \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m points2 \u001b[38;5;241m=\u001b[39mkornia\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mget_laf_center(lafs2)     \n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints1 shape: \u001b[39m\u001b[38;5;124m'\u001b[39m,points1\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_t shape: \u001b[39m\u001b[38;5;124m'\u001b[39m,mask_t\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/feature/scale_space_detector.py:436\u001b[0m, in \u001b[0;36mMultiResolutionDetector.forward\u001b[0;34m(self, img, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Three stage local feature detection.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03mFirst the location and scale of interest points are determined by detect function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m KORNIA_CHECK_SHAPE(img, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 436\u001b[0m responses, lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maff(lafs, img)\n\u001b[1;32m    438\u001b[0m lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mori(lafs, img)\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/feature/scale_space_detector.py:408\u001b[0m, in \u001b[0;36mMultiResolutionDetector.detect\u001b[0;34m(self, img, mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m     res_points \u001b[38;5;241m=\u001b[39m tensor(nf2)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    406\u001b[0m     num_points_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(res_points)\n\u001b[0;32m--> 408\u001b[0m cur_scores, cur_lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_features_on_single_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_points_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m all_responses\u001b[38;5;241m.\u001b[39mappend(cur_scores\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    410\u001b[0m all_lafs\u001b[38;5;241m.\u001b[39mappend(cur_lafs)\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/feature/scale_space_detector.py:354\u001b[0m, in \u001b[0;36mMultiResolutionDetector.detect_features_on_single_level\u001b[0;34m(self, level_img, num_kp, factor)\u001b[0m\n\u001b[1;32m    352\u001b[0m yx \u001b[38;5;241m=\u001b[39m yx[:, indices[:num_kp]]\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m    353\u001b[0m current_kp_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(yx)\n\u001b[0;32m--> 354\u001b[0m xy_projected \u001b[38;5;241m=\u001b[39m \u001b[43myx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_kp_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m tensor(factor, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    355\u001b[0m scale_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (factor[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m factor[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    356\u001b[0m scale \u001b[38;5;241m=\u001b[39m scale_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmr_size \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, current_kp_num, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "aug_gen = AugmentationGenerator(15)\n",
    "image = torch.rand(1, 1, 120, 120)  # Imagem com valores aleatórios\n",
    "mask = torch.ones(1, 1, 120, 120)  # Máscara binária\n",
    "keypoints = torch.tensor([[[30, 30], [90, 90]]], dtype=torch.float32)  # Pontos chave de exemplo\n",
    "\n",
    "# Gerar as variações\n",
    "aug_gen.generate_variations_with_mask_and_keypoints(image, mask, keypoints)\n",
    "\n",
    "for i, ((dataset_name, dataloader), (class_name, detector)) in enumerate(combinations, 1):\n",
    "    matches_total = []\n",
    "    pbar = tqdm(dataloader, desc=f\"Evaluation {class_name}-{dataset_name}\")  # Usando f-string para formatar o nome da classe do detector\n",
    "    for imgs_batch, labels_batch in pbar:  # Itera em todo o dataset\n",
    "        imgs_batch = imgs_batch.to(device)    \n",
    "        mean = detect_extract_feat_in_batch(imgs_batch, aug_gen, detector)\n",
    "        matches_total.append(mean)\n",
    "        pbar.set_postfix({\"Dataset Match Mean\": f\"{np.mean(matches_total):.4f}\"})\n",
    "        aug_gen.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation KeyNetDetector-flower: 100% 102/102 [05:33<00:00,  2.52s/it, Dataset Match Mean=11.0770]\n",
    "Evaluation REKDSosNet-flower: 100% 102/102 [05:05<00:00,  2.32s/it, Dataset Match Mean=30.2933]\n",
    "Evaluation SingularPointSosNet-flower: 100% 102/102 [07:20<00:00,  3.29s/it, Dataset Match Mean=40.1591]\n",
    "\n",
    "Evaluation KeyNetDetector-fibers: 100% 9/9 [00:18<00:00,  2.03s/it, Dataset Match Mean=10.4233]\n",
    "Evaluation REKDSosNet-fibers: 100% 9/9 [00:14<00:00,  1.57s/it, Dataset Match Mean=3.6245]\n",
    "Evaluation SingularPointSosNet-fibers: 100% 9/9 [00:29<00:00,  3.26s/it, Dataset Match Mean=42.1785]\n",
    "\n",
    "Evaluation KeyNetDetector-woods: 100% 256/256 [07:16<00:00,  1.44s/it, Dataset Match Mean=13.1803]\n",
    "Evaluation REKDSosNet-woods: 100% 256/256 [06:11<00:00,  1.17s/it, Dataset Match Mean=21.7026]\n",
    "Evaluation SingularPointSosNet-woods: 100% 256/256 [09:06<00:00,  1.92s/it, Dataset Match Mean=37.6250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singular-points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

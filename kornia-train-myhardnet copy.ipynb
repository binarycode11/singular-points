{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from meu_dataset import MeuDataset,avaliar_descritor,calcular_matching\n",
    "from teste_util import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_dataset = \"./data/datasets/features_path_flowers_dataset.pt\"\n",
    "# Carregar o dataset do arquivo \"meu_dataset.pt\"\n",
    "meu_dataset = MeuDataset.load_from_file(path_dataset)\n",
    "#verificar se o objeto meu dataset está retornando o tensor correto\n",
    "assert isinstance(meu_dataset,MeuDataset), 'o tipo de retorno não é MeuDataset'\n",
    "assert isinstance(meu_dataset[0][0],torch.Tensor), 'o tipo de retorno não é torch.Tensor'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "batch_size_siam = 50\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(meu_dataset, [0.5,0.3,0.2])\n",
    "\n",
    "# Crie uma instância do DataLoader usando seu conjunto de dados personalizado\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size_siam, shuffle=False)\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=batch_size_siam, shuffle=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size_siam, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(a, b):\n",
    "    a_norm = torch.nn.functional.normalize(a, dim=-1)\n",
    "    b_norm = torch.nn.functional.normalize(b, dim=-1)\n",
    "    return torch.mm(a_norm, b_norm.T)\n",
    "\n",
    "def my_similarity(a, b):\n",
    "    a_norm = torch.nn.functional.normalize(a, dim=-1)\n",
    "    b_norm = torch.nn.functional.normalize(b, dim=-1)\n",
    "    return torch.cdist(a_norm, b_norm, p=2)\n",
    "\n",
    "# Triplet loss function\n",
    "def triplet_loss(anchor, positive, negative, margin=0.2):\n",
    "    similarities = my_similarity(anchor, positive)\n",
    "    # Calcular a média da diagonal principal (âncoras vs. seus respectivos positivos)\n",
    "    mean_diagonal = torch.mean(torch.diagonal(similarities))\n",
    "    # Calcular a média dos outros elementos (âncoras vs. positivos não correspondentes)\n",
    "    mean_other = torch.mean(similarities[~torch.eye(similarities.shape[0], dtype=torch.bool)])\n",
    "    \n",
    "    # losses = torch.relu(mean_other - mean_diagonal + margin)# losses considerando similaridade de cosseno\n",
    "    losses = torch.relu(mean_diagonal - mean_other + margin)# losses considerando similaridade de cosseno\n",
    "    # print(losses,mean_diagonal,mean_other)\n",
    "    # losses = torch.relu(pos_similarity - neg_similarity + margin)\n",
    "    return losses\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer, loss_fn, device='cpu', is_training=True):\n",
    "    model.train(is_training)\n",
    "    total_loss = 0.\n",
    "\n",
    "    progress_bar = tqdm(data_loader)\n",
    "    for idx, data in enumerate(progress_bar):\n",
    "        # Extract the anchor and positive batches\n",
    "        anchor_batch, positive_batch = (\n",
    "            data[0].to(device),\n",
    "            data[1].to(device),\n",
    "        )\n",
    "\n",
    "        # Calculate descriptors for the anchor and positive images\n",
    "        descs_anchor = model(anchor_batch)\n",
    "        descs_pos = model(positive_batch)\n",
    "\n",
    "        # Calculate the triplet loss\n",
    "        loss = loss_fn(descs_anchor, descs_pos, None, margin=3.0)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'Loss: {loss.item()} - Total Loss: {total_loss/len(data_loader)}')\n",
    "\n",
    "    return total_loss/len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2cnn import gspaces\n",
    "from e2cnn import nn as enn    #the equivariant layer we need to build the model\n",
    "from torch import nn\n",
    "\n",
    "class Feature(nn.Module):\n",
    "    def __init__(self,n_channel=2) -> None:\n",
    "        super().__init__()\n",
    "        pool_size1=6\n",
    "        pool_size2=3\n",
    "        mult_fist_block = 4\n",
    "        n_group = 12\n",
    "        r2_act = gspaces.Rot2dOnR2(N=n_group)\n",
    "\n",
    "        feat_type_in  = enn.FieldType(r2_act,  n_channel*[r2_act.trivial_repr])\n",
    "        feat_type_out = enn.FieldType(r2_act, mult_fist_block*n_channel*[r2_act.regular_repr])\n",
    "        self.input_type = feat_type_in\n",
    "\n",
    "        self.block1 = enn.SequentialModule(\n",
    "                enn.R2Conv(feat_type_in, feat_type_out, kernel_size=5, padding=0, bias=False),\n",
    "                enn.InnerBatchNorm(feat_type_out),\n",
    "                enn.ReLU(feat_type_out, inplace=True),\n",
    "                enn.GroupPooling(feat_type_out),\n",
    "                )\n",
    "        self.pool1 = enn.PointwiseAdaptiveAvgPool(self.block1.out_type,pool_size1)\n",
    "        self.pool2 = enn.PointwiseAdaptiveAvgPool(self.block1.out_type,pool_size2)\n",
    "        \n",
    "        # size_after_pool = n_channel*((pool_size1**2)+(pool_size2**2))\n",
    "        size_after_pool = mult_fist_block*n_channel*((pool_size1**2))\n",
    "        self.dense1 = nn.Linear(size_after_pool, size_after_pool//3)\n",
    "        self.dense2 = nn.Linear(size_after_pool//3, 128)\n",
    "        self.dense3 = nn.Linear(size_after_pool//8, 128)\n",
    "        \n",
    "        self.droupout = nn.Dropout(0.2)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self,X1)->torch.Tensor:\n",
    "        x = enn.GeometricTensor(X1, self.input_type)\n",
    "        n_dim = X1.shape[-1]\n",
    "        mask = enn.MaskModule(self.input_type, n_dim, margin=2).to(X1.device)\n",
    "        x = mask(x)\n",
    "        # mais features\n",
    "        x = self.block1(x)\n",
    "        \n",
    "        # pooling de media\n",
    "        x1 = self.pool1(x)\n",
    "        x2 = self.pool2(x)            \n",
    "        \n",
    "        # flatten\n",
    "        x1 = x1.tensor.reshape(x1.shape[0],-1)\n",
    "        # x2 = x2.tensor.reshape(x2.shape[0],-1)\n",
    "        \n",
    "        # x3 = torch.cat((x1,x2),dim=1)\n",
    "        # print(x1.shape,x2.shape,x3.shape)\n",
    "        # rede densa\n",
    "        x3 = self.droupout(self.dense1(x1))\n",
    "        x3 = self.activation(x3)\n",
    "        x3 = self.droupout(self.dense2(x3))\n",
    "        x3 = self.activation(x3)\n",
    "        # x3 = self.droupout(self.dense3(x3))\n",
    "        # x3 = self.activation(x3)\n",
    "        return x3\n",
    "    \n",
    "n_channel =8\n",
    "model =Feature(n_channel=n_channel).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.491128444671631 - Total Loss: 2.4969415863355002: 100%|██████████| 60/60 [00:02<00:00, 20.89it/s] \n",
      "Loss: 2.102372407913208 - Total Loss: 2.105892797311147: 100%|██████████| 36/36 [00:00<00:00, 38.91it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200] - Running Loss: 2.4969, Test Loss: 2.1059, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.41430926322937 - Total Loss: 2.408060952027639: 100%|██████████| 60/60 [00:02<00:00, 20.30it/s]   \n",
      "Loss: 2.099515676498413 - Total Loss: 2.0315516193707785: 100%|██████████| 36/36 [00:00<00:00, 37.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] - Running Loss: 2.4081, Test Loss: 2.0316, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.316608190536499 - Total Loss: 2.417895205815633: 100%|██████████| 60/60 [00:02<00:00, 20.86it/s]   \n",
      "Loss: 2.26814341545105 - Total Loss: 2.102235794067383: 100%|██████████| 36/36 [00:00<00:00, 38.61it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200] - Running Loss: 2.4179, Test Loss: 2.1022, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3740458488464355 - Total Loss: 2.389464318752289: 100%|██████████| 60/60 [00:02<00:00, 21.12it/s]  \n",
      "Loss: 2.0328917503356934 - Total Loss: 1.9876831240124173: 100%|██████████| 36/36 [00:00<00:00, 38.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200] - Running Loss: 2.3895, Test Loss: 1.9877, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4217844009399414 - Total Loss: 2.4046576023101807: 100%|██████████| 60/60 [00:02<00:00, 21.16it/s]\n",
      "Loss: 2.109236717224121 - Total Loss: 2.009805699189504: 100%|██████████| 36/36 [00:00<00:00, 38.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200] - Running Loss: 2.4047, Test Loss: 2.0098, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.378255605697632 - Total Loss: 2.3858689308166503: 100%|██████████| 60/60 [00:02<00:00, 21.18it/s] \n",
      "Loss: 2.0035934448242188 - Total Loss: 1.9474282761414845: 100%|██████████| 36/36 [00:00<00:00, 38.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200] - Running Loss: 2.3859, Test Loss: 1.9474, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3570594787597656 - Total Loss: 2.3569136102994284: 100%|██████████| 60/60 [00:02<00:00, 21.24it/s]\n",
      "Loss: 2.101142406463623 - Total Loss: 1.9836554494169023: 100%|██████████| 36/36 [00:00<00:00, 38.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200] - Running Loss: 2.3569, Test Loss: 1.9837, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3924570083618164 - Total Loss: 2.3761433601379394: 100%|██████████| 60/60 [00:02<00:00, 21.10it/s] \n",
      "Loss: 2.097047805786133 - Total Loss: 1.9826716317070856: 100%|██████████| 36/36 [00:00<00:00, 37.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200] - Running Loss: 2.3761, Test Loss: 1.9827, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2674641609191895 - Total Loss: 2.355623122056325: 100%|██████████| 60/60 [00:02<00:00, 20.51it/s] \n",
      "Loss: 2.0555598735809326 - Total Loss: 1.9590865704748366: 100%|██████████| 36/36 [00:01<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200] - Running Loss: 2.3556, Test Loss: 1.9591, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.385672092437744 - Total Loss: 2.3523756663004556: 100%|██████████| 60/60 [00:02<00:00, 20.77it/s] \n",
      "Loss: 2.1827454566955566 - Total Loss: 2.0762491722901664: 100%|██████████| 36/36 [00:00<00:00, 37.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200] - Running Loss: 2.3524, Test Loss: 2.0762, Initial LR: 0.010000, Current LR: 0.010000, Epochs without Improvement: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.313458204269409 - Total Loss: 2.3824081818262735: 100%|██████████| 60/60 [00:02<00:00, 20.74it/s] \n",
      "Loss: 2.0927534103393555 - Total Loss: 1.973212589820226: 100%|██████████| 36/36 [00:00<00:00, 36.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./data/models/feature_flowers_sp.pt\n",
      "Epoch [10/200] - Running Loss: 2.3824, Test Loss: 1.9732, Initial LR: 0.010000, Current LR: 0.007500, Epochs without Improvement: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.30610728263855 - Total Loss: 2.3316495537757875: 100%|██████████| 60/60 [00:02<00:00, 20.77it/s]   \n",
      "Loss: 2.030424118041992 - Total Loss: 1.9428491989771526: 100%|██████████| 36/36 [00:00<00:00, 36.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200] - Running Loss: 2.3316, Test Loss: 1.9428, Initial LR: 0.010000, Current LR: 0.007500, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3141286373138428 - Total Loss: 2.348312199115753: 100%|██████████| 60/60 [00:02<00:00, 20.81it/s] \n",
      "Loss: 2.0214011669158936 - Total Loss: 1.9344875514507294: 100%|██████████| 36/36 [00:00<00:00, 37.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200] - Running Loss: 2.3483, Test Loss: 1.9345, Initial LR: 0.010000, Current LR: 0.007500, Epochs without Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3280601501464844 - Total Loss: 2.3254806756973267: 100%|██████████| 60/60 [00:02<00:00, 20.86it/s]\n",
      "Loss: 1.9768012762069702 - Total Loss: 1.9375328653388553: 100%|██████████| 36/36 [00:00<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200] - Running Loss: 2.3255, Test Loss: 1.9375, Initial LR: 0.010000, Current LR: 0.007500, Epochs without Improvement: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3834986686706543 - Total Loss: 2.231308122475942:  95%|█████████▌| 57/60 [00:02<00:00, 20.52it/s] "
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "def train(model,dataloader_train,dataloader_val):\n",
    "    optimizer_siamese = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "    scheduler = ExponentialLR(optimizer_siamese, gamma=0.75)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    epochs_without_improvement = 0\n",
    "    epochs = 200\n",
    "    patience = 50\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(model,dataloader_train , optimizer_siamese, triplet_loss, device=device, is_training=True)\n",
    "        with torch.no_grad():\n",
    "            test_loss = train_one_epoch(model,dataloader_val , optimizer_siamese, triplet_loss, device=device, is_training=False)\n",
    "\n",
    "        # Verificar se a perda melhorou\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model = model.state_dict()        \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if (epoch % 10 == 0) and (epoch != 0):\n",
    "            scheduler.step()\n",
    "            save_model(model, PATH_MODEL)\n",
    "        \n",
    "        # Verificar a condição de parada\n",
    "        if epochs_without_improvement == patience:\n",
    "            print(f\"No improvement in loss for {epochs_without_improvement} epochs. Training stopped.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - Running Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Initial LR: {optimizer_siamese.param_groups[0]['initial_lr']:.6f}, Current LR: {optimizer_siamese.param_groups[0]['lr']:.6f}, Epochs without Improvement: {epochs_without_improvement}\")\n",
    "\n",
    "    # Carregar a melhor configuração do modelo\n",
    "    model.load_state_dict(best_model)\n",
    "    print(f'Epoch: {epoch}, Best Loss: {best_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "PATH_MODEL = './data/models/feature_flowers_sp.pt'\n",
    "model = train(model,dataloader_train,dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, PATH_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODEL = './data/models/feature_flowers_sp.pt'\n",
    "model =Feature(n_channel=8)\n",
    "model.to(device)\n",
    "load_model(model, PATH_MODEL,device)\n",
    "\n",
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test, model,th=0.02)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test, model,th=0.32)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refazer o treinamento para fazer o descritor na imagem original ao inves da feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"./data/datasets/img_path_flowers_dataset.pt\"\n",
    "meu_dataset2 = MeuDataset.load_from_file(path_dataset)\n",
    "train_dataset2, val_dataset2, test_dataset2 = random_split(meu_dataset2, [0.5,0.3,0.2])\n",
    "\n",
    "# Crie uma instância do DataLoader usando seu conjunto de dados personalizado\n",
    "dataloader_train2 = DataLoader(train_dataset2, batch_size=batch_size_siam, shuffle=True)\n",
    "dataloader_val2 = DataLoader(val_dataset2, batch_size=batch_size_siam, shuffle=True)\n",
    "dataloader_test2 = DataLoader(test_dataset2, batch_size=batch_size_siam, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel =1\n",
    "model =Feature(n_channel=n_channel).to(device)\n",
    "PATH_MODEL = './data/models/img_flowers_sp.pt'\n",
    "model = train(model,dataloader_train2,dataloader_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =model.eval()\n",
    "with torch.no_grad():\n",
    "    total_acertos,total_erros,total_elementos = avaliar_descritor(dataloader_test2, model,th=0.2)\n",
    "sub_conjunto = total_elementos//2\n",
    "print(f'Total de elementos no DataLoader: {total_elementos}')\n",
    "print(f'Acertei: {total_acertos}/{sub_conjunto} Errei: {total_erros}/{sub_conjunto}')\n",
    "save_model(model, PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2cnn import gspaces\n",
    "from e2cnn import nn as enn    #the equivariant layer we need to build the model\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Feature(nn.Module):\n",
    "    def __init__(self,n_channel=2) -> None:\n",
    "        super().__init__()\n",
    "        pool_size1=9\n",
    "        pool_size2=3\n",
    "        n_group = 12\n",
    "        r2_act = gspaces.Rot2dOnR2(N=n_group)\n",
    "\n",
    "        feat_type_in  = enn.FieldType(r2_act,  n_channel*[r2_act.trivial_repr])\n",
    "        feat_type_out = enn.FieldType(r2_act, n_channel*[r2_act.regular_repr])\n",
    "        self.input_type = feat_type_in\n",
    "\n",
    "        self.block1 = enn.SequentialModule(\n",
    "                enn.R2Conv(feat_type_in, feat_type_out, kernel_size=5, padding=0, bias=False),\n",
    "                enn.InnerBatchNorm(feat_type_out),\n",
    "                enn.ReLU(feat_type_out, inplace=True),\n",
    "                # enn.GroupPooling(feat_type_out),\n",
    "                )\n",
    "        self.pool1 = enn.PointwiseAdaptiveAvgPool(self.block1.out_type,pool_size1)\n",
    "        self.pool2 = enn.PointwiseAdaptiveAvgPool(self.block1.out_type,pool_size2)\n",
    "        \n",
    "        # size_after_pool = n_channel*n_group*((pool_size1**2)+(pool_size2**2))\n",
    "        size_after_pool = n_channel*n_group*((pool_size1**2))\n",
    "        self.dense1 = nn.Linear(size_after_pool, size_after_pool//3)\n",
    "        self.dense2 = nn.Linear(size_after_pool//3, 128)\n",
    "        self.dense3 = nn.Linear(size_after_pool//8, 128)\n",
    "        \n",
    "        self.droupout = nn.Dropout(0.2)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self,X1)->torch.Tensor:\n",
    "        x = enn.GeometricTensor(X1, self.input_type)\n",
    "        n_dim = X1.shape[-1]\n",
    "        mask = enn.MaskModule(self.input_type, n_dim, margin=2).to(X1.device)\n",
    "        x = mask(x)\n",
    "        # mais features\n",
    "        x = self.block1(x)\n",
    "        \n",
    "        # pooling de media\n",
    "        x1 = self.pool1(x)\n",
    "        x2 = self.pool2(x)            \n",
    "        \n",
    "        # flatten\n",
    "        x1 = x1.tensor.reshape(x1.shape[0],-1)\n",
    "        # x2 = x2.tensor.reshape(x2.shape[0],-1)\n",
    "        \n",
    "        # x3 = torch.cat((x1,x2),dim=1)\n",
    "        # print(x1.shape,x2.shape,x3.shape)\n",
    "        # rede densa\n",
    "        x3 = self.droupout(self.dense1(x1))\n",
    "        x3 = self.activation(x3)\n",
    "        x3 = self.droupout(self.dense2(x3))\n",
    "        x3 = self.activation(x3)\n",
    "        # x3 = self.droupout(self.dense3(x3))\n",
    "        # x3 = self.activation(x3)\n",
    "        return x3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_channel =8\n",
    "model =Feature(n_channel=n_channel).to(device)\n",
    "image_a =torch.rand(4,n_channel,32,32).to(device)\n",
    "image_p =torch.rand(4,n_channel,32,32).to(device)\n",
    "\n",
    "\n",
    "# Calculate descriptors for the anchor and positive images\n",
    "descs_anchor = model(image_a)\n",
    "descs_pos = model(image_p)\n",
    "\n",
    "torch.ones(4, 1)\n",
    "# Calculate distances/similarities between anchor and all examples in the batch\n",
    "distances = cosine_similarity(descs_anchor, descs_pos)  # Broadcasting\n",
    "print(\"distances \",distances)\n",
    "# Choose the hardest negative example for each anchor\n",
    "hard_negatives = torch.argmin(distances, dim=1)  # Get the index of the minimum similarity for each anchor\n",
    "\n",
    "def similarity(desc1, desc2):\n",
    "    desc1_norm = torch.nn.functional.normalize(desc1, dim=-1)\n",
    "    desc2_norm = torch.nn.functional.normalize(desc2, dim=-1)\n",
    "    return torch.sum(desc1_norm * desc2_norm)\n",
    "\n",
    "print(descs_anchor.shape, descs_pos.shape)\n",
    "similarity(descs_anchor, descs_pos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

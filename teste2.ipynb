{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_best_matching_indices_knn(points1, points2, threshold, k=3):\n",
    "    distances = cdist(points1, points2)\n",
    "    best_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    best_distances = np.take_along_axis(distances, best_indices, axis=1)\n",
    "\n",
    "    matched = []\n",
    "\n",
    "    for i in range(len(points1)):\n",
    "        min_distance = np.min(best_distances[i])\n",
    "        if min_distance < threshold:\n",
    "            best_index = np.argmin(best_distances[i])\n",
    "            matched.append((i, best_indices[i, best_index]))\n",
    "\n",
    "    return matched\n",
    "\n",
    "\n",
    "def find_matching_in_batch(batch_points1, batch_points2, threshold):\n",
    "    # Lista para armazenar as correspondências\n",
    "    lista_correspondencias = []\n",
    "\n",
    "    # Iterar sobre o lote de pontos\n",
    "    for i in range(batch_points1.shape[0]):\n",
    "        # Obter os pontos correspondentes entre duas imagens\n",
    "        correspondencias = find_best_matching_indices_knn(batch_points1[i], batch_points2[i], threshold)\n",
    "        lista_correspondencias.append(correspondencias)\n",
    "\n",
    "    return lista_correspondencias\n",
    "\n",
    "def evaluates_repeatability(_kp1, _kp2,batch_size=1):\n",
    "    \n",
    "    lista_correspondencias = find_matching_in_batch(_kp1, _kp2, 2.5)\n",
    "    num_matchs = 0\n",
    "    num_matchs_with_outliers = 0\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        print(_kp1.shape, _kp2.shape)\n",
    "        pts1 = np.array([_kp1[i, match[0]] for match in lista_correspondencias[i]])\n",
    "        pts2 = np.array([_kp2[i, match[1]] for match in lista_correspondencias[i]])\n",
    "        num_matchs += len(lista_correspondencias[i])\n",
    "        \n",
    "        print(\"Quant. de correspondecias Posicionais: {}\".format(num_matchs))\n",
    "        \n",
    "        # Calcular a matriz fundamental usando o método RANSAC\n",
    "        fundamental_matrix, mask = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC, ransacReprojThreshold=1.0)\n",
    "        print(\"Fundamental Matrix:\")\n",
    "        print(fundamental_matrix)\n",
    "        # Filtrar os pontos correspondentes com base na máscara\n",
    "        pts1_filtered = pts1[mask.ravel().astype(bool)]\n",
    "        pts2_filtered = pts2[mask.ravel().astype(bool)]\n",
    "        num_matchs_with_outliers += mask.ravel().astype(bool).sum()\n",
    "        print(\"Correspondencias sem outliers {}\".format(num_matchs_with_outliers))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches_keypoints(image1, keypoints1, image2, keypoints2, matches, **kwargs):\n",
    "    # Concatenar as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((image1.cpu(), image2.cpu()), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(combined_image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Desenhar pontos correspondentes e linhas conectando-os\n",
    "    offset = image1.shape[1]\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints1.cpu()):\n",
    "        ax.plot(x, y, 'o',markerfacecolor='none', markeredgecolor='g',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x, y), color='g',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints2.cpu()):\n",
    "        ax.plot(x+offset, y, 'o',markerfacecolor='none', markeredgecolor='g',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x+offset, y), color='g',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "    try:\n",
    "        for match in matches:\n",
    "            x1, y1 = keypoints1[match[0],0], keypoints1[match[0],1]\n",
    "            x2, y2 = keypoints2[match[1],0]+offset, keypoints2[match[1],1]\n",
    "            ax.plot([x1, x2], [y1, y2], '-', color='lime', lw=0.5)\n",
    "    except:\n",
    "        print(\"Erro ao plotar correspondencias\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'kornia.augmentation' has no attribute 'AugmentationSequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     random\u001b[38;5;241m.\u001b[39mseed(seed)\u001b[38;5;66;03m# Definir a semente para o módulo random do Python\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\u001b[38;5;66;03m# Definir a semente para o módulo numpy\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m data_augmentation \u001b[38;5;241m=\u001b[39m \u001b[43mKA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAugmentationSequential\u001b[49m(\n\u001b[1;32m     17\u001b[0m     KA\u001b[38;5;241m.\u001b[39mRandomAffine(degrees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m180\u001b[39m, translate\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m), scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.95\u001b[39m, \u001b[38;5;241m1.05\u001b[39m), shear\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m),\n\u001b[1;32m     18\u001b[0m     KA\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     19\u001b[0m     KA\u001b[38;5;241m.\u001b[39mRandomVerticalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     20\u001b[0m     same_on_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     data_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlaf_to_xy\u001b[39m(lafs):\n\u001b[1;32m     25\u001b[0m     xy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((lafs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],lafs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'kornia.augmentation' has no attribute 'AugmentationSequential'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import kornia.augmentation as KA\n",
    "from torchvision.transforms import transforms, InterpolationMode\n",
    "\n",
    "PONTOS = 10\n",
    "BATCH = 2\n",
    "\n",
    "# Definir a semente\n",
    "def seed_everything(seed=123):\n",
    "    torch.manual_seed(seed) # Definir a semente para PyTorch\n",
    "    random.seed(seed)# Definir a semente para o módulo random do Python\n",
    "    np.random.seed(seed)# Definir a semente para o módulo numpy\n",
    "    \n",
    "data_augmentation = KA.AugmentationSequential(\n",
    "    KA.RandomAffine(degrees=180, translate=(0.1, 0.1), scale=(0.95, 1.05), shear=10, p=0.8),\n",
    "    KA.RandomHorizontalFlip(p=0.5),\n",
    "    KA.RandomVerticalFlip(p=0.5),\n",
    "    same_on_batch=False,\n",
    "    data_keys=[\"input\", \"keypoints\"]\n",
    ")\n",
    "\n",
    "def laf_to_xy(lafs):\n",
    "    xy = torch.zeros((lafs.shape[0],lafs.shape[1], 2))\n",
    "    xy[:,:, 0] = lafs[:,:,0, 2]\n",
    "    xy[:,:, 1] = lafs[:,:,1, 2]\n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kornia.feature as KF\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms, InterpolationMode\n",
    "import kornia_moons.feature as KMF\n",
    "import kornia.augmentation as KA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_and_match(first_batch,second_batch,keynet_hardnet,matcher):\n",
    "    laf1, _, desc1 = keynet_hardnet(first_batch)\n",
    "    laf2, _, desc2 = keynet_hardnet(second_batch)\n",
    "    \n",
    "    \n",
    "    kp1 =laf_to_xy(laf1.detach().numpy())\n",
    "    kp2 =laf_to_xy(laf2.detach().numpy())\n",
    "    \n",
    "    # print(laf1.shape,kp1.shape,desc1.shape)\n",
    "    \n",
    "    # Remove a dimensão extra dos descritores\n",
    "    desc1 = desc1[0]\n",
    "    desc2 = desc2[0]\n",
    "    \n",
    "    # Realiza a correspondência dos descritores\n",
    "    dist,matches = matcher(desc1, desc2)\n",
    "    # print(dist.shape,matches.shape)\n",
    "    \n",
    "    return kp1,kp2,matches\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((120,120), interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.Flowers102(root='./data/datasets', split='train',\n",
    "                                        download=True, transform=transform2)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "keynet_hardnet = KF.KeyNetHardNet()\n",
    "matcher = KF.DescriptorMatcher('snn', 0.5)\n",
    "seed_everything()\n",
    "\n",
    "for data in trainloader:\n",
    "    first_batch,_ = data\n",
    "    laf1, _, desc1 = keynet_hardnet(first_batch)\n",
    "    kp1 =laf_to_xy(laf1)\n",
    "\n",
    "    second_batch, keypoints_trans = data_augmentation(first_batch, kp1)  # Realizar transformações de aumento de dados\n",
    "    laf2, _, desc2 = keynet_hardnet(first_batch)\n",
    "    kp2 =laf_to_xy(laf2)\n",
    "    \n",
    "    print(keypoints_trans.shape,kp2.shape,type(keypoints_trans))\n",
    "    evaluates_repeatability(keypoints_trans.detach().numpy(),kp2.detach().numpy())\n",
    "    print(kp1[0,:5].cpu())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_matching_points(keypoints1, keypoints2, threshold):\n",
    "    matches = []\n",
    "    \n",
    "    for i, kp1 in enumerate(keypoints1):\n",
    "        best_match = None\n",
    "        best_distance = float('inf')\n",
    "        \n",
    "        for j, kp2 in enumerate(keypoints2):\n",
    "            distance = np.linalg.norm(np.array(kp1.pt) - np.array(kp2.pt))\n",
    "            \n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = j\n",
    "        \n",
    "        if best_distance < threshold:\n",
    "            matches.append(cv2.DMatch(i, best_match, best_distance))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "# keypoints1 e keypoints2 são listas de keypoints usando a estrutura cv2.KeyPoint do OpenCV\n",
    "keypoints1 = [cv2.KeyPoint(10, 20, 1.0), cv2.KeyPoint(30, 40, 1.0), cv2.KeyPoint(50, 60, 1.0)]\n",
    "keypoints2 = [cv2.KeyPoint(12, 22, 1.0), cv2.KeyPoint(28, 38, 1.0), cv2.KeyPoint(55, 65, 1.0)]\n",
    "threshold = 10.0\n",
    "\n",
    "matches = find_matching_points(keypoints1, keypoints2, threshold)\n",
    "\n",
    "# Imprimir correspondências encontradas\n",
    "for match in matches:\n",
    "    print(f\"Keypoint 1: {match.queryIdx}, Keypoint 2: {match.trainIdx}, Distance: {match.distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_matching_points(keypoints1, keypoints2, threshold):\n",
    "    # Converter os keypoints em matrizes NumPy com tipo CV_32F\n",
    "    keypoints1_np = np.array([kp.pt for kp in keypoints1], dtype=np.float32)\n",
    "    keypoints2_np = np.array([kp.pt for kp in keypoints2], dtype=np.float32)\n",
    "\n",
    "    # Inicializar o matcher de força bruta\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2)  # Usando a métrica de distância L2\n",
    "\n",
    "    # Encontrar correspondências entre os keypoints\n",
    "    matches = matcher.match(keypoints1_np, keypoints2_np)\n",
    "\n",
    "    # Filtrar correspondências com base no threshold\n",
    "    good_matches = [match for match in matches if match.distance < threshold]\n",
    "\n",
    "    return good_matches\n",
    "\n",
    "# Exemplo de uso\n",
    "keypoints1 = [cv2.KeyPoint(10, 20, 1.0), cv2.KeyPoint(30, 40, 1.0), cv2.KeyPoint(50, 60, 1.0)]\n",
    "keypoints2 = [cv2.KeyPoint(12, 22, 1.0), cv2.KeyPoint(28, 38, 1.0), cv2.KeyPoint(55, 65, 1.0)]\n",
    "threshold = 10.0\n",
    "\n",
    "matches = find_matching_points(keypoints1, keypoints2, threshold)\n",
    "\n",
    "# Imprimir correspondências encontradas\n",
    "for match in matches:\n",
    "    print(match.queryIdx, match.trainIdx, match.distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

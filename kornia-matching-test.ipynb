{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wagner/anaconda3/envs/singular-points/lib/python3.9/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647327249/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  full_mask[mask] = norms.to(torch.uint8)\n",
      "/home/wagner/Documentos/python/singular-points2/teste_util.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filepath,map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./data/models/sp_map_fo_30.pth\n",
      "Model loaded from ./data/models/sp_map_fo_30.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_743046/2773550758.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "# Imports organizados por funcionalidade\n",
    "import torch\n",
    "from torch import nn\n",
    "import kornia\n",
    "import itertools\n",
    "from teste_util import read_dataload_flower, set_seed\n",
    "from custom_local_feature import REKDSosNet, SingularPointSosNet\n",
    "from external.hardnet_pytorch import HardNet\n",
    "\n",
    "# Configurações iniciais\n",
    "set_seed(42)  # Fixar a semente para reprodutibilidade\n",
    "# Leitura dos dados\n",
    "data_dir = './data/datasets'\n",
    "batch_size = 60\n",
    "train_loader, test_loader = read_dataload_flower(120, data_dir, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Configuração do detector de pontos-chave\n",
    "keypoint_detector_config = {\n",
    "    'num_filters': 8,\n",
    "    'num_levels': 3,\n",
    "    'kernel_size': 5,\n",
    "    'Detector_conf': {\n",
    "        'nms_size': 5,\n",
    "        'pyramid_levels': 0,\n",
    "        'up_levels': 0,\n",
    "        'scale_factor_levels': 1.0,\n",
    "        's_mult': 5.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "singular_point_detector = (\n",
    "    SingularPointSosNet(config=keypoint_detector_config, device=device)\n",
    "    ._initialize_detector(num_features=60, size_laf=32)\n",
    "    .to(device)\n",
    ")\n",
    "\n",
    "# Classe para o descritor HardNet\n",
    "class HardNetDescriptor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        hardnet = HardNet()\n",
    "        checkpoint_path = 'trained_models/pretrained_nets/HardNet++.pth'\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        hardnet.load_state_dict(checkpoint['state_dict'])\n",
    "        hardnet.eval()\n",
    "        hardnet.to(device)\n",
    "        self.model = hardnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Inicialização dos descritores\n",
    "hardnet_descriptor = HardNetDescriptor()\n",
    "sift_descriptor = kornia.feature.SIFTDescriptor(32, rootsift=True)\n",
    "\n",
    "# Dicionário com detectores e descritores já instanciados\n",
    "detectors = {\n",
    "    \"singular_point\": singular_point_detector,  # Instância do detector\n",
    "}\n",
    "\n",
    "descriptors = {\n",
    "    \"hardnet\": hardnet_descriptor,  # Instância do descritor HardNet\n",
    "    \"sift\": sift_descriptor,        # Instância do descritor SIFT\n",
    "}\n",
    "\n",
    "thresholds = {\n",
    "    \"alpha_threshold\": [0.5, 1.0, 1.5],  # Lista de thresholds\n",
    "}\n",
    "\n",
    "def generate_combinations(detectors, descriptors, thresholds):\n",
    "    # Produto cartesiano entre detectores, descritores e thresholds\n",
    "    return list(itertools.product(detectors.items(), descriptors.items(), thresholds[\"alpha_threshold\"]))\n",
    "\n",
    "# Gerar as combinações\n",
    "combinations = generate_combinations(detectors, descriptors, thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.feature import laf_from_center_scale_ori\n",
    "def convert_points_to_lafs(points,img1, PS=19,scale=6):\n",
    "    orient = kornia.feature.LAFOrienter(PS)#kornia.feature.LAFOrienter(PS)PassLAF()\n",
    "    scale_lafs = torch.ones(img1.shape[0],points.shape[1],1,1)*scale\n",
    "    scale_lafs = scale_lafs.to(img1.device)\n",
    "    points = points.to(img1.device)\n",
    "    lafs1 = laf_from_center_scale_ori(points,scale_lafs)\n",
    "    lafs2 = orient(lafs1, img1)\n",
    "    return lafs2\n",
    "    \n",
    "def extract_patches_simple(batch, lafs, PS=19):\n",
    "    imgs_patches = kornia.feature.extract_patches_from_pyramid(batch, lafs, PS)\n",
    "    imgs_patches =imgs_patches.reshape(-1,imgs_patches.shape[2],PS,PS)\n",
    "    return imgs_patches\n",
    "\n",
    "def plot_patches_side_by_side(imgs_patches):\n",
    "    num_imgs = imgs_patches.shape[0]  # Número de imagens\n",
    "    fig, axs = plt.subplots(1, num_imgs, figsize=(num_imgs*4, 4))\n",
    "\n",
    "    axs = axs.reshape((1, num_imgs))  # Ajustar a forma para matriz 2D com uma única linha\n",
    "\n",
    "    for i in range(num_imgs):\n",
    "        axs[0, i].imshow(kornia.tensor_to_image(imgs_patches[i]))\n",
    "        axs[0, i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import kornia.feature as KF\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia as K\n",
    "\n",
    "def visualize_LAF(img, LAF, img_idx = 0):\n",
    "    x, y = KF.laf.get_laf_pts_to_draw(LAF, img_idx)\n",
    "    print(x[0][:5],y[0][:5])\n",
    "    plt.figure()\n",
    "    plt.imshow(K.utils.tensor_to_image(img[img_idx]))\n",
    "    plt.plot(x, y, 'r')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_matches_keypoints(image1, keypoints1, image2, keypoints2, matches, **kwargs):\n",
    "    print('image1 shape: ',image1.shape,image1.dtype,image2.shape,image2.dtype)\n",
    "    # Concatenar as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(combined_image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Desenhar pontos correspondentes e linhas conectando-os\n",
    "    offset = image1.shape[1]\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints1):\n",
    "        ax.plot(x, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints2):\n",
    "        ax.plot(x+offset, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x+offset, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for match in matches:\n",
    "        x1, y1 = keypoints1[match[0],0], keypoints1[match[0],1]\n",
    "        x2, y2 = keypoints2[match[1],0]+offset, keypoints2[match[1],1]\n",
    "        ax.plot([x1, x2], [y1, y2], '-', color='lime', lw=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_with_keypoints(image_tensor, keypoints_tensor):\n",
    "    # Converter a imagem tensorial em objeto PIL.Image\n",
    "    image = kornia.utils.tensor_to_image(image_tensor)\n",
    "    # Plotar a imagem e os keypoints\n",
    "    plt.imshow(image)\n",
    "    if keypoints_tensor is not None:\n",
    "        # Extrair as coordenadas x e y dos keypoints\n",
    "        keypoints_x = keypoints_tensor[:,0].flatten().tolist()\n",
    "        keypoints_y = keypoints_tensor[:,1].flatten().tolist()\n",
    "        plt.scatter(keypoints_x, keypoints_y, c='red')\n",
    "    plt.show()\n",
    "    \n",
    "def filtrar_keypoints(lista_de_pontos, tensor_mascara):\n",
    "    # Verificar se as coordenadas estão dentro das dimensões\n",
    "    dimensao_max_x, dimensao_max_y = tensor_mascara.shape[1] - 1, tensor_mascara.shape[0] - 1\n",
    "    pontos_filtrados = [\n",
    "        ponto.tolist()  for ponto in lista_de_pontos \n",
    "        if 0 <= ponto[0] <= dimensao_max_x \n",
    "        and 0 <= ponto[1] <= dimensao_max_y \n",
    "        and tensor_mascara[int(ponto[1]), int(ponto[0])] \n",
    "    ]\n",
    "    return torch.tensor(pontos_filtrados)\n",
    "\n",
    "def filtrar_keypoints_conjuntos(lista_de_pontos_1, lista_de_pontos_2, tensor_mascara):\n",
    "    dimensao_max_x, dimensao_max_y = tensor_mascara.shape[1] - 1, tensor_mascara.shape[0] - 1\n",
    "    pontos_filtrados_1 = []\n",
    "    pontos_filtrados_2 = []\n",
    "    \n",
    "    for ponto_1, ponto_2 in zip(lista_de_pontos_1.cpu(), lista_de_pontos_2.cpu()):\n",
    "        x, y = ponto_1\n",
    "        if 0 <= x <= dimensao_max_x and 0 <= y <= dimensao_max_y and tensor_mascara[int(y), int(x)]:\n",
    "            pontos_filtrados_1.append(ponto_1.numpy())\n",
    "            pontos_filtrados_2.append(ponto_2.numpy())\n",
    "            \n",
    "    return torch.tensor(pontos_filtrados_1), torch.tensor(pontos_filtrados_2)\n",
    "\n",
    "def find_best_matching_indices_knn(points1, points2, threshold, k=3):\n",
    "    if len(points1) == 0 or len(points2) == 0:\n",
    "        return []\n",
    "    distances = cdist(points1, points2)\n",
    "    best_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    best_distances = np.take_along_axis(distances, best_indices, axis=1)\n",
    "\n",
    "    matched = []\n",
    "\n",
    "    for i in range(len(points1)):\n",
    "        min_distance = np.min(best_distances[i])\n",
    "        if min_distance < threshold:\n",
    "            best_index = np.argmin(best_distances[i])\n",
    "            matched.append((i, best_indices[i, best_index]))\n",
    "\n",
    "    return matched\n",
    "\n",
    "def calcular_associacao(matches1, matches2):\n",
    "    intersecao = set(tuple(match) for match in matches1) & set(tuple(match) for match in matches2)\n",
    "    # assoc_score = len(intersecao) / min(matches1.shape[0], matches2.shape[0])\n",
    "    return intersecao #assoc_score\n",
    "\n",
    "\n",
    "def detect_extract_feat_in_batch(batch1,aug_list, detector,descritor,alpha_threshold):\n",
    "    total = []\n",
    "    intersecao_total = []\n",
    "    with torch.no_grad():\n",
    "        for img1  in batch1:            \n",
    "            lafs1, resps1 = detector(img1[None])\n",
    "            B,C,H,W = img1[None].shape\n",
    "            mask = torch.ones(B,C,H,W).to(img1.device) \n",
    "            #lafs1 to points1\n",
    "            points1 =kornia.feature.get_laf_center(lafs1)   \n",
    "\n",
    "            if( points1.shape[1] == 0):\n",
    "                # print('aug_list shape: ',points1.shape) \n",
    "                continue                    \n",
    "            params = next(aug_list)    \n",
    "            img2,mask_t,ponts_t=aug_list.augmentation_sequence(img1,mask,points1,params=params)    \n",
    "            img2 = img2.to(img1.device)                   \n",
    "            lafs2, resps2 = detector(img2)            \n",
    "            points2 =kornia.feature.get_laf_center(lafs2)\n",
    "            # visualize_LAF(img2, lafs2, 0)\n",
    "                        \n",
    "            # pontos filtrados com base da mascara\n",
    "            filtered_points1,filtered_points0 = filtrar_keypoints_conjuntos(ponts_t[0],points1[0],mask_t[0,0].bool())\n",
    "            filtered_points2 = filtrar_keypoints(points2[0],mask_t[0,0].bool())                        \n",
    "            # print('filtered shape: ',filtered_points1.shape,filtered_points2.shape)\n",
    "            if( filtered_points1.shape[0] == 0 or filtered_points2.shape[0] == 0):\n",
    "                # print('filtered shape: ',filtered_points1.shape,filtered_points2.shape)\n",
    "                continue                        \n",
    "            \n",
    "            matches = find_best_matching_indices_knn(filtered_points1.cpu(), filtered_points2.cpu(), threshold=alpha_threshold, k=1)\n",
    "            if(len(matches) == 0):\n",
    "                # print('matches shape: ',len(matches))\n",
    "                continue\n",
    "            \n",
    "            # print('filtered_points1 shape: ',filtered_points0.shape,filtered_points1.shape,filtered_points2.shape)\n",
    "            lafs1 = convert_points_to_lafs(filtered_points0[None],img1[None], PS=19,scale=5)\n",
    "            lafs2 = convert_points_to_lafs(filtered_points2[None],img2, PS=19,scale=5)\n",
    "            # print('lafs1 shape: ',lafs1.shape,lafs2.shape,img1.shape,img2.shape)\n",
    "            patch1 = extract_patches_simple(img1[None], lafs1, PS=32)# TODO 13 para sift e 32 hardnet\n",
    "            patch2 = extract_patches_simple(img2, lafs2, PS=32)# TODO 13 para sift e 32 hardnet\n",
    " \n",
    "            B, N, CH, H, W = patch1[None].size()       \n",
    "            # print(B, N, CH, H, W) \n",
    "            desc1 =descritor(patch1.view(B * N, CH, H, W))\n",
    "            B, N, CH, H, W = patch2[None].size()\n",
    "            desc2 =descritor(patch2.view(B * N, CH, H, W))                        \n",
    "            #TODO: verificar a correspondencia entre os descritores\n",
    "\n",
    "            dist,match_desc = kornia.feature.match_smnn(desc1, desc2, th=0.8) \n",
    "            \n",
    "            # print('calcular_associacao ',match_desc.shape,len(matches))            \n",
    "            intersecao = calcular_associacao(match_desc.cpu().numpy(), np.array(matches)) \n",
    "            total.append(len(matches))\n",
    "            intersecao_total.append(len(intersecao))            \n",
    "            # plot_matches_keypoints(img2[0,0].cpu().numpy(), filtered_points1.cpu().numpy(), img2[0,0].cpu().numpy(), filtered_points2.cpu().numpy(), matches)\n",
    "            # plot_matches_keypoints(img2[0,0].cpu().numpy(), filtered_points1.cpu().numpy(), img2[0,0].cpu().numpy(), filtered_points2.cpu().numpy(), match_desc)\n",
    "    # print('total: ',np.sum(total),' intersecao: ',np.sum(intersecao_total))\n",
    "    return (np.sum(intersecao_total)/np.sum(total))*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationGenerator:\n",
    "    def __init__(self, n_variations):\n",
    "        # Definir as augmentações\n",
    "        aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "            kornia.augmentation.RandomAffine(degrees=360, translate=(0.2, 0.2), scale=(0.95, 1.05), shear=10,p=0.8),\n",
    "            kornia.augmentation.RandomPerspective(0.2, p=0.7),\n",
    "            kornia.augmentation.RandomBoxBlur((4,4),p=0.5),\n",
    "            data_keys=[kornia.constants.DataKey.INPUT,  # Especifica as chaves corretamente\n",
    "                       kornia.constants.DataKey.MASK,\n",
    "                       kornia.constants.DataKey.KEYPOINTS],\n",
    "            same_on_batch=True,\n",
    "        )\n",
    "\n",
    "        self.augmentation_sequence = aug_gen\n",
    "        self.n_variations = n_variations\n",
    "        self.param_list = []\n",
    "        self.current_index = 0\n",
    "\n",
    "    def generate_variations(self, image, mask, keypoints):\n",
    "        \"\"\"\n",
    "        Gera múltiplas variações de augmentações e coleta seus parâmetros.\n",
    "        \"\"\"\n",
    "        for _ in range(self.n_variations):\n",
    "            # Apenas executa a sequência de augmentação e salva os parâmetros gerados\n",
    "            self.augmentation_sequence(image, mask, keypoints)\n",
    "            self.param_list.append(self.augmentation_sequence._params)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current_index = 0  # Resetar o índice a cada nova iteração\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"\n",
    "        Retorna a próxima variação de parâmetros de augmentação.\n",
    "        A iteração será circular.\n",
    "        \"\"\"\n",
    "        result = self.param_list[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.param_list)\n",
    "        return result\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Método para resetar o estado do gerador de augmentação.\"\"\"\n",
    "        self.current_index = 0  # Reseta o índice de iteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wagner/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/functional.py:4969: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/wagner/anaconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdb70be9762482bbf0b51f66eabc933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - hardnet - 0.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_743046/2450327458.py:80: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647327249/work/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(pontos_filtrados_1), torch.tensor(pontos_filtrados_2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f4b50cf7504b44852eac7b1e88c27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - hardnet - 1.0:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cbebb4b0d640c5975ad356412e140c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - hardnet - 1.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e363a4b5604a04a105db716e7859be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - sift - 0.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c98b851ac9b446dab4aa25cf2884482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - sift - 1.0:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80c353504784ca297215b80977ac80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - sift - 1.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "set_seed(42)\n",
    "aug_gen = AugmentationGenerator(15)\n",
    "image = torch.rand(1, 1, 120, 120)  # Imagem com valores aleatórios\n",
    "mask = torch.ones(1, 1, 120, 120)  # Máscara binária\n",
    "keypoints = torch.tensor([[[30, 30], [90, 90]]], dtype=torch.float32)  # Pontos chave de exemplo\n",
    "\n",
    "# Gerar as variações\n",
    "aug_gen.generate_variations(image, mask, keypoints)\n",
    "# Loop pelas combinações geradas\n",
    "for (detector_name, detector), (descriptor_name, descriptor), alpha_threshold in combinations:\n",
    "    # Log dos parâmetros atuais\n",
    "    pbar = tqdm(test_loader, desc=f\"Evaluation {detector_name} - {descriptor_name} - {alpha_threshold}\")  # Usando f-string para formatar o nome da classe do detector\n",
    "    list_acc = []\n",
    "    for imgs_batch,labels_batch in pbar:# itera em todo dataset\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "        _acc = detect_extract_feat_in_batch(imgs_batch,aug_gen,detector,descriptor,alpha_threshold)\n",
    "        list_acc.append(_acc)\n",
    "        pbar.set_postfix({\"Acc.\": f\"{_acc:.4f}\", \"Mean Acc.\": f\"{np.mean(list_acc):.4f}\"})\n",
    "    aug_gen.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation singular_point - hardnet - 0.5: 100%  102/102 [09:14<00:00,  4.22s/it, Acc.=65.4762, Mean Acc.=68.5757]\n",
    "Evaluation singular_point - hardnet - 1.0: 100%  102/102 [09:09<00:00,  3.93s/it, Acc.=53.2520, Mean Acc.=58.6233]\n",
    "Evaluation singular_point - hardnet - 1.5: 100%  102/102 [08:50<00:00,  4.02s/it, Acc.=45.7055, Mean Acc.=51.0960]\n",
    "\n",
    "Evaluation singular_point - sift - 0.5: 100%  102/102 [08:57<00:00,  3.98s/it, Acc.=59.5238, Mean Acc.=66.1388]\n",
    "Evaluation singular_point - sift - 1.0: 100%  102/102 [08:58<00:00,  4.03s/it, Acc.=47.9675, Mean Acc.=55.4892]\n",
    "Evaluation singular_point - sift - 1.5: 100%  102/102 [08:59<00:00,  4.07s/it, Acc.=41.1043, Mean Acc.=47.7420]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    "kornia-matching-test.\n",
    "\n",
    "ours\tsift\t0.5 match of dataset  68.12792897842729\n",
    "ours\tsift\t1.0 match of dataset  57.2651854514897\n",
    "ours\tsift\t1.5 match of dataset  48.07975034660492\n",
    "\n",
    "ours\thardnet\t0.5 match of dataset  69.75870075937866\n",
    "ours\thardnet\t1.0 match of dataset  59.41000414346953\n",
    "ours\thardnet\t1.5 match of dataset  50.44833692096903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match of dataset  47.742045293607646"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singular-points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

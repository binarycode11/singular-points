{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Documentation: Evaluating Repeatability vs Matching Accuracy\n",
    "\n",
    "This document advances the analysis of positional congruence by probing its influence on the matching accuracy of keypoint descriptors. Building on the findings of the initial experiment, we concentrate on a subset of keypoints that adhere to a repeatability criterion, evaluated under three positional congruence thresholds: **α** = 0.5, **α** = 1.0, and **α** = 1.5. The descriptors under examination, SIFT and HardNet, are established benchmarks in the domain of keypoint-based matching algorithms.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "To ensure methodological rigor, the same detection approach employed in the preceding experiment was utilized, given its superior performance in achieving positional congruence. Matching accuracy was computed exclusively for keypoints meeting the repeatability criterion at each positional congruence threshold, enabling a controlled and precise evaluation of descriptor performance.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The primary aim of this experiment is to elucidate the interplay between repeatability thresholds and feature matching accuracy. The results underscore a critical trade-off: increasing the leniency of positional congruence thresholds (**higher α**) accommodates greater keypoint deviations but potentially diminishes matching accuracy. Conversely, imposing stricter thresholds (**lower α**) enhances matching precision at the expense of excluding a larger proportion of keypoints.\n",
    "\n",
    "Through a systematic exploration of these dynamics, this study contributes a nuanced understanding of how positional congruence influences descriptor efficacy, offering valuable insights into their performance across varying operational constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072\n"
     ]
    }
   ],
   "source": [
    "# Imports organizados por funcionalidade\n",
    "import torch\n",
    "from torch import nn\n",
    "import kornia\n",
    "import itertools\n",
    "from teste_util import read_dataload_flower, set_seed\n",
    "from visidex.kornia_local_feature import SingularPointSosNet\n",
    "# from external.hardnet_pytorch import HardNet\n",
    "\n",
    "# Configurações iniciais\n",
    "set_seed(42)  # Fixar a semente para reprodutibilidade\n",
    "# Leitura dos dados\n",
    "data_dir = './data/datasets'\n",
    "batch_size = 60\n",
    "train_loader, test_loader = read_dataload_flower(120, data_dir, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Configuração do detector de pontos-chave\n",
    "keypoint_detector_config = {\n",
    "    'num_filters': 8,\n",
    "    'num_levels': 3,\n",
    "    'kernel_size': 5,\n",
    "    'Detector_conf': {\n",
    "        'nms_size': 5,\n",
    "        'pyramid_levels': 0,\n",
    "        'up_levels': 0,\n",
    "        'scale_factor_levels': 1.0,\n",
    "        's_mult': 5.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "singular_point_detector = (\n",
    "    SingularPointSosNet(config=keypoint_detector_config, device=device)\n",
    "    .initialize_detector(num_features=60, size_laf=32)\n",
    "    .to(device)\n",
    ")\n",
    "# # Classe para o descritor HardNet\n",
    "# class HardNetDescriptor(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         hardnet = HardNet()\n",
    "#         checkpoint_path = 'trained_models/pretrained_nets/HardNet++.pth'\n",
    "#         checkpoint = torch.load(checkpoint_path)\n",
    "#         hardnet.load_state_dict(checkpoint['state_dict'])\n",
    "#         hardnet.eval()\n",
    "#         hardnet.to(device)\n",
    "#         self.model = hardnet\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "# Inicialização dos descritores\n",
    "hardnet_descriptor = kornia.feature.HardNet(pretrained=True).to(device).eval()\n",
    "sosnet_descriptor = kornia.feature.SOSNet(pretrained=True).to(device).eval()\n",
    "sift_descriptor = kornia.feature.SIFTDescriptor(32, rootsift=True)\n",
    "\n",
    "# Dicionário com detectores e descritores já instanciados\n",
    "detectors = {\n",
    "    \"singular_point\": singular_point_detector,  # Instância do detector\n",
    "}\n",
    "\n",
    "descriptors = {\n",
    "    \"hardnet\": hardnet_descriptor,  # Instância do descritor HardNet\n",
    "    \"sosnet\":sosnet_descriptor,        # Instância do descritor SOSNet\n",
    "    \"sift\": sift_descriptor,        # Instância do descritor SIFT\n",
    "}\n",
    "\n",
    "thresholds = {\n",
    "    \"alpha_threshold\": [1.5],  # Lista de thresholds 0.5, 1.0, 1.5\n",
    "}\n",
    "\n",
    "def generate_combinations(detectors, descriptors, thresholds):\n",
    "    # Produto cartesiano entre detectores, descritores e thresholds\n",
    "    return list(itertools.product(detectors.items(), descriptors.items(), thresholds[\"alpha_threshold\"]))\n",
    "\n",
    "# Gerar as combinações\n",
    "combinations = generate_combinations(detectors, descriptors, thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.feature import laf_from_center_scale_ori\n",
    "def convert_points_to_lafs(points,img1, PS=19,scale=6):\n",
    "    orient = kornia.feature.LAFOrienter(PS)#kornia.feature.LAFOrienter(PS)PassLAF()\n",
    "    scale_lafs = torch.ones(img1.shape[0],points.shape[1],1,1)*scale\n",
    "    scale_lafs = scale_lafs.to(img1.device)\n",
    "    points = points.to(img1.device)\n",
    "    lafs1 = laf_from_center_scale_ori(points,scale_lafs)\n",
    "    lafs2 = orient(lafs1, img1)\n",
    "    return lafs2\n",
    "    \n",
    "def extract_patches_simple(batch, lafs, PS=19):\n",
    "    imgs_patches = kornia.feature.extract_patches_from_pyramid(batch, lafs, PS)\n",
    "    imgs_patches =imgs_patches.reshape(-1,imgs_patches.shape[2],PS,PS)\n",
    "    return imgs_patches\n",
    "\n",
    "def plot_patches_side_by_side(imgs_patches):\n",
    "    num_imgs = imgs_patches.shape[0]  # Número de imagens\n",
    "    fig, axs = plt.subplots(1, num_imgs, figsize=(num_imgs*4, 4))\n",
    "\n",
    "    axs = axs.reshape((1, num_imgs))  # Ajustar a forma para matriz 2D com uma única linha\n",
    "\n",
    "    for i in range(num_imgs):\n",
    "        axs[0, i].imshow(kornia.tensor_to_image(imgs_patches[i]))\n",
    "        axs[0, i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import kornia.feature as KF\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia as K\n",
    "\n",
    "def visualize_LAF(img, LAF, img_idx = 0):\n",
    "    x, y = KF.laf.get_laf_pts_to_draw(LAF, img_idx)\n",
    "    print(x[0][:5],y[0][:5])\n",
    "    plt.figure()\n",
    "    plt.imshow(K.utils.tensor_to_image(img[img_idx]))\n",
    "    plt.plot(x, y, 'r')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_matches_keypoints(image1, keypoints1, image2, keypoints2, matches, **kwargs):\n",
    "    print('image1 shape: ',image1.shape,image1.dtype,image2.shape,image2.dtype)\n",
    "    # Concatenar as duas imagens lado a lado\n",
    "    combined_image = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(combined_image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Desenhar pontos correspondentes e linhas conectando-os\n",
    "    offset = image1.shape[1]\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints1):\n",
    "        ax.plot(x, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for i, (x, y) in enumerate(keypoints2):\n",
    "        ax.plot(x+offset, y, 'o',markerfacecolor='none', markeredgecolor='r',\n",
    "                markersize=20, markeredgewidth=1)\n",
    "        ax.annotate(str(i), (x+offset, y), color='r',xytext=(10, 10), textcoords='offset points', fontsize=12)\n",
    "\n",
    "    for match in matches:\n",
    "        x1, y1 = keypoints1[match[0],0], keypoints1[match[0],1]\n",
    "        x2, y2 = keypoints2[match[1],0]+offset, keypoints2[match[1],1]\n",
    "        ax.plot([x1, x2], [y1, y2], '-', color='lime', lw=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_with_keypoints(image_tensor, keypoints_tensor):\n",
    "    # Converter a imagem tensorial em objeto PIL.Image\n",
    "    image = kornia.utils.tensor_to_image(image_tensor)\n",
    "    # Plotar a imagem e os keypoints\n",
    "    plt.imshow(image)\n",
    "    if keypoints_tensor is not None:\n",
    "        # Extrair as coordenadas x e y dos keypoints\n",
    "        keypoints_x = keypoints_tensor[:,0].flatten().tolist()\n",
    "        keypoints_y = keypoints_tensor[:,1].flatten().tolist()\n",
    "        plt.scatter(keypoints_x, keypoints_y, c='red')\n",
    "    plt.show()\n",
    "    \n",
    "def filtrar_keypoints(lista_de_pontos, tensor_mascara):\n",
    "    # Verificar se as coordenadas estão dentro das dimensões\n",
    "    dimensao_max_x, dimensao_max_y = tensor_mascara.shape[1] - 1, tensor_mascara.shape[0] - 1\n",
    "    pontos_filtrados = [\n",
    "        ponto.tolist()  for ponto in lista_de_pontos \n",
    "        if 0 <= ponto[0] <= dimensao_max_x \n",
    "        and 0 <= ponto[1] <= dimensao_max_y \n",
    "        and tensor_mascara[int(ponto[1]), int(ponto[0])] \n",
    "    ]\n",
    "    return torch.tensor(pontos_filtrados)\n",
    "\n",
    "def filtrar_keypoints_conjuntos(lista_de_pontos_1, lista_de_pontos_2, tensor_mascara):\n",
    "    dimensao_max_x, dimensao_max_y = tensor_mascara.shape[1] - 1, tensor_mascara.shape[0] - 1\n",
    "    pontos_filtrados_1 = []\n",
    "    pontos_filtrados_2 = []\n",
    "    \n",
    "    for ponto_1, ponto_2 in zip(lista_de_pontos_1.cpu(), lista_de_pontos_2.cpu()):\n",
    "        x, y = ponto_1\n",
    "        if 0 <= x <= dimensao_max_x and 0 <= y <= dimensao_max_y and tensor_mascara[int(y), int(x)]:\n",
    "            pontos_filtrados_1.append(ponto_1.numpy())\n",
    "            pontos_filtrados_2.append(ponto_2.numpy())\n",
    "            \n",
    "    return torch.tensor(pontos_filtrados_1), torch.tensor(pontos_filtrados_2)\n",
    "\n",
    "def find_best_matching_indices_knn(points1, points2, threshold, k=3):\n",
    "    if len(points1) == 0 or len(points2) == 0:\n",
    "        return []\n",
    "    distances = cdist(points1, points2)\n",
    "    best_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    best_distances = np.take_along_axis(distances, best_indices, axis=1)\n",
    "\n",
    "    matched = []\n",
    "\n",
    "    for i in range(len(points1)):\n",
    "        min_distance = np.min(best_distances[i])\n",
    "        if min_distance < threshold:\n",
    "            best_index = np.argmin(best_distances[i])\n",
    "            matched.append((i, best_indices[i, best_index]))\n",
    "\n",
    "    return matched\n",
    "\n",
    "def calcular_associacao(matches1, matches2):\n",
    "    intersecao = set(tuple(match) for match in matches1) & set(tuple(match) for match in matches2)\n",
    "    # assoc_score = len(intersecao) / min(matches1.shape[0], matches2.shape[0])\n",
    "    return intersecao #assoc_score\n",
    "\n",
    "\n",
    "def detect_extract_feat_in_batch(batch1,aug_list, detector,descritor,alpha_threshold):\n",
    "    total = []\n",
    "    intersecao_total = []\n",
    "    with torch.no_grad():\n",
    "        for img1  in batch1:            \n",
    "            lafs1, resps1 = detector(img1[None])\n",
    "            B,C,H,W = img1[None].shape\n",
    "            mask = torch.ones(B,C,H,W).to(img1.device) \n",
    "            #lafs1 to points1\n",
    "            points1 =kornia.feature.get_laf_center(lafs1)   \n",
    "\n",
    "            if( points1.shape[1] == 0):\n",
    "                # print('aug_list shape: ',points1.shape) \n",
    "                continue                    \n",
    "            params = next(aug_list)    \n",
    "            img2,mask_t,ponts_t=aug_list.augmentation_sequence(img1,mask,points1,params=params)    \n",
    "            img2 = img2.to(img1.device)                   \n",
    "            lafs2, resps2 = detector(img2)            \n",
    "            points2 =kornia.feature.get_laf_center(lafs2)\n",
    "            # visualize_LAF(img2, lafs2, 0)\n",
    "                        \n",
    "            # pontos filtrados com base da mascara\n",
    "            filtered_points1,filtered_points0 = filtrar_keypoints_conjuntos(ponts_t[0],points1[0],mask_t[0,0].bool())\n",
    "            filtered_points2 = filtrar_keypoints(points2[0],mask_t[0,0].bool())                        \n",
    "            # print('filtered shape: ',filtered_points1.shape,filtered_points2.shape)\n",
    "            if( filtered_points1.shape[0] == 0 or filtered_points2.shape[0] == 0):\n",
    "                # print('filtered shape: ',filtered_points1.shape,filtered_points2.shape)\n",
    "                continue                        \n",
    "            \n",
    "            matches = find_best_matching_indices_knn(filtered_points1.cpu(), filtered_points2.cpu(), threshold=alpha_threshold, k=1)\n",
    "            if(len(matches) == 0):\n",
    "                # print('matches shape: ',len(matches))\n",
    "                continue\n",
    "            \n",
    "            # print('filtered_points1 shape: ',filtered_points0.shape,filtered_points1.shape,filtered_points2.shape)\n",
    "            lafs1 = convert_points_to_lafs(filtered_points0[None],img1[None], PS=19,scale=5)\n",
    "            lafs2 = convert_points_to_lafs(filtered_points2[None],img2, PS=19,scale=5)\n",
    "            # print('lafs1 shape: ',lafs1.shape,lafs2.shape,img1.shape,img2.shape)\n",
    "            patch1 = extract_patches_simple(img1[None], lafs1, PS=32)# TODO 13 para sift e 32 hardnet\n",
    "            patch2 = extract_patches_simple(img2, lafs2, PS=32)# TODO 13 para sift e 32 hardnet\n",
    " \n",
    "            B, N, CH, H, W = patch1[None].size()       \n",
    "            # print(B, N, CH, H, W) \n",
    "            desc1 =descritor(patch1.view(B * N, CH, H, W))\n",
    "            B, N, CH, H, W = patch2[None].size()\n",
    "            desc2 =descritor(patch2.view(B * N, CH, H, W))                        \n",
    "            #TODO: verificar a correspondencia entre os descritores\n",
    "\n",
    "            dist,match_desc = kornia.feature.match_smnn(desc1, desc2, th=0.8) \n",
    "            \n",
    "            # print('calcular_associacao ',match_desc.shape,len(matches))            \n",
    "            intersecao = calcular_associacao(match_desc.cpu().numpy(), np.array(matches)) \n",
    "            total.append(len(matches))\n",
    "            intersecao_total.append(len(intersecao))            \n",
    "            # plot_matches_keypoints(img2[0,0].cpu().numpy(), filtered_points1.cpu().numpy(), img2[0,0].cpu().numpy(), filtered_points2.cpu().numpy(), matches)\n",
    "            # plot_matches_keypoints(img2[0,0].cpu().numpy(), filtered_points1.cpu().numpy(), img2[0,0].cpu().numpy(), filtered_points2.cpu().numpy(), match_desc)\n",
    "    # print('total: ',np.sum(total),' intersecao: ',np.sum(intersecao_total))\n",
    "    return (np.sum(intersecao_total)/np.sum(total))*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationGenerator:\n",
    "    def __init__(self, n_variations):\n",
    "        # Definir as augmentações\n",
    "        aug_gen = kornia.augmentation.AugmentationSequential(\n",
    "            kornia.augmentation.RandomAffine(degrees=360, translate=(0.2, 0.2), scale=(0.95, 1.05), shear=10,p=0.8),\n",
    "            kornia.augmentation.RandomPerspective(0.2, p=0.7),\n",
    "            kornia.augmentation.RandomBoxBlur((4,4),p=0.5),\n",
    "            data_keys=[kornia.constants.DataKey.INPUT,  # Especifica as chaves corretamente\n",
    "                       kornia.constants.DataKey.MASK,\n",
    "                       kornia.constants.DataKey.KEYPOINTS],\n",
    "            same_on_batch=True,\n",
    "        )\n",
    "\n",
    "        self.augmentation_sequence = aug_gen\n",
    "        self.n_variations = n_variations\n",
    "        self.param_list = []\n",
    "        self.current_index = 0\n",
    "\n",
    "    def generate_variations(self, image, mask, keypoints):\n",
    "        \"\"\"\n",
    "        Gera múltiplas variações de augmentações e coleta seus parâmetros.\n",
    "        \"\"\"\n",
    "        for _ in range(self.n_variations):\n",
    "            # Apenas executa a sequência de augmentação e salva os parâmetros gerados\n",
    "            self.augmentation_sequence(image, mask, keypoints)\n",
    "            self.param_list.append(self.augmentation_sequence._params)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current_index = 0  # Resetar o índice a cada nova iteração\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"\n",
    "        Retorna a próxima variação de parâmetros de augmentação.\n",
    "        A iteração será circular.\n",
    "        \"\"\"\n",
    "        result = self.param_list[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.param_list)\n",
    "        return result\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Método para resetar o estado do gerador de augmentação.\"\"\"\n",
    "        self.current_index = 0  # Reseta o índice de iteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7064673bc2ee4c1a933941edd8ea0404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - hardnet - 1.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cd0eb578f24f969a13c09856cddfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - sosnet - 1.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159136c3cf884d5cbe08f73f9dda6855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation singular_point - sift - 1.5:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs_batch,labels_batch \u001b[38;5;129;01min\u001b[39;00m pbar:\u001b[38;5;66;03m# itera em todo dataset\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     imgs_batch \u001b[38;5;241m=\u001b[39m imgs_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m     _acc \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_extract_feat_in_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43maug_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdescriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     list_acc\u001b[38;5;241m.\u001b[39mappend(_acc)\n\u001b[1;32m     20\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc.\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Acc.\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(list_acc)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n",
      "Cell \u001b[0;32mIn[8], line 120\u001b[0m, in \u001b[0;36mdetect_extract_feat_in_batch\u001b[0;34m(batch1, aug_list, detector, descritor, alpha_threshold)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m                    \n\u001b[1;32m    119\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(aug_list)    \n\u001b[0;32m--> 120\u001b[0m img2,mask_t,ponts_t\u001b[38;5;241m=\u001b[39m\u001b[43maug_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmentation_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpoints1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m    121\u001b[0m img2 \u001b[38;5;241m=\u001b[39m img2\u001b[38;5;241m.\u001b[39mto(img1\u001b[38;5;241m.\u001b[39mdevice)                   \n\u001b[1;32m    122\u001b[0m lafs2, resps2 \u001b[38;5;241m=\u001b[39m detector(img2)            \n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/container/augment.py:516\u001b[0m, in \u001b[0;36mAugmentationSequential.__call__\u001b[0;34m(self, input_names_to_handle, output_type, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_features:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# TODO: Some more behaviour for AugmentationSequential needs to be revisited later\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# e.g. We convert only images, etc.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     decorated_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_input_output(\n\u001b[1;32m    514\u001b[0m         input_names_to_handle\u001b[38;5;241m=\u001b[39minput_names_to_handle, output_type\u001b[38;5;241m=\u001b[39moutput_type\n\u001b[1;32m    515\u001b[0m     )(\u001b[38;5;28msuper\u001b[39m(ImageSequential, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m)\n\u001b[0;32m--> 516\u001b[0m     _output_image \u001b[38;5;241m=\u001b[39m \u001b[43mdecorated_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    519\u001b[0m         original_keys, in_data_keys, inputs, invalid_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preproc_dict_data(inputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/core/module.py:81\u001b[0m, in \u001b[0;36mImageModuleMixIn.convert_input_output.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             kwargs[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_tensor(value)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Call the actual forward method\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m tensor_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor_outputs, (\u001b[38;5;28mtuple\u001b[39m,)):\n\u001b[1;32m     84\u001b[0m     tensor_outputs \u001b[38;5;241m=\u001b[39m (tensor_outputs,)\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/container/augment.py:465\u001b[0m, in \u001b[0;36mAugmentationSequential.forward\u001b[0;34m(self, params, data_keys, *args)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    464\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_submodule(param\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 465\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_args\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;66;03m# Make sure we are unpacking a list whilst post-proc\u001b[39;00m\n\u001b[1;32m    470\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m [outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/container/ops.py:155\u001b[0m, in \u001b[0;36mAugmentationSequentialOps.transform\u001b[0;34m(self, module, param, extra_args, data_keys, *arg)\u001b[0m\n\u001b[1;32m    153\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mappend(MaskSequentialOps\u001b[38;5;241m.\u001b[39mtransform_list(inp, module, param\u001b[38;5;241m=\u001b[39mparam, extra_args\u001b[38;5;241m=\u001b[39mextra_arg))\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_arg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/container/ops.py:282\u001b[0m, in \u001b[0;36mMaskSequentialOps.transform\u001b[0;34m(cls, input, module, param, extra_args)\u001b[0m\n\u001b[1;32m    279\u001b[0m     extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, (K\u001b[38;5;241m.\u001b[39mGeometricAugmentationBase2D,)):\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_masks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance_module_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, (K\u001b[38;5;241m.\u001b[39mGeometricAugmentationBase3D,)):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe support for 3d mask operations are not yet supported. You are welcome to file a PR in our repo.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/base.py:362\u001b[0m, in \u001b[0;36m_AugmentationBase.transform_masks\u001b[0;34m(self, input, params, flags, transform, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_tensor(in_tensor)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_apply\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 362\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m to_apply\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    364\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_non_transform_mask(in_tensor, params, flags, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/_2d/geometric/base.py:92\u001b[0m, in \u001b[0;36mGeometricAugmentationBase2D.apply_transform_mask\u001b[0;34m(self, input, params, flags, transform)\u001b[0m\n\u001b[1;32m     90\u001b[0m     resample_method \u001b[38;5;241m=\u001b[39m flags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m     flags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Resample\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resample_method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     flags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m resample_method\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/augmentation/_2d/geometric/affine.py:133\u001b[0m, in \u001b[0;36mRandomAffine.apply_transform\u001b[0;34m(self, input, params, flags, transform)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, Tensor):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the `transform` be a Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(transform)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwarp_affine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malign_corners\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/kornia/geometry/transform/imgwarp.py:219\u001b[0m, in \u001b[0;36mwarp_affine\u001b[0;34m(src, M, dsize, mode, padding_mode, align_corners, fill_value)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# src_norm_trans_dst_norm = torch.inverse(dst_norm_trans_src_norm)\u001b[39;00m\n\u001b[1;32m    217\u001b[0m src_norm_trans_dst_norm \u001b[38;5;241m=\u001b[39m _torch_inverse_cast(dst_norm_trans_src_norm)\n\u001b[0;32m--> 219\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_norm_trans_dst_norm\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/singular-points/lib/python3.9/site-packages/torch/nn/functional.py:5012\u001b[0m, in \u001b[0;36maffine_grid\u001b[0;34m(theta, size, align_corners)\u001b[0m\n\u001b[1;32m   5009\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected non-zero, positive output size. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5012\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_grid_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "set_seed(42)\n",
    "aug_gen = AugmentationGenerator(15)\n",
    "image = torch.rand(1, 1, 120, 120)  # Imagem com valores aleatórios\n",
    "mask = torch.ones(1, 1, 120, 120)  # Máscara binária\n",
    "keypoints = torch.tensor([[[30, 30], [90, 90]]], dtype=torch.float32)  # Pontos chave de exemplo\n",
    "\n",
    "# Gerar as variações\n",
    "aug_gen.generate_variations(image, mask, keypoints)\n",
    "# Loop pelas combinações geradas\n",
    "for (detector_name, detector), (descriptor_name, descriptor), alpha_threshold in combinations:\n",
    "    # Log dos parâmetros atuais\n",
    "    pbar = tqdm(test_loader, desc=f\"Evaluation {detector_name} - {descriptor_name} - {alpha_threshold}\")  # Usando f-string para formatar o nome da classe do detector\n",
    "    list_acc = []\n",
    "    for imgs_batch,labels_batch in pbar:# itera em todo dataset\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "        _acc = detect_extract_feat_in_batch(imgs_batch,aug_gen,detector,descriptor,alpha_threshold)\n",
    "        list_acc.append(_acc)\n",
    "        pbar.set_postfix({\"Acc.\": f\"{_acc:.4f}\", \"Mean Acc.\": f\"{np.mean(list_acc):.4f}\"})\n",
    "    aug_gen.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation singular_point - hardnet - 0.5: 100% 102/102 [09:19<00:00,  4.18s/it, Acc.=54.7619, Mean Acc.=66.0701]\n",
    "Evaluation singular_point - hardnet - 1.0: 100% 102/102 [09:21<00:00,  4.19s/it, Acc.=46.7480, Mean Acc.=55.0861]\n",
    "Evaluation singular_point - hardnet - 1.5: 100% 102/102 [09:18<00:00,  3.98s/it, Acc.=38.6503, Mean Acc.=47.0133]\n",
    "\n",
    "Evaluation singular_point - sosnet - 0.5: 100% 102/102 [08:55<00:00,  4.03s/it, Acc.=60.7143, Mean Acc.=65.8783]\n",
    "Evaluation singular_point - sosnet - 1.0: 100% 102/102 [09:19<00:00,  4.52s/it, Acc.=48.7805, Mean Acc.=54.6731]\n",
    "Evaluation singular_point - sosnet - 1.5: 100% 102/102 [09:45<00:00,  4.31s/it, Acc.=40.1840, Mean Acc.=46.4996]\n",
    "\n",
    "Evaluation singular_point - sift - 0.5: 100% 102/102 [09:29<00:00,  4.26s/it, Acc.=59.5238, Mean Acc.=66.1388]\n",
    "Evaluation singular_point - sift - 1.0: 100% 102/102 [09:22<00:00,  4.08s/it, Acc.=47.9675, Mean Acc.=55.4892]\n",
    "Evaluation singular_point - sift - 1.5: 100% 102/102 [09:50<00:00,  4.59s/it, Acc.=41.1043, Mean Acc.=47.7420]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    "kornia-matching-test.\n",
    "\n",
    "ours\tsift\t0.5 match of dataset  68.12792897842729\n",
    "ours\tsift\t1.0 match of dataset  57.2651854514897\n",
    "ours\tsift\t1.5 match of dataset  48.07975034660492\n",
    "\n",
    "ours\thardnet\t0.5 match of dataset  69.75870075937866\n",
    "ours\thardnet\t1.0 match of dataset  59.41000414346953\n",
    "ours\thardnet\t1.5 match of dataset  50.44833692096903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match of dataset  47.742045293607646"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singular-points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
